INFO:root:Using: cuda:7
INFO:root:Using seed 25.
INFO:root:Dataset: chameleon
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=2325, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f6ad55b36d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f6ad55b36d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f6ad55b36d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f6ad55b36d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (2): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f6ad55b36d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f6ad55b36d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 212061
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.523935 train_acc: 0.381775 train_f1: 0.381775 time: 1.3914s
INFO:root:Epoch: 0010 val_loss: 1.490174 val_acc: 0.388278 val_f1: 0.388278
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.360637 train_acc: 0.509034 train_f1: 0.509034 time: 1.3944s
INFO:root:Epoch: 0020 val_loss: 1.380870 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.213120 train_acc: 0.634721 train_f1: 0.634721 time: 1.3967s
INFO:root:Epoch: 0030 val_loss: 1.262069 val_acc: 0.578755 val_f1: 0.578755
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.084563 train_acc: 0.687745 train_f1: 0.687745 time: 1.3868s
INFO:root:Epoch: 0040 val_loss: 1.177746 val_acc: 0.639194 val_f1: 0.639194
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.015570 train_acc: 0.733700 train_f1: 0.733700 time: 1.3878s
INFO:root:Epoch: 0050 val_loss: 1.154015 val_acc: 0.637363 val_f1: 0.637363
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 0.969882 train_acc: 0.736057 train_f1: 0.736057 time: 1.3897s
INFO:root:Epoch: 0060 val_loss: 1.114831 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.947879 train_acc: 0.736449 train_f1: 0.736449 time: 1.4662s
INFO:root:Epoch: 0070 val_loss: 1.095764 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.936316 train_acc: 0.738020 train_f1: 0.738020 time: 1.4021s
INFO:root:Epoch: 0080 val_loss: 1.114099 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.927687 train_acc: 0.735664 train_f1: 0.735664 time: 1.3947s
INFO:root:Epoch: 0090 val_loss: 1.092518 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 0.911171 train_acc: 0.738413 train_f1: 0.738413 time: 1.3957s
INFO:root:Epoch: 0100 val_loss: 1.097151 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.904051 train_acc: 0.738806 train_f1: 0.738806 time: 1.3942s
INFO:root:Epoch: 0110 val_loss: 1.092655 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.902212 train_acc: 0.738413 train_f1: 0.738413 time: 1.3969s
INFO:root:Epoch: 0120 val_loss: 1.103793 val_acc: 0.644689 val_f1: 0.644689
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.897287 train_acc: 0.739592 train_f1: 0.739592 time: 1.3977s
INFO:root:Epoch: 0130 val_loss: 1.097230 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.899086 train_acc: 0.742734 train_f1: 0.742734 time: 1.3955s
INFO:root:Epoch: 0140 val_loss: 1.091789 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.894007 train_acc: 0.738806 train_f1: 0.738806 time: 1.3949s
INFO:root:Epoch: 0150 val_loss: 1.093833 val_acc: 0.639194 val_f1: 0.639194
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.888085 train_acc: 0.739592 train_f1: 0.739592 time: 1.3944s
INFO:root:Epoch: 0160 val_loss: 1.071228 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.891723 train_acc: 0.745876 train_f1: 0.745876 time: 1.3927s
INFO:root:Epoch: 0170 val_loss: 1.097513 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.895209 train_acc: 0.744698 train_f1: 0.744698 time: 1.3938s
INFO:root:Epoch: 0180 val_loss: 1.097310 val_acc: 0.663004 val_f1: 0.663004
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.883908 train_acc: 0.739984 train_f1: 0.739984 time: 1.3931s
INFO:root:Epoch: 0190 val_loss: 1.063722 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 0.884962 train_acc: 0.740770 train_f1: 0.740770 time: 1.3944s
INFO:root:Epoch: 0200 val_loss: 1.074962 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 0.883994 train_acc: 0.741555 train_f1: 0.741555 time: 1.4020s
INFO:root:Epoch: 0210 val_loss: 1.084434 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 0.885213 train_acc: 0.739592 train_f1: 0.739592 time: 1.4004s
INFO:root:Epoch: 0220 val_loss: 1.084065 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 0.882468 train_acc: 0.739199 train_f1: 0.739199 time: 1.4004s
INFO:root:Epoch: 0230 val_loss: 1.086085 val_acc: 0.644689 val_f1: 0.644689
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 0.888359 train_acc: 0.750589 train_f1: 0.750589 time: 1.3965s
INFO:root:Epoch: 0240 val_loss: 1.087437 val_acc: 0.659341 val_f1: 0.659341
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.882035 train_acc: 0.767871 train_f1: 0.767871 time: 1.3950s
INFO:root:Epoch: 0250 val_loss: 1.085968 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.881675 train_acc: 0.752553 train_f1: 0.752553 time: 1.3945s
INFO:root:Epoch: 0260 val_loss: 1.071972 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.877374 train_acc: 0.741948 train_f1: 0.741948 time: 1.4021s
INFO:root:Epoch: 0270 val_loss: 1.073839 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.881980 train_acc: 0.766693 train_f1: 0.766693 time: 1.3956s
INFO:root:Epoch: 0280 val_loss: 1.083972 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.879516 train_acc: 0.763158 train_f1: 0.763158 time: 1.3961s
INFO:root:Epoch: 0290 val_loss: 1.074096 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0300 lr: [0.00025, 0.00025] train_loss: 0.882618 train_acc: 0.739592 train_f1: 0.739592 time: 1.3915s
INFO:root:Epoch: 0300 val_loss: 1.070092 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0310 lr: [0.00025, 0.00025] train_loss: 0.871323 train_acc: 0.779654 train_f1: 0.779654 time: 1.4066s
INFO:root:Epoch: 0310 val_loss: 1.083237 val_acc: 0.686813 val_f1: 0.686813
INFO:root:Epoch: 0320 lr: [0.00025, 0.00025] train_loss: 0.866133 train_acc: 0.756088 train_f1: 0.756088 time: 1.3980s
INFO:root:Epoch: 0320 val_loss: 1.062849 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0330 lr: [0.00025, 0.00025] train_loss: 0.869995 train_acc: 0.795365 train_f1: 0.795365 time: 1.3902s
INFO:root:Epoch: 0330 val_loss: 1.072888 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0340 lr: [0.00025, 0.00025] train_loss: 0.874497 train_acc: 0.793401 train_f1: 0.793401 time: 1.3983s
INFO:root:Epoch: 0340 val_loss: 1.060276 val_acc: 0.683150 val_f1: 0.683150
INFO:root:Epoch: 0350 lr: [0.00025, 0.00025] train_loss: 0.872882 train_acc: 0.741948 train_f1: 0.741948 time: 1.3961s
INFO:root:Epoch: 0350 val_loss: 1.067782 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0360 lr: [0.00025, 0.00025] train_loss: 0.886885 train_acc: 0.826002 train_f1: 0.826002 time: 1.4050s
INFO:root:Epoch: 0360 val_loss: 1.074514 val_acc: 0.683150 val_f1: 0.683150
INFO:root:Epoch: 0370 lr: [0.00025, 0.00025] train_loss: 0.854797 train_acc: 0.790652 train_f1: 0.790652 time: 1.4004s
INFO:root:Epoch: 0370 val_loss: 1.067393 val_acc: 0.699634 val_f1: 0.699634
INFO:root:Epoch: 0380 lr: [0.00025, 0.00025] train_loss: 0.862614 train_acc: 0.754124 train_f1: 0.754124 time: 1.3969s
INFO:root:Epoch: 0380 val_loss: 1.068064 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0390 lr: [0.00025, 0.00025] train_loss: 0.858065 train_acc: 0.828751 train_f1: 0.828751 time: 1.4013s
INFO:root:Epoch: 0390 val_loss: 1.071917 val_acc: 0.681319 val_f1: 0.681319
INFO:root:Epoch: 0400 lr: [0.00025, 0.00025] train_loss: 0.843406 train_acc: 0.781618 train_f1: 0.781618 time: 1.3955s
INFO:root:Epoch: 0400 val_loss: 1.070523 val_acc: 0.679487 val_f1: 0.679487
INFO:root:Epoch: 0410 lr: [0.00025, 0.00025] train_loss: 0.854953 train_acc: 0.831893 train_f1: 0.831893 time: 1.3937s
INFO:root:Epoch: 0410 val_loss: 1.066883 val_acc: 0.686813 val_f1: 0.686813
INFO:root:Epoch: 0420 lr: [0.00025, 0.00025] train_loss: 0.854274 train_acc: 0.807934 train_f1: 0.807934 time: 1.3973s
INFO:root:Epoch: 0420 val_loss: 1.092040 val_acc: 0.663004 val_f1: 0.663004
INFO:root:Epoch: 0430 lr: [0.00025, 0.00025] train_loss: 0.845686 train_acc: 0.818932 train_f1: 0.818932 time: 1.4215s
INFO:root:Epoch: 0430 val_loss: 1.065915 val_acc: 0.694139 val_f1: 0.694139
INFO:root:Epoch: 0440 lr: [0.00025, 0.00025] train_loss: 0.844880 train_acc: 0.765122 train_f1: 0.765122 time: 1.4031s
INFO:root:Epoch: 0440 val_loss: 1.070985 val_acc: 0.681319 val_f1: 0.681319
INFO:root:Epoch: 0450 lr: [0.000125, 0.000125] train_loss: 0.834325 train_acc: 0.829144 train_f1: 0.829144 time: 1.4002s
INFO:root:Epoch: 0450 val_loss: 1.087544 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0460 lr: [0.000125, 0.000125] train_loss: 0.843890 train_acc: 0.742734 train_f1: 0.742734 time: 1.3933s
INFO:root:Epoch: 0460 val_loss: 1.082563 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0470 lr: [0.000125, 0.000125] train_loss: 0.834230 train_acc: 0.789866 train_f1: 0.789866 time: 1.3978s
INFO:root:Epoch: 0470 val_loss: 1.083518 val_acc: 0.688645 val_f1: 0.688645
INFO:root:Epoch: 0480 lr: [0.000125, 0.000125] train_loss: 0.834717 train_acc: 0.782404 train_f1: 0.782404 time: 1.3961s
INFO:root:Epoch: 0480 val_loss: 1.089133 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0490 lr: [0.000125, 0.000125] train_loss: 0.821983 train_acc: 0.791830 train_f1: 0.791830 time: 1.3962s
INFO:root:Epoch: 0490 val_loss: 1.078588 val_acc: 0.684982 val_f1: 0.684982
INFO:root:Epoch: 0500 lr: [0.000125, 0.000125] train_loss: 0.807662 train_acc: 0.838178 train_f1: 0.838178 time: 1.3901s
INFO:root:Epoch: 0500 val_loss: 1.091924 val_acc: 0.681319 val_f1: 0.681319
INFO:root:Epoch: 0510 lr: [0.000125, 0.000125] train_loss: 0.796533 train_acc: 0.738413 train_f1: 0.738413 time: 1.3955s
INFO:root:Epoch: 0510 val_loss: 1.099057 val_acc: 0.686813 val_f1: 0.686813
INFO:root:Epoch: 0520 lr: [0.000125, 0.000125] train_loss: 0.776785 train_acc: 0.835035 train_f1: 0.835035 time: 1.3892s
INFO:root:Epoch: 0520 val_loss: 1.095809 val_acc: 0.686813 val_f1: 0.686813
INFO:root:Epoch: 0530 lr: [0.000125, 0.000125] train_loss: 0.770808 train_acc: 0.840141 train_f1: 0.840141 time: 1.3896s
INFO:root:Epoch: 0530 val_loss: 1.125140 val_acc: 0.679487 val_f1: 0.679487
INFO:root:Epoch: 0540 lr: [0.000125, 0.000125] train_loss: 0.793121 train_acc: 0.854281 train_f1: 0.854281 time: 1.4083s
INFO:root:Epoch: 0540 val_loss: 1.110031 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0550 lr: [0.000125, 0.000125] train_loss: 0.771928 train_acc: 0.819717 train_f1: 0.819717 time: 1.3977s
INFO:root:Epoch: 0550 val_loss: 1.101718 val_acc: 0.699634 val_f1: 0.699634
INFO:root:Epoch: 0560 lr: [0.000125, 0.000125] train_loss: 0.758398 train_acc: 0.924195 train_f1: 0.924195 time: 1.3957s
INFO:root:Epoch: 0560 val_loss: 1.120486 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0570 lr: [0.000125, 0.000125] train_loss: 0.796583 train_acc: 0.846033 train_f1: 0.846033 time: 1.3932s
INFO:root:Epoch: 0570 val_loss: 1.134995 val_acc: 0.730769 val_f1: 0.730769
INFO:root:Epoch: 0580 lr: [0.000125, 0.000125] train_loss: 0.746151 train_acc: 0.959544 train_f1: 0.959544 time: 1.3985s
INFO:root:Epoch: 0580 val_loss: 1.135631 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0590 lr: [0.000125, 0.000125] train_loss: 0.739033 train_acc: 0.964258 train_f1: 0.964258 time: 1.3947s
INFO:root:Epoch: 0590 val_loss: 1.124578 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0600 lr: [6.25e-05, 6.25e-05] train_loss: 0.733545 train_acc: 0.972506 train_f1: 0.972506 time: 1.3915s
INFO:root:Epoch: 0600 val_loss: 1.125777 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0610 lr: [6.25e-05, 6.25e-05] train_loss: 0.728380 train_acc: 0.949332 train_f1: 0.949332 time: 1.3928s
INFO:root:Epoch: 0610 val_loss: 1.123571 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0620 lr: [6.25e-05, 6.25e-05] train_loss: 0.730641 train_acc: 0.936764 train_f1: 0.936764 time: 1.4019s
INFO:root:Epoch: 0620 val_loss: 1.135391 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0630 lr: [6.25e-05, 6.25e-05] train_loss: 0.725921 train_acc: 0.950903 train_f1: 0.950903 time: 1.3966s
INFO:root:Epoch: 0630 val_loss: 1.132298 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0640 lr: [6.25e-05, 6.25e-05] train_loss: 0.752900 train_acc: 0.861744 train_f1: 0.861744 time: 1.3958s
INFO:root:Epoch: 0640 val_loss: 1.147342 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0650 lr: [6.25e-05, 6.25e-05] train_loss: 0.734004 train_acc: 0.977219 train_f1: 0.977219 time: 1.4040s
INFO:root:Epoch: 0650 val_loss: 1.153970 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0660 lr: [6.25e-05, 6.25e-05] train_loss: 0.717424 train_acc: 0.946976 train_f1: 0.946976 time: 1.3915s
INFO:root:Epoch: 0660 val_loss: 1.153428 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0670 lr: [6.25e-05, 6.25e-05] train_loss: 0.714646 train_acc: 0.972113 train_f1: 0.972113 time: 1.3927s
INFO:root:Epoch: 0670 val_loss: 1.138504 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0680 lr: [6.25e-05, 6.25e-05] train_loss: 0.718003 train_acc: 0.975255 train_f1: 0.975255 time: 1.3903s
INFO:root:Epoch: 0680 val_loss: 1.146224 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0690 lr: [6.25e-05, 6.25e-05] train_loss: 0.720373 train_acc: 0.962687 train_f1: 0.962687 time: 1.4026s
INFO:root:Epoch: 0690 val_loss: 1.151539 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0700 lr: [6.25e-05, 6.25e-05] train_loss: 0.735402 train_acc: 0.882168 train_f1: 0.882168 time: 1.3991s
INFO:root:Epoch: 0700 val_loss: 1.123140 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0710 lr: [6.25e-05, 6.25e-05] train_loss: 0.716320 train_acc: 0.976434 train_f1: 0.976434 time: 1.3904s
INFO:root:Epoch: 0710 val_loss: 1.135327 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0720 lr: [6.25e-05, 6.25e-05] train_loss: 0.712270 train_acc: 0.972899 train_f1: 0.972899 time: 1.3989s
INFO:root:Epoch: 0720 val_loss: 1.162885 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0730 lr: [6.25e-05, 6.25e-05] train_loss: 0.709458 train_acc: 0.972506 train_f1: 0.972506 time: 1.3947s
INFO:root:Epoch: 0730 val_loss: 1.155748 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0740 lr: [6.25e-05, 6.25e-05] train_loss: 0.728711 train_acc: 0.877848 train_f1: 0.877848 time: 1.3980s
INFO:root:Epoch: 0740 val_loss: 1.162520 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0750 lr: [3.125e-05, 3.125e-05] train_loss: 0.708747 train_acc: 0.976826 train_f1: 0.976826 time: 1.3913s
INFO:root:Epoch: 0750 val_loss: 1.152757 val_acc: 0.749084 val_f1: 0.749084
INFO:root:Epoch: 0760 lr: [3.125e-05, 3.125e-05] train_loss: 0.724810 train_acc: 0.977219 train_f1: 0.977219 time: 1.3913s
INFO:root:Epoch: 0760 val_loss: 1.151012 val_acc: 0.747253 val_f1: 0.747253
INFO:root:Epoch: 0770 lr: [3.125e-05, 3.125e-05] train_loss: 0.705452 train_acc: 0.970542 train_f1: 0.970542 time: 1.3986s
INFO:root:Epoch: 0770 val_loss: 1.155696 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0780 lr: [3.125e-05, 3.125e-05] train_loss: 0.712053 train_acc: 0.977219 train_f1: 0.977219 time: 1.3996s
INFO:root:Epoch: 0780 val_loss: 1.163762 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0790 lr: [3.125e-05, 3.125e-05] train_loss: 0.703580 train_acc: 0.973291 train_f1: 0.973291 time: 1.3918s
INFO:root:Epoch: 0790 val_loss: 1.166669 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0800 lr: [3.125e-05, 3.125e-05] train_loss: 0.711021 train_acc: 0.968578 train_f1: 0.968578 time: 1.3930s
INFO:root:Epoch: 0800 val_loss: 1.166983 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0810 lr: [3.125e-05, 3.125e-05] train_loss: 0.702531 train_acc: 0.949332 train_f1: 0.949332 time: 1.3963s
INFO:root:Epoch: 0810 val_loss: 1.161963 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0820 lr: [3.125e-05, 3.125e-05] train_loss: 0.703469 train_acc: 0.980361 train_f1: 0.980361 time: 1.3968s
INFO:root:Epoch: 0820 val_loss: 1.168079 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0830 lr: [3.125e-05, 3.125e-05] train_loss: 0.697471 train_acc: 0.981147 train_f1: 0.981147 time: 1.4009s
INFO:root:Epoch: 0830 val_loss: 1.172589 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0840 lr: [3.125e-05, 3.125e-05] train_loss: 0.704524 train_acc: 0.982325 train_f1: 0.982325 time: 1.4009s
INFO:root:Epoch: 0840 val_loss: 1.169644 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0850 lr: [3.125e-05, 3.125e-05] train_loss: 0.707667 train_acc: 0.981540 train_f1: 0.981540 time: 1.3942s
INFO:root:Epoch: 0850 val_loss: 1.147014 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0860 lr: [3.125e-05, 3.125e-05] train_loss: 0.709998 train_acc: 0.983111 train_f1: 0.983111 time: 1.3943s
INFO:root:Epoch: 0860 val_loss: 1.141115 val_acc: 0.749084 val_f1: 0.749084
INFO:root:Epoch: 0870 lr: [3.125e-05, 3.125e-05] train_loss: 0.730506 train_acc: 0.886096 train_f1: 0.886096 time: 1.3983s
INFO:root:Epoch: 0870 val_loss: 1.156896 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0880 lr: [3.125e-05, 3.125e-05] train_loss: 0.700124 train_acc: 0.980361 train_f1: 0.980361 time: 1.4008s
INFO:root:Epoch: 0880 val_loss: 1.153967 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0890 lr: [3.125e-05, 3.125e-05] train_loss: 0.698244 train_acc: 0.979969 train_f1: 0.979969 time: 1.3956s
INFO:root:Epoch: 0890 val_loss: 1.164263 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0900 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.704059 train_acc: 0.983111 train_f1: 0.983111 time: 1.3969s
INFO:root:Epoch: 0900 val_loss: 1.174959 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0910 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.698183 train_acc: 0.974077 train_f1: 0.974077 time: 1.3950s
INFO:root:Epoch: 0910 val_loss: 1.177096 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0920 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.699925 train_acc: 0.979969 train_f1: 0.979969 time: 1.3952s
INFO:root:Epoch: 0920 val_loss: 1.174538 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0930 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.701633 train_acc: 0.983504 train_f1: 0.983504 time: 1.3990s
INFO:root:Epoch: 0930 val_loss: 1.167855 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0940 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.694918 train_acc: 0.982718 train_f1: 0.982718 time: 1.4014s
INFO:root:Epoch: 0940 val_loss: 1.170655 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0950 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.709195 train_acc: 0.899843 train_f1: 0.899843 time: 1.3981s
INFO:root:Epoch: 0950 val_loss: 1.172396 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0960 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.706656 train_acc: 0.977612 train_f1: 0.977612 time: 1.3970s
INFO:root:Epoch: 0960 val_loss: 1.178165 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0970 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.704015 train_acc: 0.982718 train_f1: 0.982718 time: 1.3959s
INFO:root:Epoch: 0970 val_loss: 1.176493 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0980 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.701813 train_acc: 0.971328 train_f1: 0.971328 time: 1.3969s
INFO:root:Epoch: 0980 val_loss: 1.171487 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0990 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.735712 train_acc: 0.868421 train_f1: 0.868421 time: 1.4030s
INFO:root:Epoch: 0990 val_loss: 1.173639 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 1000 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.722712 train_acc: 0.873134 train_f1: 0.873134 time: 1.3981s
INFO:root:Epoch: 1000 val_loss: 1.177025 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1010 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.703346 train_acc: 0.979969 train_f1: 0.979969 time: 1.4001s
INFO:root:Epoch: 1010 val_loss: 1.176745 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 1020 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.699251 train_acc: 0.979969 train_f1: 0.979969 time: 1.3993s
INFO:root:Epoch: 1020 val_loss: 1.177601 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 1030 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.702529 train_acc: 0.972506 train_f1: 0.972506 time: 1.3934s
INFO:root:Epoch: 1030 val_loss: 1.177076 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 1040 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.695194 train_acc: 0.983504 train_f1: 0.983504 time: 1.3952s
INFO:root:Epoch: 1040 val_loss: 1.166966 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 1050 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.710224 train_acc: 0.981540 train_f1: 0.981540 time: 1.3979s
INFO:root:Epoch: 1050 val_loss: 1.164370 val_acc: 0.747253 val_f1: 0.747253
INFO:root:Epoch: 1060 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.699140 train_acc: 0.983504 train_f1: 0.983504 time: 1.3974s
INFO:root:Epoch: 1060 val_loss: 1.162732 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 1070 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.716994 train_acc: 0.917910 train_f1: 0.917910 time: 1.4027s
INFO:root:Epoch: 1070 val_loss: 1.163739 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 1080 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.694571 train_acc: 0.982325 train_f1: 0.982325 time: 1.3895s
INFO:root:Epoch: 1080 val_loss: 1.166472 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1090 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.708855 train_acc: 0.979576 train_f1: 0.979576 time: 1.3940s
INFO:root:Epoch: 1090 val_loss: 1.169979 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1100 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.700222 train_acc: 0.978397 train_f1: 0.978397 time: 1.3959s
INFO:root:Epoch: 1100 val_loss: 1.171953 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1110 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.695390 train_acc: 0.981147 train_f1: 0.981147 time: 1.3969s
INFO:root:Epoch: 1110 val_loss: 1.171588 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 1120 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.702269 train_acc: 0.977612 train_f1: 0.977612 time: 1.3936s
INFO:root:Epoch: 1120 val_loss: 1.169742 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1130 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.693340 train_acc: 0.981540 train_f1: 0.981540 time: 1.3945s
INFO:root:Epoch: 1130 val_loss: 1.168148 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1140 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.692191 train_acc: 0.981932 train_f1: 0.981932 time: 1.4004s
INFO:root:Epoch: 1140 val_loss: 1.167985 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1150 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.694387 train_acc: 0.980361 train_f1: 0.980361 time: 1.3952s
INFO:root:Epoch: 1150 val_loss: 1.170347 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1160 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.692674 train_acc: 0.980361 train_f1: 0.980361 time: 1.3917s
INFO:root:Epoch: 1160 val_loss: 1.169782 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1170 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.704647 train_acc: 0.973291 train_f1: 0.973291 time: 1.3935s
INFO:root:Epoch: 1170 val_loss: 1.174225 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1180 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.693159 train_acc: 0.979183 train_f1: 0.979183 time: 1.3952s
INFO:root:Epoch: 1180 val_loss: 1.176219 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 1190 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.692730 train_acc: 0.980361 train_f1: 0.980361 time: 1.3971s
INFO:root:Epoch: 1190 val_loss: 1.178031 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 1200 lr: [3.90625e-06, 3.90625e-06] train_loss: 0.698472 train_acc: 0.980754 train_f1: 0.980754 time: 1.3953s
INFO:root:Epoch: 1200 val_loss: 1.178814 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1210 lr: [3.90625e-06, 3.90625e-06] train_loss: 0.687583 train_acc: 0.980754 train_f1: 0.980754 time: 1.4035s
INFO:root:Epoch: 1210 val_loss: 1.179223 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1220 lr: [3.90625e-06, 3.90625e-06] train_loss: 0.699044 train_acc: 0.968971 train_f1: 0.968971 time: 1.4015s
INFO:root:Epoch: 1220 val_loss: 1.180076 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1230 lr: [3.90625e-06, 3.90625e-06] train_loss: 0.694080 train_acc: 0.976041 train_f1: 0.976041 time: 1.3903s
INFO:root:Epoch: 1230 val_loss: 1.179436 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1240 lr: [3.90625e-06, 3.90625e-06] train_loss: 0.707245 train_acc: 0.977612 train_f1: 0.977612 time: 1.3936s
INFO:root:Epoch: 1240 val_loss: 1.176125 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 1250 lr: [3.90625e-06, 3.90625e-06] train_loss: 0.693035 train_acc: 0.981147 train_f1: 0.981147 time: 1.3986s
INFO:root:Epoch: 1250 val_loss: 1.174632 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1786.9821s
INFO:root:Val set results: val_loss: 1.152757 val_acc: 0.749084 val_f1: 0.749084
INFO:root:Test set results: test_loss: 1.136419 test_acc: 0.767399 test_f1: 0.767399
