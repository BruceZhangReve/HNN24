INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: chameleon
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=2325, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f577f82b6d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f577f82b6d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f577f82b6d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f577f82b6d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (2): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f577f82b6d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f577f82b6d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 212061
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.520688 train_acc: 0.326787 train_f1: 0.326787 time: 1.3949s
INFO:root:Epoch: 0010 val_loss: 1.496353 val_acc: 0.347985 val_f1: 0.347985
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.437371 train_acc: 0.382561 train_f1: 0.382561 time: 1.4034s
INFO:root:Epoch: 0020 val_loss: 1.398595 val_acc: 0.465201 val_f1: 0.465201
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.291160 train_acc: 0.478790 train_f1: 0.478790 time: 1.3942s
INFO:root:Epoch: 0030 val_loss: 1.349930 val_acc: 0.452381 val_f1: 0.452381
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.220325 train_acc: 0.504321 train_f1: 0.504321 time: 1.3943s
INFO:root:Epoch: 0040 val_loss: 1.297954 val_acc: 0.529304 val_f1: 0.529304
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.165350 train_acc: 0.520817 train_f1: 0.520817 time: 1.3947s
INFO:root:Epoch: 0050 val_loss: 1.264992 val_acc: 0.571429 val_f1: 0.571429
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.105317 train_acc: 0.621760 train_f1: 0.621760 time: 1.4009s
INFO:root:Epoch: 0060 val_loss: 1.230652 val_acc: 0.602564 val_f1: 0.602564
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.087286 train_acc: 0.701493 train_f1: 0.701493 time: 1.4699s
INFO:root:Epoch: 0070 val_loss: 1.208872 val_acc: 0.617216 val_f1: 0.617216
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.041065 train_acc: 0.717596 train_f1: 0.717596 time: 1.4021s
INFO:root:Epoch: 0080 val_loss: 1.188530 val_acc: 0.630037 val_f1: 0.630037
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.025445 train_acc: 0.687745 train_f1: 0.687745 time: 1.3967s
INFO:root:Epoch: 0090 val_loss: 1.183067 val_acc: 0.628205 val_f1: 0.628205
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 0.994892 train_acc: 0.723488 train_f1: 0.723488 time: 1.4006s
INFO:root:Epoch: 0100 val_loss: 1.172761 val_acc: 0.622711 val_f1: 0.622711
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.999050 train_acc: 0.720738 train_f1: 0.720738 time: 1.3913s
INFO:root:Epoch: 0110 val_loss: 1.197641 val_acc: 0.611722 val_f1: 0.611722
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.978771 train_acc: 0.711312 train_f1: 0.711312 time: 1.3957s
INFO:root:Epoch: 0120 val_loss: 1.180228 val_acc: 0.620879 val_f1: 0.620879
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.973760 train_acc: 0.716418 train_f1: 0.716418 time: 1.3934s
INFO:root:Epoch: 0130 val_loss: 1.161458 val_acc: 0.622711 val_f1: 0.622711
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.982090 train_acc: 0.721524 train_f1: 0.721524 time: 1.3983s
INFO:root:Epoch: 0140 val_loss: 1.156106 val_acc: 0.635531 val_f1: 0.635531
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.968883 train_acc: 0.726237 train_f1: 0.726237 time: 1.3912s
INFO:root:Epoch: 0150 val_loss: 1.147948 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.960390 train_acc: 0.709741 train_f1: 0.709741 time: 1.3934s
INFO:root:Epoch: 0160 val_loss: 1.155091 val_acc: 0.637363 val_f1: 0.637363
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.956255 train_acc: 0.726630 train_f1: 0.726630 time: 1.3991s
INFO:root:Epoch: 0170 val_loss: 1.142121 val_acc: 0.633700 val_f1: 0.633700
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.948397 train_acc: 0.698350 train_f1: 0.698350 time: 1.3953s
INFO:root:Epoch: 0180 val_loss: 1.136806 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.930054 train_acc: 0.717596 train_f1: 0.717596 time: 1.3936s
INFO:root:Epoch: 0190 val_loss: 1.136455 val_acc: 0.644689 val_f1: 0.644689
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 0.956276 train_acc: 0.545562 train_f1: 0.545562 time: 1.3958s
INFO:root:Epoch: 0200 val_loss: 1.136715 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 0.935233 train_acc: 0.734485 train_f1: 0.734485 time: 1.3904s
INFO:root:Epoch: 0210 val_loss: 1.122664 val_acc: 0.655678 val_f1: 0.655678
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 0.927122 train_acc: 0.732129 train_f1: 0.732129 time: 1.3946s
INFO:root:Epoch: 0220 val_loss: 1.126321 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 0.927325 train_acc: 0.732129 train_f1: 0.732129 time: 1.3984s
INFO:root:Epoch: 0230 val_loss: 1.123213 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 0.922147 train_acc: 0.733307 train_f1: 0.733307 time: 1.3971s
INFO:root:Epoch: 0240 val_loss: 1.121216 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.922532 train_acc: 0.734093 train_f1: 0.734093 time: 1.3969s
INFO:root:Epoch: 0250 val_loss: 1.126731 val_acc: 0.642857 val_f1: 0.642857
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.923735 train_acc: 0.693637 train_f1: 0.693637 time: 1.3973s
INFO:root:Epoch: 0260 val_loss: 1.124102 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.913731 train_acc: 0.734878 train_f1: 0.734878 time: 1.3938s
INFO:root:Epoch: 0270 val_loss: 1.118248 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.915327 train_acc: 0.734093 train_f1: 0.734093 time: 1.3895s
INFO:root:Epoch: 0280 val_loss: 1.117698 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.909329 train_acc: 0.729379 train_f1: 0.729379 time: 1.3936s
INFO:root:Epoch: 0290 val_loss: 1.123036 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0300 lr: [0.00025, 0.00025] train_loss: 0.912551 train_acc: 0.734878 train_f1: 0.734878 time: 1.3978s
INFO:root:Epoch: 0300 val_loss: 1.123258 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0310 lr: [0.00025, 0.00025] train_loss: 0.910294 train_acc: 0.733700 train_f1: 0.733700 time: 1.3909s
INFO:root:Epoch: 0310 val_loss: 1.125604 val_acc: 0.655678 val_f1: 0.655678
INFO:root:Epoch: 0320 lr: [0.00025, 0.00025] train_loss: 0.907856 train_acc: 0.734878 train_f1: 0.734878 time: 1.3939s
INFO:root:Epoch: 0320 val_loss: 1.120818 val_acc: 0.655678 val_f1: 0.655678
INFO:root:Epoch: 0330 lr: [0.00025, 0.00025] train_loss: 0.915824 train_acc: 0.734093 train_f1: 0.734093 time: 1.3957s
INFO:root:Epoch: 0330 val_loss: 1.117020 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0340 lr: [0.00025, 0.00025] train_loss: 0.901982 train_acc: 0.728987 train_f1: 0.728987 time: 1.3975s
INFO:root:Epoch: 0340 val_loss: 1.118248 val_acc: 0.655678 val_f1: 0.655678
INFO:root:Epoch: 0350 lr: [0.00025, 0.00025] train_loss: 0.916592 train_acc: 0.734485 train_f1: 0.734485 time: 1.3970s
INFO:root:Epoch: 0350 val_loss: 1.115318 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0360 lr: [0.00025, 0.00025] train_loss: 0.912727 train_acc: 0.728201 train_f1: 0.728201 time: 1.3976s
INFO:root:Epoch: 0360 val_loss: 1.124640 val_acc: 0.641026 val_f1: 0.641026
INFO:root:Epoch: 0370 lr: [0.00025, 0.00025] train_loss: 0.909720 train_acc: 0.727808 train_f1: 0.727808 time: 1.4009s
INFO:root:Epoch: 0370 val_loss: 1.120346 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0380 lr: [0.00025, 0.00025] train_loss: 0.892778 train_acc: 0.734878 train_f1: 0.734878 time: 1.3908s
INFO:root:Epoch: 0380 val_loss: 1.111527 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0390 lr: [0.00025, 0.00025] train_loss: 0.890117 train_acc: 0.732914 train_f1: 0.732914 time: 1.3943s
INFO:root:Epoch: 0390 val_loss: 1.097107 val_acc: 0.655678 val_f1: 0.655678
INFO:root:Epoch: 0400 lr: [0.00025, 0.00025] train_loss: 0.905143 train_acc: 0.684211 train_f1: 0.684211 time: 1.4002s
INFO:root:Epoch: 0400 val_loss: 1.098458 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0410 lr: [0.00025, 0.00025] train_loss: 0.866253 train_acc: 0.839356 train_f1: 0.839356 time: 1.3898s
INFO:root:Epoch: 0410 val_loss: 1.101047 val_acc: 0.690476 val_f1: 0.690476
INFO:root:Epoch: 0420 lr: [0.00025, 0.00025] train_loss: 0.858788 train_acc: 0.839749 train_f1: 0.839749 time: 1.3989s
INFO:root:Epoch: 0420 val_loss: 1.111269 val_acc: 0.688645 val_f1: 0.688645
INFO:root:Epoch: 0430 lr: [0.00025, 0.00025] train_loss: 0.857622 train_acc: 0.839356 train_f1: 0.839356 time: 1.4281s
INFO:root:Epoch: 0430 val_loss: 1.117272 val_acc: 0.686813 val_f1: 0.686813
INFO:root:Epoch: 0440 lr: [0.00025, 0.00025] train_loss: 0.910860 train_acc: 0.822074 train_f1: 0.822074 time: 1.4020s
INFO:root:Epoch: 0440 val_loss: 1.119826 val_acc: 0.694139 val_f1: 0.694139
INFO:root:Epoch: 0450 lr: [0.000125, 0.000125] train_loss: 0.848397 train_acc: 0.848390 train_f1: 0.848390 time: 1.3978s
INFO:root:Epoch: 0450 val_loss: 1.097899 val_acc: 0.692308 val_f1: 0.692308
INFO:root:Epoch: 0460 lr: [0.000125, 0.000125] train_loss: 0.834008 train_acc: 0.846033 train_f1: 0.846033 time: 1.4002s
INFO:root:Epoch: 0460 val_loss: 1.127318 val_acc: 0.694139 val_f1: 0.694139
INFO:root:Epoch: 0470 lr: [0.000125, 0.000125] train_loss: 0.818840 train_acc: 0.849568 train_f1: 0.849568 time: 1.3973s
INFO:root:Epoch: 0470 val_loss: 1.113371 val_acc: 0.699634 val_f1: 0.699634
INFO:root:Epoch: 0480 lr: [0.000125, 0.000125] train_loss: 0.834820 train_acc: 0.850746 train_f1: 0.850746 time: 1.3969s
INFO:root:Epoch: 0480 val_loss: 1.095840 val_acc: 0.688645 val_f1: 0.688645
INFO:root:Epoch: 0490 lr: [0.000125, 0.000125] train_loss: 0.812777 train_acc: 0.648861 train_f1: 0.648861 time: 1.3983s
INFO:root:Epoch: 0490 val_loss: 1.094965 val_acc: 0.686813 val_f1: 0.686813
INFO:root:Epoch: 0500 lr: [0.000125, 0.000125] train_loss: 0.878238 train_acc: 0.725452 train_f1: 0.725452 time: 1.3996s
INFO:root:Epoch: 0500 val_loss: 1.104008 val_acc: 0.697802 val_f1: 0.697802
INFO:root:Epoch: 0510 lr: [0.000125, 0.000125] train_loss: 0.816311 train_acc: 0.847604 train_f1: 0.847604 time: 1.4006s
INFO:root:Epoch: 0510 val_loss: 1.094495 val_acc: 0.728938 val_f1: 0.728938
INFO:root:Epoch: 0520 lr: [0.000125, 0.000125] train_loss: 0.821611 train_acc: 0.916339 train_f1: 0.916339 time: 1.3982s
INFO:root:Epoch: 0520 val_loss: 1.114028 val_acc: 0.732601 val_f1: 0.732601
INFO:root:Epoch: 0530 lr: [0.000125, 0.000125] train_loss: 0.804640 train_acc: 0.895915 train_f1: 0.895915 time: 1.3915s
INFO:root:Epoch: 0530 val_loss: 1.128095 val_acc: 0.716117 val_f1: 0.716117
INFO:root:Epoch: 0540 lr: [0.000125, 0.000125] train_loss: 0.811276 train_acc: 0.938335 train_f1: 0.938335 time: 1.3994s
INFO:root:Epoch: 0540 val_loss: 1.121112 val_acc: 0.732601 val_f1: 0.732601
INFO:root:Epoch: 0550 lr: [0.000125, 0.000125] train_loss: 0.825506 train_acc: 0.886881 train_f1: 0.886881 time: 1.3963s
INFO:root:Epoch: 0550 val_loss: 1.102545 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0560 lr: [0.000125, 0.000125] train_loss: 0.789967 train_acc: 0.897093 train_f1: 0.897093 time: 1.3953s
INFO:root:Epoch: 0560 val_loss: 1.116784 val_acc: 0.723443 val_f1: 0.723443
INFO:root:Epoch: 0570 lr: [0.000125, 0.000125] train_loss: 0.793266 train_acc: 0.898272 train_f1: 0.898272 time: 1.3988s
INFO:root:Epoch: 0570 val_loss: 1.112380 val_acc: 0.734432 val_f1: 0.734432
INFO:root:Epoch: 0580 lr: [0.000125, 0.000125] train_loss: 0.792772 train_acc: 0.902200 train_f1: 0.902200 time: 1.3987s
INFO:root:Epoch: 0580 val_loss: 1.112994 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0590 lr: [0.000125, 0.000125] train_loss: 0.794384 train_acc: 0.904163 train_f1: 0.904163 time: 1.4016s
INFO:root:Epoch: 0590 val_loss: 1.097777 val_acc: 0.725275 val_f1: 0.725275
INFO:root:Epoch: 0600 lr: [6.25e-05, 6.25e-05] train_loss: 0.784723 train_acc: 0.933229 train_f1: 0.933229 time: 1.3953s
INFO:root:Epoch: 0600 val_loss: 1.109895 val_acc: 0.734432 val_f1: 0.734432
INFO:root:Epoch: 0610 lr: [6.25e-05, 6.25e-05] train_loss: 0.780080 train_acc: 0.950511 train_f1: 0.950511 time: 1.3994s
INFO:root:Epoch: 0610 val_loss: 1.107797 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0620 lr: [6.25e-05, 6.25e-05] train_loss: 0.795317 train_acc: 0.901414 train_f1: 0.901414 time: 1.3950s
INFO:root:Epoch: 0620 val_loss: 1.112340 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0630 lr: [6.25e-05, 6.25e-05] train_loss: 0.821409 train_acc: 0.838570 train_f1: 0.838570 time: 1.3937s
INFO:root:Epoch: 0630 val_loss: 1.104505 val_acc: 0.739927 val_f1: 0.739927
INFO:root:Epoch: 0640 lr: [6.25e-05, 6.25e-05] train_loss: 0.801802 train_acc: 0.900236 train_f1: 0.900236 time: 1.4065s
INFO:root:Epoch: 0640 val_loss: 1.114429 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0650 lr: [6.25e-05, 6.25e-05] train_loss: 0.787700 train_acc: 0.902592 train_f1: 0.902592 time: 1.3960s
INFO:root:Epoch: 0650 val_loss: 1.123112 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0660 lr: [6.25e-05, 6.25e-05] train_loss: 0.782135 train_acc: 0.941477 train_f1: 0.941477 time: 1.3971s
INFO:root:Epoch: 0660 val_loss: 1.107339 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0670 lr: [6.25e-05, 6.25e-05] train_loss: 0.829439 train_acc: 0.699921 train_f1: 0.699921 time: 1.3982s
INFO:root:Epoch: 0670 val_loss: 1.115196 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0680 lr: [6.25e-05, 6.25e-05] train_loss: 0.773218 train_acc: 0.904163 train_f1: 0.904163 time: 1.3907s
INFO:root:Epoch: 0680 val_loss: 1.122472 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0690 lr: [6.25e-05, 6.25e-05] train_loss: 0.770724 train_acc: 0.933229 train_f1: 0.933229 time: 1.4018s
INFO:root:Epoch: 0690 val_loss: 1.122713 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0700 lr: [6.25e-05, 6.25e-05] train_loss: 0.772816 train_acc: 0.955224 train_f1: 0.955224 time: 1.3958s
INFO:root:Epoch: 0700 val_loss: 1.127863 val_acc: 0.741758 val_f1: 0.741758
INFO:root:Epoch: 0710 lr: [6.25e-05, 6.25e-05] train_loss: 0.803171 train_acc: 0.937156 train_f1: 0.937156 time: 1.3986s
INFO:root:Epoch: 0710 val_loss: 1.131120 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0720 lr: [6.25e-05, 6.25e-05] train_loss: 0.788519 train_acc: 0.881383 train_f1: 0.881383 time: 1.4017s
INFO:root:Epoch: 0720 val_loss: 1.124246 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0730 lr: [6.25e-05, 6.25e-05] train_loss: 0.753360 train_acc: 0.931265 train_f1: 0.931265 time: 1.3989s
INFO:root:Epoch: 0730 val_loss: 1.123968 val_acc: 0.725275 val_f1: 0.725275
INFO:root:Epoch: 0740 lr: [6.25e-05, 6.25e-05] train_loss: 0.770377 train_acc: 0.923802 train_f1: 0.923802 time: 1.3913s
INFO:root:Epoch: 0740 val_loss: 1.133019 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0750 lr: [3.125e-05, 3.125e-05] train_loss: 0.764529 train_acc: 0.921053 train_f1: 0.921053 time: 1.3927s
INFO:root:Epoch: 0750 val_loss: 1.136877 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0760 lr: [3.125e-05, 3.125e-05] train_loss: 0.774745 train_acc: 0.938727 train_f1: 0.938727 time: 1.3996s
INFO:root:Epoch: 0760 val_loss: 1.132839 val_acc: 0.749084 val_f1: 0.749084
INFO:root:Epoch: 0770 lr: [3.125e-05, 3.125e-05] train_loss: 0.764894 train_acc: 0.930479 train_f1: 0.930479 time: 1.4005s
INFO:root:Epoch: 0770 val_loss: 1.136095 val_acc: 0.749084 val_f1: 0.749084
INFO:root:Epoch: 0780 lr: [3.125e-05, 3.125e-05] train_loss: 0.757667 train_acc: 0.903771 train_f1: 0.903771 time: 1.3948s
INFO:root:Epoch: 0780 val_loss: 1.132948 val_acc: 0.747253 val_f1: 0.747253
INFO:root:Epoch: 0790 lr: [3.125e-05, 3.125e-05] train_loss: 0.757180 train_acc: 0.924980 train_f1: 0.924980 time: 1.4007s
INFO:root:Epoch: 0790 val_loss: 1.127298 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0800 lr: [3.125e-05, 3.125e-05] train_loss: 0.757090 train_acc: 0.952474 train_f1: 0.952474 time: 1.3975s
INFO:root:Epoch: 0800 val_loss: 1.120923 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0810 lr: [3.125e-05, 3.125e-05] train_loss: 0.762396 train_acc: 0.956402 train_f1: 0.956402 time: 1.3981s
INFO:root:Epoch: 0810 val_loss: 1.114440 val_acc: 0.736264 val_f1: 0.736264
INFO:root:Epoch: 0820 lr: [3.125e-05, 3.125e-05] train_loss: 0.758129 train_acc: 0.897093 train_f1: 0.897093 time: 1.3970s
INFO:root:Epoch: 0820 val_loss: 1.114884 val_acc: 0.745421 val_f1: 0.745421
INFO:root:Epoch: 0830 lr: [3.125e-05, 3.125e-05] train_loss: 0.759316 train_acc: 0.951689 train_f1: 0.951689 time: 1.3989s
INFO:root:Epoch: 0830 val_loss: 1.123268 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0840 lr: [3.125e-05, 3.125e-05] train_loss: 0.788290 train_acc: 0.878633 train_f1: 0.878633 time: 1.3980s
INFO:root:Epoch: 0840 val_loss: 1.135066 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0850 lr: [3.125e-05, 3.125e-05] train_loss: 0.762680 train_acc: 0.934014 train_f1: 0.934014 time: 1.3986s
INFO:root:Epoch: 0850 val_loss: 1.140449 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0860 lr: [3.125e-05, 3.125e-05] train_loss: 0.770474 train_acc: 0.952867 train_f1: 0.952867 time: 1.4008s
INFO:root:Epoch: 0860 val_loss: 1.134481 val_acc: 0.743590 val_f1: 0.743590
INFO:root:Epoch: 0870 lr: [3.125e-05, 3.125e-05] train_loss: 0.760179 train_acc: 0.816575 train_f1: 0.816575 time: 1.3996s
INFO:root:Epoch: 0870 val_loss: 1.136040 val_acc: 0.738095 val_f1: 0.738095
INFO:root:Epoch: 0880 lr: [3.125e-05, 3.125e-05] train_loss: 0.752638 train_acc: 0.921053 train_f1: 0.921053 time: 1.3948s
INFO:root:Epoch: 0880 val_loss: 1.127637 val_acc: 0.747253 val_f1: 0.747253
INFO:root:Epoch: 0890 lr: [3.125e-05, 3.125e-05] train_loss: 0.776364 train_acc: 0.944226 train_f1: 0.944226 time: 1.3937s
INFO:root:Epoch: 0890 val_loss: 1.129137 val_acc: 0.749084 val_f1: 0.749084
INFO:root:Epoch: 0900 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.802058 train_acc: 0.954831 train_f1: 0.954831 time: 1.3986s
INFO:root:Epoch: 0900 val_loss: 1.135629 val_acc: 0.747253 val_f1: 0.747253
INFO:root:Epoch: 0910 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.756057 train_acc: 0.943833 train_f1: 0.943833 time: 1.4001s
INFO:root:Epoch: 0910 val_loss: 1.132812 val_acc: 0.743590 val_f1: 0.743590
