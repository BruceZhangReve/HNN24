INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: chameleon
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=2325, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fc9d3c776d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fc9d3c776d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fc9d3c776d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fc9d3c776d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 240645
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.561719 train_acc: 0.281225 train_f1: 0.281225 time: 1.0309s
INFO:root:Epoch: 0010 val_loss: 1.537550 val_acc: 0.304029 val_f1: 0.304029
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.558239 train_acc: 0.282011 train_f1: 0.282011 time: 1.0241s
INFO:root:Epoch: 0020 val_loss: 1.536590 val_acc: 0.304029 val_f1: 0.304029
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.549456 train_acc: 0.282011 train_f1: 0.282011 time: 1.0238s
INFO:root:Epoch: 0030 val_loss: 1.545649 val_acc: 0.304029 val_f1: 0.304029
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.527736 train_acc: 0.328358 train_f1: 0.328358 time: 1.0313s
INFO:root:Epoch: 0040 val_loss: 1.533512 val_acc: 0.307692 val_f1: 0.307692
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.458027 train_acc: 0.372349 train_f1: 0.372349 time: 1.0312s
INFO:root:Epoch: 0050 val_loss: 1.547515 val_acc: 0.307692 val_f1: 0.307692
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.388802 train_acc: 0.433229 train_f1: 0.433229 time: 1.0266s
INFO:root:Epoch: 0060 val_loss: 1.475815 val_acc: 0.360806 val_f1: 0.360806
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.341976 train_acc: 0.451689 train_f1: 0.451689 time: 1.0345s
INFO:root:Epoch: 0070 val_loss: 1.429205 val_acc: 0.401099 val_f1: 0.401099
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.347362 train_acc: 0.404163 train_f1: 0.404163 time: 1.0243s
INFO:root:Epoch: 0080 val_loss: 1.333034 val_acc: 0.454212 val_f1: 0.454212
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.162821 train_acc: 0.492930 train_f1: 0.492930 time: 1.0266s
INFO:root:Epoch: 0090 val_loss: 1.249700 val_acc: 0.476190 val_f1: 0.476190
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 1.120736 train_acc: 0.507070 train_f1: 0.507070 time: 1.0285s
INFO:root:Epoch: 0100 val_loss: 1.287135 val_acc: 0.463370 val_f1: 0.463370
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 1.119047 train_acc: 0.505892 train_f1: 0.505892 time: 1.0291s
INFO:root:Epoch: 0110 val_loss: 1.385858 val_acc: 0.434066 val_f1: 0.434066
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 1.096669 train_acc: 0.501964 train_f1: 0.501964 time: 1.0297s
INFO:root:Epoch: 0120 val_loss: 1.223359 val_acc: 0.489011 val_f1: 0.489011
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 1.086130 train_acc: 0.511390 train_f1: 0.511390 time: 1.0264s
INFO:root:Epoch: 0130 val_loss: 1.294241 val_acc: 0.465201 val_f1: 0.465201
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 1.022298 train_acc: 0.515711 train_f1: 0.515711 time: 1.0278s
INFO:root:Epoch: 0140 val_loss: 1.231526 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 1.025099 train_acc: 0.516496 train_f1: 0.516496 time: 1.0308s
INFO:root:Epoch: 0150 val_loss: 1.299879 val_acc: 0.470696 val_f1: 0.470696
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 1.016770 train_acc: 0.516104 train_f1: 0.516104 time: 1.0276s
INFO:root:Epoch: 0160 val_loss: 1.248697 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 0.989715 train_acc: 0.518068 train_f1: 0.518068 time: 1.0238s
INFO:root:Epoch: 0170 val_loss: 1.264408 val_acc: 0.492674 val_f1: 0.492674
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 0.970772 train_acc: 0.518068 train_f1: 0.518068 time: 1.0350s
INFO:root:Epoch: 0180 val_loss: 1.253529 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 0.968350 train_acc: 0.517675 train_f1: 0.517675 time: 1.0250s
INFO:root:Epoch: 0190 val_loss: 1.261332 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0200 lr: [0.001, 0.001] train_loss: 0.969292 train_acc: 0.518853 train_f1: 0.518853 time: 1.0281s
INFO:root:Epoch: 0200 val_loss: 1.294377 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0210 lr: [0.001, 0.001] train_loss: 0.962970 train_acc: 0.518460 train_f1: 0.518460 time: 1.0234s
INFO:root:Epoch: 0210 val_loss: 1.337050 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0220 lr: [0.001, 0.001] train_loss: 0.959759 train_acc: 0.518460 train_f1: 0.518460 time: 1.0279s
INFO:root:Epoch: 0220 val_loss: 1.333572 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0230 lr: [0.001, 0.001] train_loss: 0.954892 train_acc: 0.516889 train_f1: 0.516889 time: 1.0239s
INFO:root:Epoch: 0230 val_loss: 1.332670 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0240 lr: [0.001, 0.001] train_loss: 0.947545 train_acc: 0.519639 train_f1: 0.519639 time: 1.0257s
INFO:root:Epoch: 0240 val_loss: 1.371819 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.941088 train_acc: 0.519639 train_f1: 0.519639 time: 1.0249s
INFO:root:Epoch: 0250 val_loss: 1.349880 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.943453 train_acc: 0.519639 train_f1: 0.519639 time: 1.0273s
INFO:root:Epoch: 0260 val_loss: 1.385127 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.938604 train_acc: 0.520817 train_f1: 0.520817 time: 1.0268s
INFO:root:Epoch: 0270 val_loss: 1.408011 val_acc: 0.481685 val_f1: 0.481685
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.933622 train_acc: 0.520424 train_f1: 0.520424 time: 1.0294s
INFO:root:Epoch: 0280 val_loss: 1.378603 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.932568 train_acc: 0.520817 train_f1: 0.520817 time: 1.0276s
INFO:root:Epoch: 0290 val_loss: 1.374214 val_acc: 0.489011 val_f1: 0.489011
INFO:root:Epoch: 0300 lr: [0.0005, 0.0005] train_loss: 0.941349 train_acc: 0.518853 train_f1: 0.518853 time: 1.0248s
INFO:root:Epoch: 0300 val_loss: 1.395950 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0310 lr: [0.0005, 0.0005] train_loss: 0.939586 train_acc: 0.520031 train_f1: 0.520031 time: 1.0288s
INFO:root:Epoch: 0310 val_loss: 1.399455 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0320 lr: [0.0005, 0.0005] train_loss: 0.932459 train_acc: 0.520424 train_f1: 0.520424 time: 1.0267s
INFO:root:Epoch: 0320 val_loss: 1.415941 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0330 lr: [0.0005, 0.0005] train_loss: 0.926942 train_acc: 0.519639 train_f1: 0.519639 time: 1.0258s
INFO:root:Epoch: 0330 val_loss: 1.436781 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0340 lr: [0.0005, 0.0005] train_loss: 0.922874 train_acc: 0.520424 train_f1: 0.520424 time: 1.0258s
INFO:root:Epoch: 0340 val_loss: 1.442244 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0350 lr: [0.0005, 0.0005] train_loss: 0.925775 train_acc: 0.518068 train_f1: 0.518068 time: 1.0300s
INFO:root:Epoch: 0350 val_loss: 1.449342 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0360 lr: [0.0005, 0.0005] train_loss: 0.925645 train_acc: 0.519246 train_f1: 0.519246 time: 1.0390s
INFO:root:Epoch: 0360 val_loss: 1.456041 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0370 lr: [0.0005, 0.0005] train_loss: 0.924014 train_acc: 0.520031 train_f1: 0.520031 time: 1.0264s
INFO:root:Epoch: 0370 val_loss: 1.465077 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0380 lr: [0.0005, 0.0005] train_loss: 0.933071 train_acc: 0.520424 train_f1: 0.520424 time: 1.0356s
INFO:root:Epoch: 0380 val_loss: 1.473126 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0390 lr: [0.0005, 0.0005] train_loss: 0.917167 train_acc: 0.520031 train_f1: 0.520031 time: 1.0299s
INFO:root:Epoch: 0390 val_loss: 1.481773 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0400 lr: [0.0005, 0.0005] train_loss: 0.919811 train_acc: 0.520424 train_f1: 0.520424 time: 1.0226s
INFO:root:Epoch: 0400 val_loss: 1.480687 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0410 lr: [0.0005, 0.0005] train_loss: 0.918482 train_acc: 0.520817 train_f1: 0.520817 time: 1.0339s
INFO:root:Epoch: 0410 val_loss: 1.477879 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0420 lr: [0.0005, 0.0005] train_loss: 0.934700 train_acc: 0.520817 train_f1: 0.520817 time: 1.0372s
INFO:root:Epoch: 0420 val_loss: 1.476913 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0430 lr: [0.0005, 0.0005] train_loss: 0.923733 train_acc: 0.520817 train_f1: 0.520817 time: 1.0429s
INFO:root:Epoch: 0430 val_loss: 1.478512 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0440 lr: [0.0005, 0.0005] train_loss: 0.926151 train_acc: 0.520424 train_f1: 0.520424 time: 1.0285s
INFO:root:Epoch: 0440 val_loss: 1.493236 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0450 lr: [0.0005, 0.0005] train_loss: 0.919496 train_acc: 0.520817 train_f1: 0.520817 time: 1.0336s
INFO:root:Epoch: 0450 val_loss: 1.516176 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0460 lr: [0.0005, 0.0005] train_loss: 0.913207 train_acc: 0.521210 train_f1: 0.521210 time: 1.0281s
INFO:root:Epoch: 0460 val_loss: 1.532868 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0470 lr: [0.0005, 0.0005] train_loss: 0.912441 train_acc: 0.521603 train_f1: 0.521603 time: 1.0335s
INFO:root:Epoch: 0470 val_loss: 1.499834 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0480 lr: [0.0005, 0.0005] train_loss: 0.920336 train_acc: 0.521210 train_f1: 0.521210 time: 1.0257s
INFO:root:Epoch: 0480 val_loss: 1.498908 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0490 lr: [0.0005, 0.0005] train_loss: 0.921113 train_acc: 0.520031 train_f1: 0.520031 time: 1.0420s
INFO:root:Epoch: 0490 val_loss: 1.504905 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0500 lr: [0.00025, 0.00025] train_loss: 0.922916 train_acc: 0.520424 train_f1: 0.520424 time: 1.0365s
INFO:root:Epoch: 0500 val_loss: 1.516644 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0510 lr: [0.00025, 0.00025] train_loss: 0.917695 train_acc: 0.520424 train_f1: 0.520424 time: 1.0414s
INFO:root:Epoch: 0510 val_loss: 1.520711 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0520 lr: [0.00025, 0.00025] train_loss: 0.919303 train_acc: 0.520817 train_f1: 0.520817 time: 1.0277s
INFO:root:Epoch: 0520 val_loss: 1.529775 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0530 lr: [0.00025, 0.00025] train_loss: 0.921974 train_acc: 0.521603 train_f1: 0.521603 time: 1.0369s
INFO:root:Epoch: 0530 val_loss: 1.529809 val_acc: 0.485348 val_f1: 0.485348
INFO:root:Epoch: 0540 lr: [0.00025, 0.00025] train_loss: 0.912437 train_acc: 0.520031 train_f1: 0.520031 time: 1.0337s
INFO:root:Epoch: 0540 val_loss: 1.533945 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0550 lr: [0.00025, 0.00025] train_loss: 0.911739 train_acc: 0.521210 train_f1: 0.521210 time: 1.0286s
INFO:root:Epoch: 0550 val_loss: 1.543828 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0560 lr: [0.00025, 0.00025] train_loss: 0.917079 train_acc: 0.521210 train_f1: 0.521210 time: 1.0340s
INFO:root:Epoch: 0560 val_loss: 1.548195 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0570 lr: [0.00025, 0.00025] train_loss: 0.910783 train_acc: 0.521210 train_f1: 0.521210 time: 1.0276s
INFO:root:Epoch: 0570 val_loss: 1.551950 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0580 lr: [0.00025, 0.00025] train_loss: 0.916955 train_acc: 0.521210 train_f1: 0.521210 time: 1.0344s
INFO:root:Epoch: 0580 val_loss: 1.560477 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0590 lr: [0.00025, 0.00025] train_loss: 0.913914 train_acc: 0.521603 train_f1: 0.521603 time: 1.0334s
INFO:root:Epoch: 0590 val_loss: 1.564246 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0600 lr: [0.00025, 0.00025] train_loss: 0.915990 train_acc: 0.520424 train_f1: 0.520424 time: 1.0306s
INFO:root:Epoch: 0600 val_loss: 1.565838 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0610 lr: [0.00025, 0.00025] train_loss: 0.915487 train_acc: 0.520817 train_f1: 0.520817 time: 1.0402s
INFO:root:Epoch: 0610 val_loss: 1.570866 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0620 lr: [0.00025, 0.00025] train_loss: 0.911022 train_acc: 0.521210 train_f1: 0.521210 time: 1.0312s
INFO:root:Epoch: 0620 val_loss: 1.581691 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0630 lr: [0.00025, 0.00025] train_loss: 0.922111 train_acc: 0.520817 train_f1: 0.520817 time: 1.0645s
INFO:root:Epoch: 0630 val_loss: 1.582310 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0640 lr: [0.00025, 0.00025] train_loss: 0.914290 train_acc: 0.521603 train_f1: 0.521603 time: 1.0476s
INFO:root:Epoch: 0640 val_loss: 1.588285 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0650 lr: [0.00025, 0.00025] train_loss: 0.912062 train_acc: 0.521603 train_f1: 0.521603 time: 1.0354s
INFO:root:Epoch: 0650 val_loss: 1.590826 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0660 lr: [0.00025, 0.00025] train_loss: 0.910817 train_acc: 0.521603 train_f1: 0.521603 time: 1.0284s
INFO:root:Epoch: 0660 val_loss: 1.602612 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Epoch: 0670 lr: [0.00025, 0.00025] train_loss: 0.914762 train_acc: 0.521603 train_f1: 0.521603 time: 1.0339s
INFO:root:Epoch: 0670 val_loss: 1.596753 val_acc: 0.483516 val_f1: 0.483516
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 706.8421s
INFO:root:Val set results: val_loss: 1.264408 val_acc: 0.492674 val_f1: 0.492674
INFO:root:Test set results: test_loss: 1.293327 test_acc: 0.490842 test_f1: 0.490842
