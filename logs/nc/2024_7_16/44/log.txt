INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: chameleon
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=2325, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fb4a424b6d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fb4a424b6d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fb4a424b6d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fb4a424b6d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (2): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fb4a424b6d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fb4a424b6d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 212061
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.464805 train_acc: 0.401021 train_f1: 0.401021 time: 1.3845s
INFO:root:Epoch: 0010 val_loss: 1.455960 val_acc: 0.406593 val_f1: 0.406593
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.292332 train_acc: 0.492145 train_f1: 0.492145 time: 1.3949s
INFO:root:Epoch: 0020 val_loss: 1.347315 val_acc: 0.465201 val_f1: 0.465201
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.139590 train_acc: 0.709348 train_f1: 0.709348 time: 1.3969s
INFO:root:Epoch: 0030 val_loss: 1.238606 val_acc: 0.630037 val_f1: 0.630037
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.038470 train_acc: 0.723881 train_f1: 0.723881 time: 1.3984s
INFO:root:Epoch: 0040 val_loss: 1.187168 val_acc: 0.641026 val_f1: 0.641026
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 0.973897 train_acc: 0.732522 train_f1: 0.732522 time: 1.3930s
INFO:root:Epoch: 0050 val_loss: 1.156396 val_acc: 0.644689 val_f1: 0.644689
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 0.934872 train_acc: 0.733700 train_f1: 0.733700 time: 1.3974s
INFO:root:Epoch: 0060 val_loss: 1.132189 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.911715 train_acc: 0.737235 train_f1: 0.737235 time: 1.4607s
INFO:root:Epoch: 0070 val_loss: 1.114757 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.897880 train_acc: 0.738806 train_f1: 0.738806 time: 1.3905s
INFO:root:Epoch: 0080 val_loss: 1.108512 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.889087 train_acc: 0.739199 train_f1: 0.739199 time: 1.3977s
INFO:root:Epoch: 0090 val_loss: 1.103756 val_acc: 0.639194 val_f1: 0.639194
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 0.883464 train_acc: 0.739199 train_f1: 0.739199 time: 1.3961s
INFO:root:Epoch: 0100 val_loss: 1.098428 val_acc: 0.641026 val_f1: 0.641026
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.880058 train_acc: 0.739199 train_f1: 0.739199 time: 1.3966s
INFO:root:Epoch: 0110 val_loss: 1.093218 val_acc: 0.637363 val_f1: 0.637363
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.877742 train_acc: 0.739199 train_f1: 0.739199 time: 1.3972s
INFO:root:Epoch: 0120 val_loss: 1.093274 val_acc: 0.639194 val_f1: 0.639194
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.876515 train_acc: 0.739592 train_f1: 0.739592 time: 1.3951s
INFO:root:Epoch: 0130 val_loss: 1.090735 val_acc: 0.642857 val_f1: 0.642857
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.878957 train_acc: 0.739199 train_f1: 0.739199 time: 1.3979s
INFO:root:Epoch: 0140 val_loss: 1.092592 val_acc: 0.642857 val_f1: 0.642857
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 0.876641 train_acc: 0.739592 train_f1: 0.739592 time: 1.3986s
INFO:root:Epoch: 0150 val_loss: 1.089794 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 0.875187 train_acc: 0.739592 train_f1: 0.739592 time: 1.4037s
INFO:root:Epoch: 0160 val_loss: 1.088124 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 0.873767 train_acc: 0.739592 train_f1: 0.739592 time: 1.3967s
INFO:root:Epoch: 0170 val_loss: 1.088275 val_acc: 0.646520 val_f1: 0.646520
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 0.873066 train_acc: 0.739592 train_f1: 0.739592 time: 1.4216s
INFO:root:Epoch: 0180 val_loss: 1.090972 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 0.872452 train_acc: 0.739984 train_f1: 0.739984 time: 1.4023s
INFO:root:Epoch: 0190 val_loss: 1.093377 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 0.871957 train_acc: 0.739984 train_f1: 0.739984 time: 1.3987s
INFO:root:Epoch: 0200 val_loss: 1.094367 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 0.871763 train_acc: 0.739984 train_f1: 0.739984 time: 1.3978s
INFO:root:Epoch: 0210 val_loss: 1.094174 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 0.871528 train_acc: 0.739984 train_f1: 0.739984 time: 1.3911s
INFO:root:Epoch: 0220 val_loss: 1.093782 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 0.871128 train_acc: 0.739984 train_f1: 0.739984 time: 1.3956s
INFO:root:Epoch: 0230 val_loss: 1.092365 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 0.870693 train_acc: 0.739984 train_f1: 0.739984 time: 1.3938s
INFO:root:Epoch: 0240 val_loss: 1.092770 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.870426 train_acc: 0.739984 train_f1: 0.739984 time: 1.3995s
INFO:root:Epoch: 0250 val_loss: 1.092691 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.870195 train_acc: 0.739984 train_f1: 0.739984 time: 1.4033s
INFO:root:Epoch: 0260 val_loss: 1.092199 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.869929 train_acc: 0.739984 train_f1: 0.739984 time: 1.3991s
INFO:root:Epoch: 0270 val_loss: 1.092212 val_acc: 0.644689 val_f1: 0.644689
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.869408 train_acc: 0.739984 train_f1: 0.739984 time: 1.4002s
INFO:root:Epoch: 0280 val_loss: 1.089953 val_acc: 0.644689 val_f1: 0.644689
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.867255 train_acc: 0.739984 train_f1: 0.739984 time: 1.3995s
INFO:root:Epoch: 0290 val_loss: 1.089952 val_acc: 0.641026 val_f1: 0.641026
INFO:root:Epoch: 0300 lr: [0.0005, 0.0005] train_loss: 0.870187 train_acc: 0.740377 train_f1: 0.740377 time: 1.4044s
INFO:root:Epoch: 0300 val_loss: 1.087375 val_acc: 0.635531 val_f1: 0.635531
INFO:root:Epoch: 0310 lr: [0.0005, 0.0005] train_loss: 0.864434 train_acc: 0.739984 train_f1: 0.739984 time: 1.4017s
INFO:root:Epoch: 0310 val_loss: 1.084766 val_acc: 0.641026 val_f1: 0.641026
INFO:root:Epoch: 0320 lr: [0.0005, 0.0005] train_loss: 0.852802 train_acc: 0.812647 train_f1: 0.812647 time: 1.4012s
INFO:root:Epoch: 0320 val_loss: 1.085807 val_acc: 0.642857 val_f1: 0.642857
INFO:root:Epoch: 0330 lr: [0.0005, 0.0005] train_loss: 0.854851 train_acc: 0.742341 train_f1: 0.742341 time: 1.3957s
INFO:root:Epoch: 0330 val_loss: 1.087192 val_acc: 0.641026 val_f1: 0.641026
INFO:root:Epoch: 0340 lr: [0.0005, 0.0005] train_loss: 0.856780 train_acc: 0.830322 train_f1: 0.830322 time: 1.3933s
INFO:root:Epoch: 0340 val_loss: 1.086349 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0350 lr: [0.0005, 0.0005] train_loss: 0.852379 train_acc: 0.742341 train_f1: 0.742341 time: 1.4076s
INFO:root:Epoch: 0350 val_loss: 1.085971 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0360 lr: [0.0005, 0.0005] train_loss: 0.854908 train_acc: 0.741163 train_f1: 0.741163 time: 1.4040s
INFO:root:Epoch: 0360 val_loss: 1.089920 val_acc: 0.646520 val_f1: 0.646520
INFO:root:Epoch: 0370 lr: [0.0005, 0.0005] train_loss: 0.849519 train_acc: 0.832286 train_f1: 0.832286 time: 1.3943s
INFO:root:Epoch: 0370 val_loss: 1.085300 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0380 lr: [0.0005, 0.0005] train_loss: 0.849543 train_acc: 0.755302 train_f1: 0.755302 time: 1.3989s
INFO:root:Epoch: 0380 val_loss: 1.087012 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0390 lr: [0.0005, 0.0005] train_loss: 0.846943 train_acc: 0.831893 train_f1: 0.831893 time: 1.4020s
INFO:root:Epoch: 0390 val_loss: 1.089218 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0400 lr: [0.00025, 0.00025] train_loss: 0.847091 train_acc: 0.832286 train_f1: 0.832286 time: 1.4082s
INFO:root:Epoch: 0400 val_loss: 1.086155 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0410 lr: [0.00025, 0.00025] train_loss: 0.844483 train_acc: 0.831108 train_f1: 0.831108 time: 1.3976s
INFO:root:Epoch: 0410 val_loss: 1.086532 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0420 lr: [0.00025, 0.00025] train_loss: 0.845299 train_acc: 0.831893 train_f1: 0.831893 time: 1.3928s
INFO:root:Epoch: 0420 val_loss: 1.086621 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0430 lr: [0.00025, 0.00025] train_loss: 0.842748 train_acc: 0.831893 train_f1: 0.831893 time: 1.4210s
INFO:root:Epoch: 0430 val_loss: 1.086538 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0440 lr: [0.00025, 0.00025] train_loss: 0.842411 train_acc: 0.831893 train_f1: 0.831893 time: 1.3979s
INFO:root:Epoch: 0440 val_loss: 1.086294 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0450 lr: [0.00025, 0.00025] train_loss: 0.842244 train_acc: 0.831893 train_f1: 0.831893 time: 1.3986s
INFO:root:Epoch: 0450 val_loss: 1.086290 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0460 lr: [0.00025, 0.00025] train_loss: 0.842285 train_acc: 0.831893 train_f1: 0.831893 time: 1.3954s
INFO:root:Epoch: 0460 val_loss: 1.086646 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0470 lr: [0.00025, 0.00025] train_loss: 0.844789 train_acc: 0.831893 train_f1: 0.831893 time: 1.3981s
INFO:root:Epoch: 0470 val_loss: 1.086893 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0480 lr: [0.00025, 0.00025] train_loss: 0.843360 train_acc: 0.831893 train_f1: 0.831893 time: 1.3948s
INFO:root:Epoch: 0480 val_loss: 1.086537 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0490 lr: [0.00025, 0.00025] train_loss: 0.841954 train_acc: 0.831893 train_f1: 0.831893 time: 1.3996s
INFO:root:Epoch: 0490 val_loss: 1.086337 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0500 lr: [0.00025, 0.00025] train_loss: 0.841394 train_acc: 0.831893 train_f1: 0.831893 time: 1.3962s
INFO:root:Epoch: 0500 val_loss: 1.087647 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0510 lr: [0.00025, 0.00025] train_loss: 0.840687 train_acc: 0.831893 train_f1: 0.831893 time: 1.4024s
INFO:root:Epoch: 0510 val_loss: 1.086170 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0520 lr: [0.00025, 0.00025] train_loss: 0.841226 train_acc: 0.831893 train_f1: 0.831893 time: 1.3945s
INFO:root:Epoch: 0520 val_loss: 1.087199 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0530 lr: [0.00025, 0.00025] train_loss: 0.839449 train_acc: 0.831893 train_f1: 0.831893 time: 1.4042s
INFO:root:Epoch: 0530 val_loss: 1.086729 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0540 lr: [0.00025, 0.00025] train_loss: 0.839013 train_acc: 0.831893 train_f1: 0.831893 time: 1.3959s
INFO:root:Epoch: 0540 val_loss: 1.086503 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0550 lr: [0.00025, 0.00025] train_loss: 0.840397 train_acc: 0.831893 train_f1: 0.831893 time: 1.4592s
INFO:root:Epoch: 0550 val_loss: 1.086957 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0560 lr: [0.00025, 0.00025] train_loss: 0.839699 train_acc: 0.831893 train_f1: 0.831893 time: 1.3952s
INFO:root:Epoch: 0560 val_loss: 1.088451 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0570 lr: [0.00025, 0.00025] train_loss: 0.838025 train_acc: 0.831893 train_f1: 0.831893 time: 1.4054s
INFO:root:Epoch: 0570 val_loss: 1.086176 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0580 lr: [0.00025, 0.00025] train_loss: 0.837798 train_acc: 0.831893 train_f1: 0.831893 time: 1.4262s
INFO:root:Epoch: 0580 val_loss: 1.086962 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0590 lr: [0.00025, 0.00025] train_loss: 0.837464 train_acc: 0.831893 train_f1: 0.831893 time: 1.4074s
INFO:root:Epoch: 0590 val_loss: 1.086604 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0600 lr: [0.000125, 0.000125] train_loss: 0.837639 train_acc: 0.832679 train_f1: 0.832679 time: 1.4058s
INFO:root:Epoch: 0600 val_loss: 1.085983 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0610 lr: [0.000125, 0.000125] train_loss: 0.837427 train_acc: 0.833071 train_f1: 0.833071 time: 1.3996s
INFO:root:Epoch: 0610 val_loss: 1.086055 val_acc: 0.675824 val_f1: 0.675824
INFO:root:Epoch: 0620 lr: [0.000125, 0.000125] train_loss: 0.830313 train_acc: 0.860566 train_f1: 0.860566 time: 1.3976s
INFO:root:Epoch: 0620 val_loss: 1.088079 val_acc: 0.684982 val_f1: 0.684982
INFO:root:Epoch: 0630 lr: [0.000125, 0.000125] train_loss: 0.823114 train_acc: 0.875098 train_f1: 0.875098 time: 1.3978s
INFO:root:Epoch: 0630 val_loss: 1.088359 val_acc: 0.684982 val_f1: 0.684982
INFO:root:Epoch: 0640 lr: [0.000125, 0.000125] train_loss: 0.817267 train_acc: 0.895522 train_f1: 0.895522 time: 1.3992s
INFO:root:Epoch: 0640 val_loss: 1.082851 val_acc: 0.683150 val_f1: 0.683150
INFO:root:Epoch: 0650 lr: [0.000125, 0.000125] train_loss: 0.813059 train_acc: 0.902200 train_f1: 0.902200 time: 1.3985s
INFO:root:Epoch: 0650 val_loss: 1.083242 val_acc: 0.684982 val_f1: 0.684982
INFO:root:Epoch: 0660 lr: [0.000125, 0.000125] train_loss: 0.811463 train_acc: 0.902985 train_f1: 0.902985 time: 1.4000s
INFO:root:Epoch: 0660 val_loss: 1.083949 val_acc: 0.681319 val_f1: 0.681319
INFO:root:Epoch: 0670 lr: [0.000125, 0.000125] train_loss: 0.810246 train_acc: 0.904163 train_f1: 0.904163 time: 1.3964s
INFO:root:Epoch: 0670 val_loss: 1.084197 val_acc: 0.677656 val_f1: 0.677656
INFO:root:Epoch: 0680 lr: [0.000125, 0.000125] train_loss: 0.808316 train_acc: 0.905734 train_f1: 0.905734 time: 1.3946s
INFO:root:Epoch: 0680 val_loss: 1.086901 val_acc: 0.677656 val_f1: 0.677656
INFO:root:Epoch: 0690 lr: [0.000125, 0.000125] train_loss: 0.808479 train_acc: 0.906520 train_f1: 0.906520 time: 1.4050s
INFO:root:Epoch: 0690 val_loss: 1.087250 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0700 lr: [0.000125, 0.000125] train_loss: 0.808510 train_acc: 0.906520 train_f1: 0.906520 time: 1.3999s
INFO:root:Epoch: 0700 val_loss: 1.087890 val_acc: 0.679487 val_f1: 0.679487
INFO:root:Epoch: 0710 lr: [0.000125, 0.000125] train_loss: 0.807938 train_acc: 0.900236 train_f1: 0.900236 time: 1.4043s
INFO:root:Epoch: 0710 val_loss: 1.089454 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0720 lr: [0.000125, 0.000125] train_loss: 0.806524 train_acc: 0.905734 train_f1: 0.905734 time: 1.4173s
INFO:root:Epoch: 0720 val_loss: 1.088951 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0730 lr: [0.000125, 0.000125] train_loss: 0.805624 train_acc: 0.906520 train_f1: 0.906520 time: 1.4028s
INFO:root:Epoch: 0730 val_loss: 1.088360 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0740 lr: [0.000125, 0.000125] train_loss: 0.804643 train_acc: 0.906520 train_f1: 0.906520 time: 1.4025s
INFO:root:Epoch: 0740 val_loss: 1.089471 val_acc: 0.672161 val_f1: 0.672161
INFO:root:Epoch: 0750 lr: [0.000125, 0.000125] train_loss: 0.805078 train_acc: 0.906520 train_f1: 0.906520 time: 1.4030s
INFO:root:Epoch: 0750 val_loss: 1.089857 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0760 lr: [0.000125, 0.000125] train_loss: 0.804179 train_acc: 0.906520 train_f1: 0.906520 time: 1.4004s
INFO:root:Epoch: 0760 val_loss: 1.089815 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0770 lr: [0.000125, 0.000125] train_loss: 0.803397 train_acc: 0.906520 train_f1: 0.906520 time: 1.3953s
INFO:root:Epoch: 0770 val_loss: 1.090926 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0780 lr: [0.000125, 0.000125] train_loss: 0.803285 train_acc: 0.906520 train_f1: 0.906520 time: 1.4023s
INFO:root:Epoch: 0780 val_loss: 1.090051 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0790 lr: [0.000125, 0.000125] train_loss: 0.803307 train_acc: 0.906520 train_f1: 0.906520 time: 1.3957s
INFO:root:Epoch: 0790 val_loss: 1.090937 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0800 lr: [6.25e-05, 6.25e-05] train_loss: 0.802860 train_acc: 0.906520 train_f1: 0.906520 time: 1.3983s
INFO:root:Epoch: 0800 val_loss: 1.091522 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0810 lr: [6.25e-05, 6.25e-05] train_loss: 0.801753 train_acc: 0.906520 train_f1: 0.906520 time: 1.4030s
INFO:root:Epoch: 0810 val_loss: 1.091241 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0820 lr: [6.25e-05, 6.25e-05] train_loss: 0.801404 train_acc: 0.906520 train_f1: 0.906520 time: 1.3981s
INFO:root:Epoch: 0820 val_loss: 1.091119 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0830 lr: [6.25e-05, 6.25e-05] train_loss: 0.801271 train_acc: 0.906520 train_f1: 0.906520 time: 1.3935s
INFO:root:Epoch: 0830 val_loss: 1.091320 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0840 lr: [6.25e-05, 6.25e-05] train_loss: 0.800938 train_acc: 0.906520 train_f1: 0.906520 time: 1.3935s
INFO:root:Epoch: 0840 val_loss: 1.091349 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0850 lr: [6.25e-05, 6.25e-05] train_loss: 0.800895 train_acc: 0.906520 train_f1: 0.906520 time: 1.3973s
INFO:root:Epoch: 0850 val_loss: 1.091540 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0860 lr: [6.25e-05, 6.25e-05] train_loss: 0.801210 train_acc: 0.906520 train_f1: 0.906520 time: 1.4027s
INFO:root:Epoch: 0860 val_loss: 1.092028 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0870 lr: [6.25e-05, 6.25e-05] train_loss: 0.800612 train_acc: 0.906520 train_f1: 0.906520 time: 1.4002s
INFO:root:Epoch: 0870 val_loss: 1.091862 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0880 lr: [6.25e-05, 6.25e-05] train_loss: 0.800682 train_acc: 0.906520 train_f1: 0.906520 time: 1.3995s
INFO:root:Epoch: 0880 val_loss: 1.091696 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0890 lr: [6.25e-05, 6.25e-05] train_loss: 0.800027 train_acc: 0.906520 train_f1: 0.906520 time: 1.3965s
INFO:root:Epoch: 0890 val_loss: 1.091829 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0900 lr: [6.25e-05, 6.25e-05] train_loss: 0.799880 train_acc: 0.906520 train_f1: 0.906520 time: 1.3904s
INFO:root:Epoch: 0900 val_loss: 1.092163 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0910 lr: [6.25e-05, 6.25e-05] train_loss: 0.799805 train_acc: 0.906520 train_f1: 0.906520 time: 1.3987s
INFO:root:Epoch: 0910 val_loss: 1.092289 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0920 lr: [6.25e-05, 6.25e-05] train_loss: 0.799650 train_acc: 0.906520 train_f1: 0.906520 time: 1.3991s
INFO:root:Epoch: 0920 val_loss: 1.093082 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0930 lr: [6.25e-05, 6.25e-05] train_loss: 0.799686 train_acc: 0.906520 train_f1: 0.906520 time: 1.3964s
INFO:root:Epoch: 0930 val_loss: 1.092995 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0940 lr: [6.25e-05, 6.25e-05] train_loss: 0.799026 train_acc: 0.906520 train_f1: 0.906520 time: 1.3964s
INFO:root:Epoch: 0940 val_loss: 1.092833 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0950 lr: [6.25e-05, 6.25e-05] train_loss: 0.799147 train_acc: 0.906520 train_f1: 0.906520 time: 1.4011s
INFO:root:Epoch: 0950 val_loss: 1.092900 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0960 lr: [6.25e-05, 6.25e-05] train_loss: 0.799059 train_acc: 0.906520 train_f1: 0.906520 time: 1.3994s
INFO:root:Epoch: 0960 val_loss: 1.093421 val_acc: 0.666667 val_f1: 0.666667
