INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: chameleon
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=2325, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f8bbe1836d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f8bbe1836d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f8bbe1836d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f8bbe1836d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (2): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f8bbe1836d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f8bbe1836d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 212061
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.491994 train_acc: 0.369207 train_f1: 0.369207 time: 1.4011s
INFO:root:Epoch: 0010 val_loss: 1.466003 val_acc: 0.397436 val_f1: 0.397436
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.348022 train_acc: 0.470542 train_f1: 0.470542 time: 1.4122s
INFO:root:Epoch: 0020 val_loss: 1.378514 val_acc: 0.450549 val_f1: 0.450549
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.257252 train_acc: 0.486253 train_f1: 0.486253 time: 1.4007s
INFO:root:Epoch: 0030 val_loss: 1.303744 val_acc: 0.478022 val_f1: 0.478022
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.166630 train_acc: 0.599372 train_f1: 0.599372 time: 1.4036s
INFO:root:Epoch: 0040 val_loss: 1.253434 val_acc: 0.597070 val_f1: 0.597070
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.092302 train_acc: 0.713276 train_f1: 0.713276 time: 1.4053s
INFO:root:Epoch: 0050 val_loss: 1.212835 val_acc: 0.630037 val_f1: 0.630037
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.034120 train_acc: 0.723095 train_f1: 0.723095 time: 1.4023s
INFO:root:Epoch: 0060 val_loss: 1.179303 val_acc: 0.633700 val_f1: 0.633700
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.994872 train_acc: 0.726630 train_f1: 0.726630 time: 1.4678s
INFO:root:Epoch: 0070 val_loss: 1.141707 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.969948 train_acc: 0.730558 train_f1: 0.730558 time: 1.3963s
INFO:root:Epoch: 0080 val_loss: 1.128363 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.953064 train_acc: 0.725452 train_f1: 0.725452 time: 1.4017s
INFO:root:Epoch: 0090 val_loss: 1.117668 val_acc: 0.642857 val_f1: 0.642857
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 0.925298 train_acc: 0.733700 train_f1: 0.733700 time: 1.4045s
INFO:root:Epoch: 0100 val_loss: 1.112691 val_acc: 0.650183 val_f1: 0.650183
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.931670 train_acc: 0.733700 train_f1: 0.733700 time: 1.4001s
INFO:root:Epoch: 0110 val_loss: 1.091236 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.909802 train_acc: 0.734485 train_f1: 0.734485 time: 1.3999s
INFO:root:Epoch: 0120 val_loss: 1.093370 val_acc: 0.642857 val_f1: 0.642857
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.902593 train_acc: 0.735271 train_f1: 0.735271 time: 1.4061s
INFO:root:Epoch: 0130 val_loss: 1.098690 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.904699 train_acc: 0.738413 train_f1: 0.738413 time: 1.3973s
INFO:root:Epoch: 0140 val_loss: 1.092864 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.894219 train_acc: 0.738020 train_f1: 0.738020 time: 1.4048s
INFO:root:Epoch: 0150 val_loss: 1.097275 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.893075 train_acc: 0.738020 train_f1: 0.738020 time: 1.4034s
INFO:root:Epoch: 0160 val_loss: 1.088156 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.894236 train_acc: 0.738020 train_f1: 0.738020 time: 1.4030s
INFO:root:Epoch: 0170 val_loss: 1.089895 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.895221 train_acc: 0.737235 train_f1: 0.737235 time: 1.3944s
INFO:root:Epoch: 0180 val_loss: 1.087700 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.887456 train_acc: 0.737628 train_f1: 0.737628 time: 1.3997s
INFO:root:Epoch: 0190 val_loss: 1.085147 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 0.899739 train_acc: 0.739199 train_f1: 0.739199 time: 1.3979s
INFO:root:Epoch: 0200 val_loss: 1.089667 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 0.892885 train_acc: 0.737628 train_f1: 0.737628 time: 1.3931s
INFO:root:Epoch: 0210 val_loss: 1.091369 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 0.891813 train_acc: 0.737235 train_f1: 0.737235 time: 1.4009s
INFO:root:Epoch: 0220 val_loss: 1.088545 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 0.896667 train_acc: 0.737628 train_f1: 0.737628 time: 1.3971s
INFO:root:Epoch: 0230 val_loss: 1.084269 val_acc: 0.664835 val_f1: 0.664835
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 0.890939 train_acc: 0.738020 train_f1: 0.738020 time: 1.4020s
INFO:root:Epoch: 0240 val_loss: 1.082042 val_acc: 0.659341 val_f1: 0.659341
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.886881 train_acc: 0.738413 train_f1: 0.738413 time: 1.3983s
INFO:root:Epoch: 0250 val_loss: 1.090449 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.889895 train_acc: 0.737628 train_f1: 0.737628 time: 1.3987s
INFO:root:Epoch: 0260 val_loss: 1.082290 val_acc: 0.657509 val_f1: 0.657509
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.889971 train_acc: 0.738020 train_f1: 0.738020 time: 1.3985s
INFO:root:Epoch: 0270 val_loss: 1.088803 val_acc: 0.663004 val_f1: 0.663004
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.885389 train_acc: 0.738020 train_f1: 0.738020 time: 1.3989s
INFO:root:Epoch: 0280 val_loss: 1.086897 val_acc: 0.657509 val_f1: 0.657509
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.886324 train_acc: 0.742734 train_f1: 0.742734 time: 1.3976s
INFO:root:Epoch: 0290 val_loss: 1.090254 val_acc: 0.659341 val_f1: 0.659341
INFO:root:Epoch: 0300 lr: [0.00025, 0.00025] train_loss: 0.892894 train_acc: 0.780047 train_f1: 0.780047 time: 1.4025s
INFO:root:Epoch: 0300 val_loss: 1.087661 val_acc: 0.670330 val_f1: 0.670330
INFO:root:Epoch: 0310 lr: [0.00025, 0.00025] train_loss: 0.884156 train_acc: 0.752946 train_f1: 0.752946 time: 1.3939s
INFO:root:Epoch: 0310 val_loss: 1.089345 val_acc: 0.679487 val_f1: 0.679487
INFO:root:Epoch: 0320 lr: [0.00025, 0.00025] train_loss: 0.881322 train_acc: 0.790652 train_f1: 0.790652 time: 1.4008s
INFO:root:Epoch: 0320 val_loss: 1.085882 val_acc: 0.694139 val_f1: 0.694139
INFO:root:Epoch: 0330 lr: [0.00025, 0.00025] train_loss: 0.873987 train_acc: 0.813433 train_f1: 0.813433 time: 1.4005s
INFO:root:Epoch: 0330 val_loss: 1.085523 val_acc: 0.690476 val_f1: 0.690476
INFO:root:Epoch: 0340 lr: [0.00025, 0.00025] train_loss: 0.857651 train_acc: 0.850353 train_f1: 0.850353 time: 1.3992s
INFO:root:Epoch: 0340 val_loss: 1.084486 val_acc: 0.723443 val_f1: 0.723443
INFO:root:Epoch: 0350 lr: [0.00025, 0.00025] train_loss: 0.835805 train_acc: 0.861744 train_f1: 0.861744 time: 1.4024s
INFO:root:Epoch: 0350 val_loss: 1.075351 val_acc: 0.727106 val_f1: 0.727106
INFO:root:Epoch: 0360 lr: [0.00025, 0.00025] train_loss: 0.793504 train_acc: 0.848782 train_f1: 0.848782 time: 1.4022s
INFO:root:Epoch: 0360 val_loss: 1.132380 val_acc: 0.723443 val_f1: 0.723443
INFO:root:Epoch: 0370 lr: [0.00025, 0.00025] train_loss: 0.795489 train_acc: 0.863708 train_f1: 0.863708 time: 1.3969s
INFO:root:Epoch: 0370 val_loss: 1.069667 val_acc: 0.723443 val_f1: 0.723443
INFO:root:Epoch: 0380 lr: [0.00025, 0.00025] train_loss: 0.789440 train_acc: 0.863315 train_f1: 0.863315 time: 1.3997s
INFO:root:Epoch: 0380 val_loss: 1.059910 val_acc: 0.723443 val_f1: 0.723443
INFO:root:Epoch: 0390 lr: [0.00025, 0.00025] train_loss: 0.780073 train_acc: 0.961115 train_f1: 0.961115 time: 1.3965s
INFO:root:Epoch: 0390 val_loss: 1.072791 val_acc: 0.760073 val_f1: 0.760073
INFO:root:Epoch: 0400 lr: [0.00025, 0.00025] train_loss: 0.764723 train_acc: 0.975648 train_f1: 0.975648 time: 1.4040s
INFO:root:Epoch: 0400 val_loss: 1.051385 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0410 lr: [0.00025, 0.00025] train_loss: 0.757443 train_acc: 0.981540 train_f1: 0.981540 time: 1.4017s
INFO:root:Epoch: 0410 val_loss: 1.051352 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0420 lr: [0.00025, 0.00025] train_loss: 0.764790 train_acc: 0.933621 train_f1: 0.933621 time: 1.4047s
INFO:root:Epoch: 0420 val_loss: 1.066413 val_acc: 0.763736 val_f1: 0.763736
INFO:root:Epoch: 0430 lr: [0.00025, 0.00025] train_loss: 0.753930 train_acc: 0.971328 train_f1: 0.971328 time: 1.4533s
INFO:root:Epoch: 0430 val_loss: 1.074814 val_acc: 0.758242 val_f1: 0.758242
INFO:root:Epoch: 0440 lr: [0.00025, 0.00025] train_loss: 0.748569 train_acc: 0.948940 train_f1: 0.948940 time: 1.4050s
INFO:root:Epoch: 0440 val_loss: 1.099378 val_acc: 0.734432 val_f1: 0.734432
INFO:root:Epoch: 0450 lr: [0.000125, 0.000125] train_loss: 0.736874 train_acc: 0.979183 train_f1: 0.979183 time: 1.4037s
INFO:root:Epoch: 0450 val_loss: 1.087555 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0460 lr: [0.000125, 0.000125] train_loss: 0.731405 train_acc: 0.985467 train_f1: 0.985467 time: 1.3997s
INFO:root:Epoch: 0460 val_loss: 1.089710 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0470 lr: [0.000125, 0.000125] train_loss: 0.724248 train_acc: 0.985075 train_f1: 0.985075 time: 1.4007s
INFO:root:Epoch: 0470 val_loss: 1.093192 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0480 lr: [0.000125, 0.000125] train_loss: 0.722263 train_acc: 0.986646 train_f1: 0.986646 time: 1.4000s
INFO:root:Epoch: 0480 val_loss: 1.094739 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0490 lr: [0.000125, 0.000125] train_loss: 0.724896 train_acc: 0.983504 train_f1: 0.983504 time: 1.4001s
INFO:root:Epoch: 0490 val_loss: 1.092500 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0500 lr: [0.000125, 0.000125] train_loss: 0.733359 train_acc: 0.921053 train_f1: 0.921053 time: 1.3997s
INFO:root:Epoch: 0500 val_loss: 1.094781 val_acc: 0.763736 val_f1: 0.763736
INFO:root:Epoch: 0510 lr: [0.000125, 0.000125] train_loss: 0.724666 train_acc: 0.959152 train_f1: 0.959152 time: 1.4008s
INFO:root:Epoch: 0510 val_loss: 1.091937 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0520 lr: [0.000125, 0.000125] train_loss: 0.715187 train_acc: 0.950118 train_f1: 0.950118 time: 1.4023s
INFO:root:Epoch: 0520 val_loss: 1.110850 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0530 lr: [0.000125, 0.000125] train_loss: 0.709240 train_acc: 0.985075 train_f1: 0.985075 time: 1.4054s
INFO:root:Epoch: 0530 val_loss: 1.109861 val_acc: 0.782051 val_f1: 0.782051
INFO:root:Epoch: 0540 lr: [0.000125, 0.000125] train_loss: 0.717214 train_acc: 0.934014 train_f1: 0.934014 time: 1.4029s
INFO:root:Epoch: 0540 val_loss: 1.122125 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0550 lr: [0.000125, 0.000125] train_loss: 0.700715 train_acc: 0.986646 train_f1: 0.986646 time: 1.4013s
INFO:root:Epoch: 0550 val_loss: 1.131260 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0560 lr: [0.000125, 0.000125] train_loss: 0.706505 train_acc: 0.977612 train_f1: 0.977612 time: 1.4045s
INFO:root:Epoch: 0560 val_loss: 1.138317 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0570 lr: [0.000125, 0.000125] train_loss: 0.700767 train_acc: 0.987431 train_f1: 0.987431 time: 1.4113s
INFO:root:Epoch: 0570 val_loss: 1.142168 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0580 lr: [0.000125, 0.000125] train_loss: 0.699735 train_acc: 0.974863 train_f1: 0.974863 time: 1.4054s
INFO:root:Epoch: 0580 val_loss: 1.148203 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0590 lr: [0.000125, 0.000125] train_loss: 0.706733 train_acc: 0.974863 train_f1: 0.974863 time: 1.4085s
INFO:root:Epoch: 0590 val_loss: 1.135781 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0600 lr: [6.25e-05, 6.25e-05] train_loss: 0.698795 train_acc: 0.985467 train_f1: 0.985467 time: 1.4063s
INFO:root:Epoch: 0600 val_loss: 1.134198 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0610 lr: [6.25e-05, 6.25e-05] train_loss: 0.699884 train_acc: 0.985860 train_f1: 0.985860 time: 1.4063s
INFO:root:Epoch: 0610 val_loss: 1.135583 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0620 lr: [6.25e-05, 6.25e-05] train_loss: 0.693369 train_acc: 0.986253 train_f1: 0.986253 time: 1.4057s
INFO:root:Epoch: 0620 val_loss: 1.139126 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0630 lr: [6.25e-05, 6.25e-05] train_loss: 0.696035 train_acc: 0.985467 train_f1: 0.985467 time: 1.4035s
INFO:root:Epoch: 0630 val_loss: 1.140454 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0640 lr: [6.25e-05, 6.25e-05] train_loss: 0.696840 train_acc: 0.984289 train_f1: 0.984289 time: 1.4027s
INFO:root:Epoch: 0640 val_loss: 1.153883 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0650 lr: [6.25e-05, 6.25e-05] train_loss: 0.693780 train_acc: 0.987431 train_f1: 0.987431 time: 1.4012s
INFO:root:Epoch: 0650 val_loss: 1.152216 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0660 lr: [6.25e-05, 6.25e-05] train_loss: 0.692184 train_acc: 0.982325 train_f1: 0.982325 time: 1.4048s
INFO:root:Epoch: 0660 val_loss: 1.144473 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0670 lr: [6.25e-05, 6.25e-05] train_loss: 0.690025 train_acc: 0.985860 train_f1: 0.985860 time: 1.4061s
INFO:root:Epoch: 0670 val_loss: 1.145830 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0680 lr: [6.25e-05, 6.25e-05] train_loss: 0.701439 train_acc: 0.983111 train_f1: 0.983111 time: 1.4045s
INFO:root:Epoch: 0680 val_loss: 1.142992 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0690 lr: [6.25e-05, 6.25e-05] train_loss: 0.690873 train_acc: 0.986646 train_f1: 0.986646 time: 1.4002s
INFO:root:Epoch: 0690 val_loss: 1.142303 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0700 lr: [6.25e-05, 6.25e-05] train_loss: 0.689417 train_acc: 0.987824 train_f1: 0.987824 time: 1.4035s
INFO:root:Epoch: 0700 val_loss: 1.159052 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0710 lr: [6.25e-05, 6.25e-05] train_loss: 0.705125 train_acc: 0.986646 train_f1: 0.986646 time: 1.4000s
INFO:root:Epoch: 0710 val_loss: 1.163425 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0720 lr: [6.25e-05, 6.25e-05] train_loss: 0.711991 train_acc: 0.965829 train_f1: 0.965829 time: 1.4013s
INFO:root:Epoch: 0720 val_loss: 1.140371 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0730 lr: [6.25e-05, 6.25e-05] train_loss: 0.687489 train_acc: 0.984289 train_f1: 0.984289 time: 1.4022s
INFO:root:Epoch: 0730 val_loss: 1.131440 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0740 lr: [6.25e-05, 6.25e-05] train_loss: 0.690868 train_acc: 0.985075 train_f1: 0.985075 time: 1.3953s
INFO:root:Epoch: 0740 val_loss: 1.135251 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0750 lr: [3.125e-05, 3.125e-05] train_loss: 0.685045 train_acc: 0.982325 train_f1: 0.982325 time: 1.4049s
INFO:root:Epoch: 0750 val_loss: 1.141799 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0760 lr: [3.125e-05, 3.125e-05] train_loss: 0.684105 train_acc: 0.985860 train_f1: 0.985860 time: 1.4098s
INFO:root:Epoch: 0760 val_loss: 1.149042 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0770 lr: [3.125e-05, 3.125e-05] train_loss: 0.690720 train_acc: 0.987824 train_f1: 0.987824 time: 1.3950s
INFO:root:Epoch: 0770 val_loss: 1.155891 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0780 lr: [3.125e-05, 3.125e-05] train_loss: 0.683996 train_acc: 0.981932 train_f1: 0.981932 time: 1.4074s
INFO:root:Epoch: 0780 val_loss: 1.153127 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0790 lr: [3.125e-05, 3.125e-05] train_loss: 0.687630 train_acc: 0.985075 train_f1: 0.985075 time: 1.4028s
INFO:root:Epoch: 0790 val_loss: 1.153912 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0800 lr: [3.125e-05, 3.125e-05] train_loss: 0.690613 train_acc: 0.964650 train_f1: 0.964650 time: 1.4028s
INFO:root:Epoch: 0800 val_loss: 1.158611 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0810 lr: [3.125e-05, 3.125e-05] train_loss: 0.691399 train_acc: 0.985860 train_f1: 0.985860 time: 1.4029s
INFO:root:Epoch: 0810 val_loss: 1.163053 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0820 lr: [3.125e-05, 3.125e-05] train_loss: 0.690601 train_acc: 0.987038 train_f1: 0.987038 time: 1.4047s
INFO:root:Epoch: 0820 val_loss: 1.166734 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0830 lr: [3.125e-05, 3.125e-05] train_loss: 0.685709 train_acc: 0.987431 train_f1: 0.987431 time: 1.4033s
INFO:root:Epoch: 0830 val_loss: 1.162051 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0840 lr: [3.125e-05, 3.125e-05] train_loss: 0.685231 train_acc: 0.982325 train_f1: 0.982325 time: 1.3989s
INFO:root:Epoch: 0840 val_loss: 1.151028 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0850 lr: [3.125e-05, 3.125e-05] train_loss: 0.693436 train_acc: 0.985075 train_f1: 0.985075 time: 1.4054s
INFO:root:Epoch: 0850 val_loss: 1.149517 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0860 lr: [3.125e-05, 3.125e-05] train_loss: 0.683536 train_acc: 0.985075 train_f1: 0.985075 time: 1.3935s
INFO:root:Epoch: 0860 val_loss: 1.154737 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0870 lr: [3.125e-05, 3.125e-05] train_loss: 0.684098 train_acc: 0.985467 train_f1: 0.985467 time: 1.3992s
INFO:root:Epoch: 0870 val_loss: 1.162952 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0880 lr: [3.125e-05, 3.125e-05] train_loss: 0.680318 train_acc: 0.985860 train_f1: 0.985860 time: 1.3964s
INFO:root:Epoch: 0880 val_loss: 1.158288 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0890 lr: [3.125e-05, 3.125e-05] train_loss: 0.682755 train_acc: 0.987431 train_f1: 0.987431 time: 1.4030s
INFO:root:Epoch: 0890 val_loss: 1.153602 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 0900 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.682598 train_acc: 0.979969 train_f1: 0.979969 time: 1.3978s
INFO:root:Epoch: 0900 val_loss: 1.147886 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0910 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.684759 train_acc: 0.982325 train_f1: 0.982325 time: 1.4052s
INFO:root:Epoch: 0910 val_loss: 1.144002 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0920 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.689329 train_acc: 0.987038 train_f1: 0.987038 time: 1.4077s
INFO:root:Epoch: 0920 val_loss: 1.148046 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0930 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.687658 train_acc: 0.985860 train_f1: 0.985860 time: 1.4100s
INFO:root:Epoch: 0930 val_loss: 1.152373 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0940 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.682049 train_acc: 0.984289 train_f1: 0.984289 time: 1.4048s
INFO:root:Epoch: 0940 val_loss: 1.155538 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0950 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.684425 train_acc: 0.987431 train_f1: 0.987431 time: 1.4032s
INFO:root:Epoch: 0950 val_loss: 1.154916 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0960 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.683047 train_acc: 0.985467 train_f1: 0.985467 time: 1.4071s
INFO:root:Epoch: 0960 val_loss: 1.158509 val_acc: 0.776557 val_f1: 0.776557
INFO:root:Epoch: 0970 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.680347 train_acc: 0.985467 train_f1: 0.985467 time: 1.3945s
INFO:root:Epoch: 0970 val_loss: 1.160066 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0980 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.688035 train_acc: 0.985467 train_f1: 0.985467 time: 1.4033s
INFO:root:Epoch: 0980 val_loss: 1.164337 val_acc: 0.780220 val_f1: 0.780220
INFO:root:Epoch: 0990 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.685896 train_acc: 0.986646 train_f1: 0.986646 time: 1.4087s
INFO:root:Epoch: 0990 val_loss: 1.167051 val_acc: 0.780220 val_f1: 0.780220
INFO:root:Epoch: 1000 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.684263 train_acc: 0.987431 train_f1: 0.987431 time: 1.4071s
INFO:root:Epoch: 1000 val_loss: 1.167429 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 1010 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.687604 train_acc: 0.986253 train_f1: 0.986253 time: 1.4020s
INFO:root:Epoch: 1010 val_loss: 1.168379 val_acc: 0.778388 val_f1: 0.778388
INFO:root:Epoch: 1020 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.683262 train_acc: 0.987038 train_f1: 0.987038 time: 1.3962s
INFO:root:Epoch: 1020 val_loss: 1.170021 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 1030 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.682872 train_acc: 0.984682 train_f1: 0.984682 time: 1.3968s
INFO:root:Epoch: 1030 val_loss: 1.168598 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1477.8460s
INFO:root:Val set results: val_loss: 1.109861 val_acc: 0.782051 val_f1: 0.782051
INFO:root:Test set results: test_loss: 1.096125 test_acc: 0.761905 test_f1: 0.761905
