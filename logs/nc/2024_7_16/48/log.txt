INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: chameleon
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=2325, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f982ddf76d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f982ddf76d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f982ddf76d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f982ddf76d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (2): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=52, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f982ddf76d0>)
            (linear2): BLinear(in_features=104, out_features=104, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=104, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7f982ddf76d0>)
            (linear2): BLinear(in_features=52, out_features=52, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 212061
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.503305 train_acc: 0.354281 train_f1: 0.354281 time: 1.4035s
INFO:root:Epoch: 0010 val_loss: 1.470974 val_acc: 0.402930 val_f1: 0.402930
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.403693 train_acc: 0.349175 train_f1: 0.349175 time: 1.3961s
INFO:root:Epoch: 0020 val_loss: 1.365336 val_acc: 0.448718 val_f1: 0.448718
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.236188 train_acc: 0.502357 train_f1: 0.502357 time: 1.4074s
INFO:root:Epoch: 0030 val_loss: 1.326549 val_acc: 0.540293 val_f1: 0.540293
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.155586 train_acc: 0.512176 train_f1: 0.512176 time: 1.3894s
INFO:root:Epoch: 0040 val_loss: 1.261455 val_acc: 0.487179 val_f1: 0.487179
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.079636 train_acc: 0.701493 train_f1: 0.701493 time: 1.3884s
INFO:root:Epoch: 0050 val_loss: 1.216941 val_acc: 0.619048 val_f1: 0.619048
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.020738 train_acc: 0.726630 train_f1: 0.726630 time: 1.4039s
INFO:root:Epoch: 0060 val_loss: 1.171180 val_acc: 0.639194 val_f1: 0.639194
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.983221 train_acc: 0.725844 train_f1: 0.725844 time: 1.4637s
INFO:root:Epoch: 0070 val_loss: 1.146573 val_acc: 0.637363 val_f1: 0.637363
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.970773 train_acc: 0.724666 train_f1: 0.724666 time: 1.4008s
INFO:root:Epoch: 0080 val_loss: 1.124163 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.944706 train_acc: 0.728987 train_f1: 0.728987 time: 1.3996s
INFO:root:Epoch: 0090 val_loss: 1.135149 val_acc: 0.628205 val_f1: 0.628205
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 0.940071 train_acc: 0.730558 train_f1: 0.730558 time: 1.4061s
INFO:root:Epoch: 0100 val_loss: 1.108545 val_acc: 0.655678 val_f1: 0.655678
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.932616 train_acc: 0.731343 train_f1: 0.731343 time: 1.4030s
INFO:root:Epoch: 0110 val_loss: 1.112499 val_acc: 0.639194 val_f1: 0.639194
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.920256 train_acc: 0.732914 train_f1: 0.732914 time: 1.4167s
INFO:root:Epoch: 0120 val_loss: 1.100292 val_acc: 0.657509 val_f1: 0.657509
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.914273 train_acc: 0.745876 train_f1: 0.745876 time: 1.4103s
INFO:root:Epoch: 0130 val_loss: 1.093953 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.912053 train_acc: 0.729379 train_f1: 0.729379 time: 1.4112s
INFO:root:Epoch: 0140 val_loss: 1.111814 val_acc: 0.635531 val_f1: 0.635531
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 0.904334 train_acc: 0.730951 train_f1: 0.730951 time: 1.4058s
INFO:root:Epoch: 0150 val_loss: 1.070485 val_acc: 0.657509 val_f1: 0.657509
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 0.902314 train_acc: 0.737628 train_f1: 0.737628 time: 1.4011s
INFO:root:Epoch: 0160 val_loss: 1.071705 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 0.895526 train_acc: 0.738806 train_f1: 0.738806 time: 1.4026s
INFO:root:Epoch: 0170 val_loss: 1.073546 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 0.953704 train_acc: 0.818539 train_f1: 0.818539 time: 1.4028s
INFO:root:Epoch: 0180 val_loss: 1.066470 val_acc: 0.694139 val_f1: 0.694139
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 0.895797 train_acc: 0.741555 train_f1: 0.741555 time: 1.3953s
INFO:root:Epoch: 0190 val_loss: 1.091809 val_acc: 0.631868 val_f1: 0.631868
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 0.897305 train_acc: 0.749411 train_f1: 0.749411 time: 1.4118s
INFO:root:Epoch: 0200 val_loss: 1.085051 val_acc: 0.648352 val_f1: 0.648352
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 0.889475 train_acc: 0.741163 train_f1: 0.741163 time: 1.4016s
INFO:root:Epoch: 0210 val_loss: 1.075577 val_acc: 0.657509 val_f1: 0.657509
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 0.890562 train_acc: 0.750196 train_f1: 0.750196 time: 1.4018s
INFO:root:Epoch: 0220 val_loss: 1.073004 val_acc: 0.659341 val_f1: 0.659341
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 0.895413 train_acc: 0.738806 train_f1: 0.738806 time: 1.3970s
INFO:root:Epoch: 0230 val_loss: 1.075394 val_acc: 0.655678 val_f1: 0.655678
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 0.889242 train_acc: 0.817753 train_f1: 0.817753 time: 1.4041s
INFO:root:Epoch: 0240 val_loss: 1.075484 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.886792 train_acc: 0.818932 train_f1: 0.818932 time: 1.4024s
INFO:root:Epoch: 0250 val_loss: 1.077648 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.886552 train_acc: 0.737628 train_f1: 0.737628 time: 1.3967s
INFO:root:Epoch: 0260 val_loss: 1.072227 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.886278 train_acc: 0.739984 train_f1: 0.739984 time: 1.3997s
INFO:root:Epoch: 0270 val_loss: 1.075761 val_acc: 0.653846 val_f1: 0.653846
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.883509 train_acc: 0.741163 train_f1: 0.741163 time: 1.4072s
INFO:root:Epoch: 0280 val_loss: 1.079537 val_acc: 0.652015 val_f1: 0.652015
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.885668 train_acc: 0.738020 train_f1: 0.738020 time: 1.3997s
INFO:root:Epoch: 0290 val_loss: 1.076505 val_acc: 0.659341 val_f1: 0.659341
INFO:root:Epoch: 0300 lr: [0.0005, 0.0005] train_loss: 0.884170 train_acc: 0.741555 train_f1: 0.741555 time: 1.3972s
INFO:root:Epoch: 0300 val_loss: 1.074907 val_acc: 0.659341 val_f1: 0.659341
INFO:root:Epoch: 0310 lr: [0.0005, 0.0005] train_loss: 0.884729 train_acc: 0.746269 train_f1: 0.746269 time: 1.3927s
INFO:root:Epoch: 0310 val_loss: 1.073462 val_acc: 0.661172 val_f1: 0.661172
INFO:root:Epoch: 0320 lr: [0.0005, 0.0005] train_loss: 0.885407 train_acc: 0.765907 train_f1: 0.765907 time: 1.3974s
INFO:root:Epoch: 0320 val_loss: 1.072502 val_acc: 0.668498 val_f1: 0.668498
INFO:root:Epoch: 0330 lr: [0.0005, 0.0005] train_loss: 0.886819 train_acc: 0.771799 train_f1: 0.771799 time: 1.3974s
INFO:root:Epoch: 0330 val_loss: 1.070796 val_acc: 0.673993 val_f1: 0.673993
INFO:root:Epoch: 0340 lr: [0.0005, 0.0005] train_loss: 0.880163 train_acc: 0.758837 train_f1: 0.758837 time: 1.4043s
INFO:root:Epoch: 0340 val_loss: 1.066998 val_acc: 0.681319 val_f1: 0.681319
INFO:root:Epoch: 0350 lr: [0.0005, 0.0005] train_loss: 0.866948 train_acc: 0.826002 train_f1: 0.826002 time: 1.4032s
INFO:root:Epoch: 0350 val_loss: 1.056090 val_acc: 0.717949 val_f1: 0.717949
INFO:root:Epoch: 0360 lr: [0.0005, 0.0005] train_loss: 0.836179 train_acc: 0.847604 train_f1: 0.847604 time: 1.3960s
INFO:root:Epoch: 0360 val_loss: 1.103436 val_acc: 0.705128 val_f1: 0.705128
INFO:root:Epoch: 0370 lr: [0.0005, 0.0005] train_loss: 0.806886 train_acc: 0.863708 train_f1: 0.863708 time: 1.3974s
INFO:root:Epoch: 0370 val_loss: 1.052104 val_acc: 0.708791 val_f1: 0.708791
INFO:root:Epoch: 0380 lr: [0.0005, 0.0005] train_loss: 0.753818 train_acc: 0.864101 train_f1: 0.864101 time: 1.4095s
INFO:root:Epoch: 0380 val_loss: 1.060774 val_acc: 0.728938 val_f1: 0.728938
INFO:root:Epoch: 0390 lr: [0.0005, 0.0005] train_loss: 0.770568 train_acc: 0.950903 train_f1: 0.950903 time: 1.4310s
INFO:root:Epoch: 0390 val_loss: 1.071938 val_acc: 0.761905 val_f1: 0.761905
INFO:root:Epoch: 0400 lr: [0.00025, 0.00025] train_loss: 0.775816 train_acc: 0.958366 train_f1: 0.958366 time: 1.4016s
INFO:root:Epoch: 0400 val_loss: 1.038463 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 0410 lr: [0.00025, 0.00025] train_loss: 0.761934 train_acc: 0.977219 train_f1: 0.977219 time: 1.4022s
INFO:root:Epoch: 0410 val_loss: 1.040270 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0420 lr: [0.00025, 0.00025] train_loss: 0.760757 train_acc: 0.965436 train_f1: 0.965436 time: 1.4017s
INFO:root:Epoch: 0420 val_loss: 1.048621 val_acc: 0.761905 val_f1: 0.761905
INFO:root:Epoch: 0430 lr: [0.00025, 0.00025] train_loss: 0.761758 train_acc: 0.868028 train_f1: 0.868028 time: 1.4300s
INFO:root:Epoch: 0430 val_loss: 1.059682 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0440 lr: [0.00025, 0.00025] train_loss: 0.744781 train_acc: 0.932050 train_f1: 0.932050 time: 1.4040s
INFO:root:Epoch: 0440 val_loss: 1.054181 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 0450 lr: [0.00025, 0.00025] train_loss: 0.736256 train_acc: 0.955617 train_f1: 0.955617 time: 1.3971s
INFO:root:Epoch: 0450 val_loss: 1.062189 val_acc: 0.761905 val_f1: 0.761905
INFO:root:Epoch: 0460 lr: [0.00025, 0.00025] train_loss: 0.718455 train_acc: 0.978397 train_f1: 0.978397 time: 1.4030s
INFO:root:Epoch: 0460 val_loss: 1.072608 val_acc: 0.758242 val_f1: 0.758242
INFO:root:Epoch: 0470 lr: [0.00025, 0.00025] train_loss: 0.714822 train_acc: 0.967007 train_f1: 0.967007 time: 1.4037s
INFO:root:Epoch: 0470 val_loss: 1.085430 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0480 lr: [0.00025, 0.00025] train_loss: 0.702672 train_acc: 0.981540 train_f1: 0.981540 time: 1.3976s
INFO:root:Epoch: 0480 val_loss: 1.091391 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0490 lr: [0.00025, 0.00025] train_loss: 0.699032 train_acc: 0.976041 train_f1: 0.976041 time: 1.3975s
INFO:root:Epoch: 0490 val_loss: 1.101492 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0500 lr: [0.00025, 0.00025] train_loss: 0.695954 train_acc: 0.978790 train_f1: 0.978790 time: 1.4013s
INFO:root:Epoch: 0500 val_loss: 1.132617 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0510 lr: [0.00025, 0.00025] train_loss: 0.719491 train_acc: 0.983111 train_f1: 0.983111 time: 1.3965s
INFO:root:Epoch: 0510 val_loss: 1.068074 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0520 lr: [0.00025, 0.00025] train_loss: 0.723125 train_acc: 0.981932 train_f1: 0.981932 time: 1.4051s
INFO:root:Epoch: 0520 val_loss: 1.042015 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 0530 lr: [0.00025, 0.00025] train_loss: 0.724779 train_acc: 0.978005 train_f1: 0.978005 time: 1.4025s
INFO:root:Epoch: 0530 val_loss: 1.038448 val_acc: 0.754579 val_f1: 0.754579
INFO:root:Epoch: 0540 lr: [0.00025, 0.00025] train_loss: 0.715207 train_acc: 0.982325 train_f1: 0.982325 time: 1.3974s
INFO:root:Epoch: 0540 val_loss: 1.042406 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 0550 lr: [0.00025, 0.00025] train_loss: 0.708783 train_acc: 0.984682 train_f1: 0.984682 time: 1.3958s
INFO:root:Epoch: 0550 val_loss: 1.045720 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 0560 lr: [0.00025, 0.00025] train_loss: 0.703785 train_acc: 0.983111 train_f1: 0.983111 time: 1.4003s
INFO:root:Epoch: 0560 val_loss: 1.050618 val_acc: 0.763736 val_f1: 0.763736
INFO:root:Epoch: 0570 lr: [0.00025, 0.00025] train_loss: 0.708176 train_acc: 0.919089 train_f1: 0.919089 time: 1.4021s
INFO:root:Epoch: 0570 val_loss: 1.066603 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0580 lr: [0.00025, 0.00025] train_loss: 0.689471 train_acc: 0.960330 train_f1: 0.960330 time: 1.4040s
INFO:root:Epoch: 0580 val_loss: 1.076342 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0590 lr: [0.00025, 0.00025] train_loss: 0.685361 train_acc: 0.982325 train_f1: 0.982325 time: 1.3993s
INFO:root:Epoch: 0590 val_loss: 1.090619 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0600 lr: [0.000125, 0.000125] train_loss: 0.673910 train_acc: 0.984289 train_f1: 0.984289 time: 1.4001s
INFO:root:Epoch: 0600 val_loss: 1.121069 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0610 lr: [0.000125, 0.000125] train_loss: 0.675248 train_acc: 0.985860 train_f1: 0.985860 time: 1.3955s
INFO:root:Epoch: 0610 val_loss: 1.132692 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0620 lr: [0.000125, 0.000125] train_loss: 0.668342 train_acc: 0.985467 train_f1: 0.985467 time: 1.3993s
INFO:root:Epoch: 0620 val_loss: 1.154305 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0630 lr: [0.000125, 0.000125] train_loss: 0.673511 train_acc: 0.985075 train_f1: 0.985075 time: 1.4009s
INFO:root:Epoch: 0630 val_loss: 1.140801 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0640 lr: [0.000125, 0.000125] train_loss: 0.672679 train_acc: 0.985467 train_f1: 0.985467 time: 1.4018s
INFO:root:Epoch: 0640 val_loss: 1.135549 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0650 lr: [0.000125, 0.000125] train_loss: 0.667883 train_acc: 0.985467 train_f1: 0.985467 time: 1.3998s
INFO:root:Epoch: 0650 val_loss: 1.144115 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0660 lr: [0.000125, 0.000125] train_loss: 0.671358 train_acc: 0.985075 train_f1: 0.985075 time: 1.3990s
INFO:root:Epoch: 0660 val_loss: 1.153561 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0670 lr: [0.000125, 0.000125] train_loss: 0.666383 train_acc: 0.986253 train_f1: 0.986253 time: 1.3995s
INFO:root:Epoch: 0670 val_loss: 1.181335 val_acc: 0.763736 val_f1: 0.763736
INFO:root:Epoch: 0680 lr: [0.000125, 0.000125] train_loss: 0.670223 train_acc: 0.984289 train_f1: 0.984289 time: 1.4018s
INFO:root:Epoch: 0680 val_loss: 1.183521 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0690 lr: [0.000125, 0.000125] train_loss: 0.662437 train_acc: 0.985860 train_f1: 0.985860 time: 1.4035s
INFO:root:Epoch: 0690 val_loss: 1.191965 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0700 lr: [0.000125, 0.000125] train_loss: 0.679199 train_acc: 0.984289 train_f1: 0.984289 time: 1.4043s
INFO:root:Epoch: 0700 val_loss: 1.176748 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0710 lr: [0.000125, 0.000125] train_loss: 0.670450 train_acc: 0.986253 train_f1: 0.986253 time: 1.4022s
INFO:root:Epoch: 0710 val_loss: 1.134589 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0720 lr: [0.000125, 0.000125] train_loss: 0.670010 train_acc: 0.985860 train_f1: 0.985860 time: 1.3939s
INFO:root:Epoch: 0720 val_loss: 1.128504 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0730 lr: [0.000125, 0.000125] train_loss: 0.667157 train_acc: 0.985467 train_f1: 0.985467 time: 1.3963s
INFO:root:Epoch: 0730 val_loss: 1.136951 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Epoch: 0740 lr: [0.000125, 0.000125] train_loss: 0.663914 train_acc: 0.986646 train_f1: 0.986646 time: 1.3963s
INFO:root:Epoch: 0740 val_loss: 1.152129 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0750 lr: [0.000125, 0.000125] train_loss: 0.656548 train_acc: 0.985075 train_f1: 0.985075 time: 1.3980s
INFO:root:Epoch: 0750 val_loss: 1.189733 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0760 lr: [0.000125, 0.000125] train_loss: 0.655183 train_acc: 0.987038 train_f1: 0.987038 time: 1.3991s
INFO:root:Epoch: 0760 val_loss: 1.183038 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0770 lr: [0.000125, 0.000125] train_loss: 0.660200 train_acc: 0.987431 train_f1: 0.987431 time: 1.4008s
INFO:root:Epoch: 0770 val_loss: 1.149243 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0780 lr: [0.000125, 0.000125] train_loss: 0.657642 train_acc: 0.986253 train_f1: 0.986253 time: 1.4041s
INFO:root:Epoch: 0780 val_loss: 1.158352 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0790 lr: [0.000125, 0.000125] train_loss: 0.657261 train_acc: 0.984289 train_f1: 0.984289 time: 1.3959s
INFO:root:Epoch: 0790 val_loss: 1.182618 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 0800 lr: [6.25e-05, 6.25e-05] train_loss: 0.662644 train_acc: 0.986253 train_f1: 0.986253 time: 1.4017s
INFO:root:Epoch: 0800 val_loss: 1.158787 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0810 lr: [6.25e-05, 6.25e-05] train_loss: 0.657670 train_acc: 0.987431 train_f1: 0.987431 time: 1.4005s
INFO:root:Epoch: 0810 val_loss: 1.146594 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0820 lr: [6.25e-05, 6.25e-05] train_loss: 0.658738 train_acc: 0.987038 train_f1: 0.987038 time: 1.4033s
INFO:root:Epoch: 0820 val_loss: 1.158223 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0830 lr: [6.25e-05, 6.25e-05] train_loss: 0.656078 train_acc: 0.987824 train_f1: 0.987824 time: 1.4006s
INFO:root:Epoch: 0830 val_loss: 1.163504 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0840 lr: [6.25e-05, 6.25e-05] train_loss: 0.655712 train_acc: 0.983896 train_f1: 0.983896 time: 1.3967s
INFO:root:Epoch: 0840 val_loss: 1.173891 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0850 lr: [6.25e-05, 6.25e-05] train_loss: 0.658400 train_acc: 0.987431 train_f1: 0.987431 time: 1.4025s
INFO:root:Epoch: 0850 val_loss: 1.157011 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0860 lr: [6.25e-05, 6.25e-05] train_loss: 0.652960 train_acc: 0.985860 train_f1: 0.985860 time: 1.4021s
INFO:root:Epoch: 0860 val_loss: 1.172540 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0870 lr: [6.25e-05, 6.25e-05] train_loss: 0.653082 train_acc: 0.987431 train_f1: 0.987431 time: 1.3982s
INFO:root:Epoch: 0870 val_loss: 1.184635 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 0880 lr: [6.25e-05, 6.25e-05] train_loss: 0.650664 train_acc: 0.987824 train_f1: 0.987824 time: 1.4037s
INFO:root:Epoch: 0880 val_loss: 1.173808 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0890 lr: [6.25e-05, 6.25e-05] train_loss: 0.654462 train_acc: 0.986253 train_f1: 0.986253 time: 1.4005s
INFO:root:Epoch: 0890 val_loss: 1.156409 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0900 lr: [6.25e-05, 6.25e-05] train_loss: 0.649595 train_acc: 0.987431 train_f1: 0.987431 time: 1.4030s
INFO:root:Epoch: 0900 val_loss: 1.151787 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0910 lr: [6.25e-05, 6.25e-05] train_loss: 0.651758 train_acc: 0.986646 train_f1: 0.986646 time: 1.4050s
INFO:root:Epoch: 0910 val_loss: 1.156986 val_acc: 0.763736 val_f1: 0.763736
INFO:root:Epoch: 0920 lr: [6.25e-05, 6.25e-05] train_loss: 0.652047 train_acc: 0.987431 train_f1: 0.987431 time: 1.3975s
INFO:root:Epoch: 0920 val_loss: 1.171106 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0930 lr: [6.25e-05, 6.25e-05] train_loss: 0.653386 train_acc: 0.987431 train_f1: 0.987431 time: 1.3977s
INFO:root:Epoch: 0930 val_loss: 1.182722 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0940 lr: [6.25e-05, 6.25e-05] train_loss: 0.654532 train_acc: 0.987038 train_f1: 0.987038 time: 1.4013s
INFO:root:Epoch: 0940 val_loss: 1.151270 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 0950 lr: [6.25e-05, 6.25e-05] train_loss: 0.649933 train_acc: 0.987431 train_f1: 0.987431 time: 1.3966s
INFO:root:Epoch: 0950 val_loss: 1.150034 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 0960 lr: [6.25e-05, 6.25e-05] train_loss: 0.648779 train_acc: 0.987824 train_f1: 0.987824 time: 1.3978s
INFO:root:Epoch: 0960 val_loss: 1.166086 val_acc: 0.772894 val_f1: 0.772894
INFO:root:Epoch: 0970 lr: [6.25e-05, 6.25e-05] train_loss: 0.649581 train_acc: 0.987824 train_f1: 0.987824 time: 1.4003s
INFO:root:Epoch: 0970 val_loss: 1.169544 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0980 lr: [6.25e-05, 6.25e-05] train_loss: 0.654290 train_acc: 0.987431 train_f1: 0.987431 time: 1.3977s
INFO:root:Epoch: 0980 val_loss: 1.164250 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 0990 lr: [6.25e-05, 6.25e-05] train_loss: 0.659843 train_acc: 0.987824 train_f1: 0.987824 time: 1.4035s
INFO:root:Epoch: 0990 val_loss: 1.160031 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 1000 lr: [3.125e-05, 3.125e-05] train_loss: 0.650935 train_acc: 0.987824 train_f1: 0.987824 time: 1.3986s
INFO:root:Epoch: 1000 val_loss: 1.167772 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 1010 lr: [3.125e-05, 3.125e-05] train_loss: 0.649808 train_acc: 0.986646 train_f1: 0.986646 time: 1.3988s
INFO:root:Epoch: 1010 val_loss: 1.176373 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 1020 lr: [3.125e-05, 3.125e-05] train_loss: 0.651533 train_acc: 0.979183 train_f1: 0.979183 time: 1.4057s
INFO:root:Epoch: 1020 val_loss: 1.155955 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 1030 lr: [3.125e-05, 3.125e-05] train_loss: 0.650048 train_acc: 0.987431 train_f1: 0.987431 time: 1.3985s
INFO:root:Epoch: 1030 val_loss: 1.149366 val_acc: 0.767399 val_f1: 0.767399
INFO:root:Epoch: 1040 lr: [3.125e-05, 3.125e-05] train_loss: 0.647026 train_acc: 0.987038 train_f1: 0.987038 time: 1.3986s
INFO:root:Epoch: 1040 val_loss: 1.148735 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 1050 lr: [3.125e-05, 3.125e-05] train_loss: 0.646586 train_acc: 0.987431 train_f1: 0.987431 time: 1.3977s
INFO:root:Epoch: 1050 val_loss: 1.154912 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 1060 lr: [3.125e-05, 3.125e-05] train_loss: 0.649035 train_acc: 0.987038 train_f1: 0.987038 time: 1.4051s
INFO:root:Epoch: 1060 val_loss: 1.159180 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 1070 lr: [3.125e-05, 3.125e-05] train_loss: 0.648710 train_acc: 0.987431 train_f1: 0.987431 time: 1.3992s
INFO:root:Epoch: 1070 val_loss: 1.164263 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 1080 lr: [3.125e-05, 3.125e-05] train_loss: 0.650439 train_acc: 0.986646 train_f1: 0.986646 time: 1.4032s
INFO:root:Epoch: 1080 val_loss: 1.172651 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 1090 lr: [3.125e-05, 3.125e-05] train_loss: 0.650317 train_acc: 0.987038 train_f1: 0.987038 time: 1.4267s
INFO:root:Epoch: 1090 val_loss: 1.176306 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Epoch: 1100 lr: [3.125e-05, 3.125e-05] train_loss: 0.646888 train_acc: 0.987038 train_f1: 0.987038 time: 1.3973s
INFO:root:Epoch: 1100 val_loss: 1.173352 val_acc: 0.765568 val_f1: 0.765568
INFO:root:Epoch: 1110 lr: [3.125e-05, 3.125e-05] train_loss: 0.650135 train_acc: 0.986253 train_f1: 0.986253 time: 1.4041s
INFO:root:Epoch: 1110 val_loss: 1.171426 val_acc: 0.771062 val_f1: 0.771062
INFO:root:Epoch: 1120 lr: [3.125e-05, 3.125e-05] train_loss: 0.646424 train_acc: 0.987038 train_f1: 0.987038 time: 1.3981s
INFO:root:Epoch: 1120 val_loss: 1.176335 val_acc: 0.769231 val_f1: 0.769231
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1606.0760s
INFO:root:Val set results: val_loss: 1.154305 val_acc: 0.774725 val_f1: 0.774725
INFO:root:Test set results: test_loss: 1.123329 test_acc: 0.767399 test_f1: 0.767399
