INFO:root:Using: cuda:7
INFO:root:Using seed 1.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(
      in_features=1703, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=False, act=None, dropout_rate=0.3
      (dropout): Dropout(p=0.3, inplace=False)
      (E_linear): Linear(in_features=1703, out_features=64, bias=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
            (1): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
            (2): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
            (3): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f4e1b9476d0>)
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
            (1): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
            (2): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
            (3): BLinear(
              in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=64, out_features=64, bias=False)
            )
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f4e1b9476d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 143173
INFO:root:Epoch: 0005 lr: [0.0003, 0.0003] train_loss: 1.574485 train_acc: 0.598361 train_f1: 0.598361 time: 0.1387s
INFO:root:Epoch: 0005 val_loss: 1.559077 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0010 lr: [0.0003, 0.0003] train_loss: 1.532087 train_acc: 0.598361 train_f1: 0.598361 time: 0.1434s
INFO:root:Epoch: 0010 val_loss: 1.510465 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0015 lr: [0.0003, 0.0003] train_loss: 1.491536 train_acc: 0.598361 train_f1: 0.598361 time: 0.1385s
INFO:root:Epoch: 0015 val_loss: 1.464153 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.0003, 0.0003] train_loss: 1.453624 train_acc: 0.598361 train_f1: 0.598361 time: 0.1472s
INFO:root:Epoch: 0020 val_loss: 1.420426 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0025 lr: [0.0003, 0.0003] train_loss: 1.417400 train_acc: 0.598361 train_f1: 0.598361 time: 0.1435s
INFO:root:Epoch: 0025 val_loss: 1.379369 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.0003, 0.0003] train_loss: 1.383346 train_acc: 0.598361 train_f1: 0.598361 time: 0.1492s
INFO:root:Epoch: 0030 val_loss: 1.340946 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0035 lr: [0.0003, 0.0003] train_loss: 1.352485 train_acc: 0.598361 train_f1: 0.598361 time: 0.1375s
INFO:root:Epoch: 0035 val_loss: 1.305121 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.0003, 0.0003] train_loss: 1.322926 train_acc: 0.598361 train_f1: 0.598361 time: 0.1482s
INFO:root:Epoch: 0040 val_loss: 1.271800 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0045 lr: [0.0003, 0.0003] train_loss: 1.296137 train_acc: 0.598361 train_f1: 0.598361 time: 0.1386s
INFO:root:Epoch: 0045 val_loss: 1.241007 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.0003, 0.0003] train_loss: 1.271854 train_acc: 0.598361 train_f1: 0.598361 time: 0.1511s
INFO:root:Epoch: 0050 val_loss: 1.212793 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0055 lr: [0.0003, 0.0003] train_loss: 1.249987 train_acc: 0.598361 train_f1: 0.598361 time: 0.1386s
INFO:root:Epoch: 0055 val_loss: 1.187395 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.0003, 0.0003] train_loss: 1.230227 train_acc: 0.598361 train_f1: 0.598361 time: 0.1535s
INFO:root:Epoch: 0060 val_loss: 1.164763 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0065 lr: [0.0003, 0.0003] train_loss: 1.213308 train_acc: 0.598361 train_f1: 0.598361 time: 0.1414s
INFO:root:Epoch: 0065 val_loss: 1.144748 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.0003, 0.0003] train_loss: 1.198068 train_acc: 0.598361 train_f1: 0.598361 time: 0.1495s
INFO:root:Epoch: 0070 val_loss: 1.127363 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0075 lr: [0.0003, 0.0003] train_loss: 1.185163 train_acc: 0.598361 train_f1: 0.598361 time: 0.1398s
INFO:root:Epoch: 0075 val_loss: 1.112556 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.0003, 0.0003] train_loss: 1.174554 train_acc: 0.598361 train_f1: 0.598361 time: 0.1500s
INFO:root:Epoch: 0080 val_loss: 1.100136 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0085 lr: [0.0003, 0.0003] train_loss: 1.165988 train_acc: 0.598361 train_f1: 0.598361 time: 0.1384s
INFO:root:Epoch: 0085 val_loss: 1.089894 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.0003, 0.0003] train_loss: 1.157753 train_acc: 0.598361 train_f1: 0.598361 time: 0.1426s
INFO:root:Epoch: 0090 val_loss: 1.081024 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0095 lr: [0.0003, 0.0003] train_loss: 1.151198 train_acc: 0.598361 train_f1: 0.598361 time: 0.1409s
INFO:root:Epoch: 0095 val_loss: 1.073309 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.0003, 0.0003] train_loss: 1.144623 train_acc: 0.598361 train_f1: 0.598361 time: 0.1577s
INFO:root:Epoch: 0100 val_loss: 1.066295 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0105 lr: [0.0003, 0.0003] train_loss: 1.137365 train_acc: 0.598361 train_f1: 0.598361 time: 0.1516s
INFO:root:Epoch: 0105 val_loss: 1.059741 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.0003, 0.0003] train_loss: 1.130293 train_acc: 0.598361 train_f1: 0.598361 time: 0.1401s
INFO:root:Epoch: 0110 val_loss: 1.053235 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0115 lr: [0.0003, 0.0003] train_loss: 1.122735 train_acc: 0.598361 train_f1: 0.598361 time: 0.1391s
INFO:root:Epoch: 0115 val_loss: 1.045953 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.0003, 0.0003] train_loss: 1.116618 train_acc: 0.598361 train_f1: 0.598361 time: 0.1419s
INFO:root:Epoch: 0120 val_loss: 1.037867 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0125 lr: [0.0003, 0.0003] train_loss: 1.105537 train_acc: 0.598361 train_f1: 0.598361 time: 0.1377s
INFO:root:Epoch: 0125 val_loss: 1.030157 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.0003, 0.0003] train_loss: 1.097502 train_acc: 0.598361 train_f1: 0.598361 time: 0.1414s
INFO:root:Epoch: 0130 val_loss: 1.022349 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0135 lr: [0.0003, 0.0003] train_loss: 1.085609 train_acc: 0.598361 train_f1: 0.598361 time: 0.1399s
INFO:root:Epoch: 0135 val_loss: 1.013483 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.0003, 0.0003] train_loss: 1.073964 train_acc: 0.598361 train_f1: 0.598361 time: 0.1393s
INFO:root:Epoch: 0140 val_loss: 1.002815 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0145 lr: [0.0003, 0.0003] train_loss: 1.063798 train_acc: 0.598361 train_f1: 0.598361 time: 0.1466s
INFO:root:Epoch: 0145 val_loss: 0.992386 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.0003, 0.0003] train_loss: 1.052893 train_acc: 0.598361 train_f1: 0.598361 time: 0.1540s
INFO:root:Epoch: 0150 val_loss: 0.983207 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0155 lr: [0.0003, 0.0003] train_loss: 1.040784 train_acc: 0.598361 train_f1: 0.598361 time: 0.1494s
INFO:root:Epoch: 0155 val_loss: 0.972148 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.0003, 0.0003] train_loss: 1.025419 train_acc: 0.598361 train_f1: 0.598361 time: 0.1386s
INFO:root:Epoch: 0160 val_loss: 0.958329 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0165 lr: [0.0003, 0.0003] train_loss: 1.015152 train_acc: 0.598361 train_f1: 0.598361 time: 0.1476s
INFO:root:Epoch: 0165 val_loss: 0.945337 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0170 lr: [0.0003, 0.0003] train_loss: 0.999855 train_acc: 0.598361 train_f1: 0.598361 time: 0.2093s
INFO:root:Epoch: 0170 val_loss: 0.932809 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0175 lr: [0.0003, 0.0003] train_loss: 0.988215 train_acc: 0.598361 train_f1: 0.598361 time: 0.1491s
INFO:root:Epoch: 0175 val_loss: 0.921068 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0180 lr: [0.0003, 0.0003] train_loss: 0.973749 train_acc: 0.598361 train_f1: 0.598361 time: 0.1416s
INFO:root:Epoch: 0180 val_loss: 0.909417 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0185 lr: [0.0003, 0.0003] train_loss: 0.962224 train_acc: 0.598361 train_f1: 0.598361 time: 0.1459s
INFO:root:Epoch: 0185 val_loss: 0.896516 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0190 lr: [0.0003, 0.0003] train_loss: 0.950728 train_acc: 0.598361 train_f1: 0.598361 time: 0.1413s
INFO:root:Epoch: 0190 val_loss: 0.882304 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0195 lr: [0.0003, 0.0003] train_loss: 0.935932 train_acc: 0.598361 train_f1: 0.598361 time: 0.1438s
INFO:root:Epoch: 0195 val_loss: 0.870838 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0200 lr: [0.0003, 0.0003] train_loss: 0.924488 train_acc: 0.598361 train_f1: 0.598361 time: 0.1397s
INFO:root:Epoch: 0200 val_loss: 0.862965 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0205 lr: [0.0003, 0.0003] train_loss: 0.916126 train_acc: 0.598361 train_f1: 0.598361 time: 0.1415s
INFO:root:Epoch: 0205 val_loss: 0.851066 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0210 lr: [0.0003, 0.0003] train_loss: 0.902237 train_acc: 0.598361 train_f1: 0.598361 time: 0.1408s
INFO:root:Epoch: 0210 val_loss: 0.837384 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0215 lr: [0.0003, 0.0003] train_loss: 0.893914 train_acc: 0.598361 train_f1: 0.598361 time: 0.1460s
INFO:root:Epoch: 0215 val_loss: 0.827440 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0220 lr: [0.0003, 0.0003] train_loss: 0.884173 train_acc: 0.598361 train_f1: 0.598361 time: 0.1420s
INFO:root:Epoch: 0220 val_loss: 0.819976 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0225 lr: [0.0003, 0.0003] train_loss: 0.875391 train_acc: 0.598361 train_f1: 0.598361 time: 0.1419s
INFO:root:Epoch: 0225 val_loss: 0.810398 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0230 lr: [0.0003, 0.0003] train_loss: 0.865171 train_acc: 0.598361 train_f1: 0.598361 time: 0.1400s
INFO:root:Epoch: 0230 val_loss: 0.801981 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0235 lr: [0.0003, 0.0003] train_loss: 0.857929 train_acc: 0.598361 train_f1: 0.598361 time: 0.1436s
INFO:root:Epoch: 0235 val_loss: 0.794590 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0240 lr: [0.0003, 0.0003] train_loss: 0.848844 train_acc: 0.598361 train_f1: 0.598361 time: 0.1415s
INFO:root:Epoch: 0240 val_loss: 0.785375 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0245 lr: [0.0003, 0.0003] train_loss: 0.843683 train_acc: 0.598361 train_f1: 0.598361 time: 0.1390s
INFO:root:Epoch: 0245 val_loss: 0.776150 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0250 lr: [0.0003, 0.0003] train_loss: 0.830918 train_acc: 0.598361 train_f1: 0.598361 time: 0.1394s
INFO:root:Epoch: 0250 val_loss: 0.769154 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0255 lr: [0.0003, 0.0003] train_loss: 0.825704 train_acc: 0.598361 train_f1: 0.598361 time: 0.1393s
INFO:root:Epoch: 0255 val_loss: 0.760990 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0260 lr: [0.0003, 0.0003] train_loss: 0.815533 train_acc: 0.598361 train_f1: 0.598361 time: 0.1419s
INFO:root:Epoch: 0260 val_loss: 0.754428 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0265 lr: [0.0003, 0.0003] train_loss: 0.810475 train_acc: 0.598361 train_f1: 0.598361 time: 0.1409s
INFO:root:Epoch: 0265 val_loss: 0.748216 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0270 lr: [0.0003, 0.0003] train_loss: 0.802181 train_acc: 0.598361 train_f1: 0.598361 time: 0.1410s
INFO:root:Epoch: 0270 val_loss: 0.741855 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0275 lr: [0.0003, 0.0003] train_loss: 0.797124 train_acc: 0.598361 train_f1: 0.598361 time: 0.1381s
INFO:root:Epoch: 0275 val_loss: 0.733979 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0280 lr: [0.0003, 0.0003] train_loss: 0.790461 train_acc: 0.598361 train_f1: 0.598361 time: 0.1400s
INFO:root:Epoch: 0280 val_loss: 0.725732 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0285 lr: [0.0003, 0.0003] train_loss: 0.784699 train_acc: 0.598361 train_f1: 0.598361 time: 0.1387s
INFO:root:Epoch: 0285 val_loss: 0.719247 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0290 lr: [0.0003, 0.0003] train_loss: 0.775912 train_acc: 0.598361 train_f1: 0.598361 time: 0.1401s
INFO:root:Epoch: 0290 val_loss: 0.711460 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0295 lr: [0.0003, 0.0003] train_loss: 0.770401 train_acc: 0.643443 train_f1: 0.643443 time: 0.1409s
INFO:root:Epoch: 0295 val_loss: 0.706456 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0300 lr: [0.0003, 0.0003] train_loss: 0.765701 train_acc: 0.717213 train_f1: 0.717213 time: 0.1387s
INFO:root:Epoch: 0300 val_loss: 0.702030 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0305 lr: [0.0003, 0.0003] train_loss: 0.757927 train_acc: 0.770492 train_f1: 0.770492 time: 0.1417s
INFO:root:Epoch: 0305 val_loss: 0.699226 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0310 lr: [0.0003, 0.0003] train_loss: 0.751014 train_acc: 0.786885 train_f1: 0.786885 time: 0.1389s
INFO:root:Epoch: 0310 val_loss: 0.695033 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0315 lr: [0.0003, 0.0003] train_loss: 0.746831 train_acc: 0.786885 train_f1: 0.786885 time: 0.1391s
INFO:root:Epoch: 0315 val_loss: 0.687323 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0320 lr: [0.0003, 0.0003] train_loss: 0.742745 train_acc: 0.786885 train_f1: 0.786885 time: 0.1447s
INFO:root:Epoch: 0320 val_loss: 0.680152 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0325 lr: [0.0003, 0.0003] train_loss: 0.737085 train_acc: 0.758197 train_f1: 0.758197 time: 0.1393s
INFO:root:Epoch: 0325 val_loss: 0.674488 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0330 lr: [0.0003, 0.0003] train_loss: 0.732404 train_acc: 0.786885 train_f1: 0.786885 time: 0.1436s
INFO:root:Epoch: 0330 val_loss: 0.668665 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0335 lr: [0.0003, 0.0003] train_loss: 0.725977 train_acc: 0.786885 train_f1: 0.786885 time: 0.1407s
INFO:root:Epoch: 0335 val_loss: 0.662194 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0340 lr: [0.0003, 0.0003] train_loss: 0.723809 train_acc: 0.782787 train_f1: 0.782787 time: 0.1565s
INFO:root:Epoch: 0340 val_loss: 0.657169 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0345 lr: [0.0003, 0.0003] train_loss: 0.720707 train_acc: 0.786885 train_f1: 0.786885 time: 0.1402s
INFO:root:Epoch: 0345 val_loss: 0.661002 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0350 lr: [0.0003, 0.0003] train_loss: 0.719366 train_acc: 0.598361 train_f1: 0.598361 time: 0.1451s
INFO:root:Epoch: 0350 val_loss: 0.650281 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0355 lr: [0.0003, 0.0003] train_loss: 0.717151 train_acc: 0.786885 train_f1: 0.786885 time: 0.1403s
INFO:root:Epoch: 0355 val_loss: 0.658773 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0360 lr: [0.0003, 0.0003] train_loss: 0.713493 train_acc: 0.782787 train_f1: 0.782787 time: 0.1585s
INFO:root:Epoch: 0360 val_loss: 0.657622 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0365 lr: [0.0003, 0.0003] train_loss: 0.712737 train_acc: 0.786885 train_f1: 0.786885 time: 0.1418s
INFO:root:Epoch: 0365 val_loss: 0.650002 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0370 lr: [0.0003, 0.0003] train_loss: 0.708800 train_acc: 0.786885 train_f1: 0.786885 time: 0.1486s
INFO:root:Epoch: 0370 val_loss: 0.649835 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0375 lr: [0.0003, 0.0003] train_loss: 0.706957 train_acc: 0.778689 train_f1: 0.778689 time: 0.1404s
INFO:root:Epoch: 0375 val_loss: 0.648327 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0380 lr: [0.0003, 0.0003] train_loss: 0.702820 train_acc: 0.786885 train_f1: 0.786885 time: 0.1480s
INFO:root:Epoch: 0380 val_loss: 0.641893 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0385 lr: [0.0003, 0.0003] train_loss: 0.699760 train_acc: 0.786885 train_f1: 0.786885 time: 0.1403s
INFO:root:Epoch: 0385 val_loss: 0.640902 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0390 lr: [0.0003, 0.0003] train_loss: 0.700675 train_acc: 0.786885 train_f1: 0.786885 time: 0.1526s
INFO:root:Epoch: 0390 val_loss: 0.639286 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0395 lr: [0.0003, 0.0003] train_loss: 0.695274 train_acc: 0.786885 train_f1: 0.786885 time: 0.1411s
INFO:root:Epoch: 0395 val_loss: 0.635668 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0400 lr: [0.0003, 0.0003] train_loss: 0.695883 train_acc: 0.782787 train_f1: 0.782787 time: 0.1549s
INFO:root:Epoch: 0400 val_loss: 0.658542 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0405 lr: [0.0003, 0.0003] train_loss: 0.705321 train_acc: 0.786885 train_f1: 0.786885 time: 0.1403s
INFO:root:Epoch: 0405 val_loss: 0.631495 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0410 lr: [0.0003, 0.0003] train_loss: 0.694478 train_acc: 0.786885 train_f1: 0.786885 time: 0.1498s
INFO:root:Epoch: 0410 val_loss: 0.630346 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0415 lr: [0.0003, 0.0003] train_loss: 0.696431 train_acc: 0.786885 train_f1: 0.786885 time: 0.1401s
INFO:root:Epoch: 0415 val_loss: 0.640118 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0420 lr: [0.0003, 0.0003] train_loss: 0.690510 train_acc: 0.786885 train_f1: 0.786885 time: 0.1480s
INFO:root:Epoch: 0420 val_loss: 0.628625 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0425 lr: [0.0003, 0.0003] train_loss: 0.690587 train_acc: 0.786885 train_f1: 0.786885 time: 0.1407s
INFO:root:Epoch: 0425 val_loss: 0.626041 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0430 lr: [0.0003, 0.0003] train_loss: 0.688177 train_acc: 0.786885 train_f1: 0.786885 time: 0.1467s
INFO:root:Epoch: 0430 val_loss: 0.627787 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0435 lr: [0.0003, 0.0003] train_loss: 0.687580 train_acc: 0.786885 train_f1: 0.786885 time: 0.1399s
INFO:root:Epoch: 0435 val_loss: 0.629181 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0440 lr: [0.0003, 0.0003] train_loss: 0.686045 train_acc: 0.786885 train_f1: 0.786885 time: 0.1445s
INFO:root:Epoch: 0440 val_loss: 0.625347 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0445 lr: [0.0003, 0.0003] train_loss: 0.683417 train_acc: 0.786885 train_f1: 0.786885 time: 0.1409s
INFO:root:Epoch: 0445 val_loss: 0.621157 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 67.2149s
INFO:root:Val set results: val_loss: 0.706456 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Test set results: test_loss: 0.809423 test_acc: 0.750000 test_f1: 0.750000
