INFO:root:Using: cuda:7
INFO:root:Using seed 2003.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(
      in_features=1703, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=False, act=None, dropout_rate=0.3
      (dropout): Dropout(p=0.3, inplace=False)
      (E_linear): Linear(in_features=1703, out_features=32, bias=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (3): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (MLP_f): BMLP(
            (linear1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fa7502b36d0>)
            (linear2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fa7502b36d0>)
            (linear2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (3): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (MLP_f): BMLP(
            (linear1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fa7502b36d0>)
            (linear2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fa7502b36d0>)
            (linear2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 71845
INFO:root:Epoch: 0005 lr: [0.0002, 0.0002] train_loss: 1.586056 train_acc: 0.590164 train_f1: 0.590164 time: 0.1591s
INFO:root:Epoch: 0005 val_loss: 1.576895 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0010 lr: [0.0002, 0.0002] train_loss: 1.546787 train_acc: 0.610656 train_f1: 0.610656 time: 0.1434s
INFO:root:Epoch: 0010 val_loss: 1.545796 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0015 lr: [0.0002, 0.0002] train_loss: 1.514884 train_acc: 0.610656 train_f1: 0.610656 time: 0.1417s
INFO:root:Epoch: 0015 val_loss: 1.512151 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0020 lr: [0.0002, 0.0002] train_loss: 1.486904 train_acc: 0.610656 train_f1: 0.610656 time: 0.1428s
INFO:root:Epoch: 0020 val_loss: 1.480559 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0025 lr: [0.0002, 0.0002] train_loss: 1.458559 train_acc: 0.610656 train_f1: 0.610656 time: 0.1438s
INFO:root:Epoch: 0025 val_loss: 1.450170 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0030 lr: [0.0002, 0.0002] train_loss: 1.430878 train_acc: 0.610656 train_f1: 0.610656 time: 0.1416s
INFO:root:Epoch: 0030 val_loss: 1.422341 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0035 lr: [0.0002, 0.0002] train_loss: 1.426305 train_acc: 0.610656 train_f1: 0.610656 time: 0.1431s
INFO:root:Epoch: 0035 val_loss: 1.397264 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0040 lr: [0.0002, 0.0002] train_loss: 1.393532 train_acc: 0.610656 train_f1: 0.610656 time: 0.1483s
INFO:root:Epoch: 0040 val_loss: 1.374570 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0045 lr: [0.0002, 0.0002] train_loss: 1.369040 train_acc: 0.610656 train_f1: 0.610656 time: 0.1474s
INFO:root:Epoch: 0045 val_loss: 1.354795 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0050 lr: [0.0002, 0.0002] train_loss: 1.361448 train_acc: 0.610656 train_f1: 0.610656 time: 0.1455s
INFO:root:Epoch: 0050 val_loss: 1.337568 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0055 lr: [0.0002, 0.0002] train_loss: 1.338113 train_acc: 0.610656 train_f1: 0.610656 time: 0.1532s
INFO:root:Epoch: 0055 val_loss: 1.322700 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0060 lr: [0.0002, 0.0002] train_loss: 1.311825 train_acc: 0.610656 train_f1: 0.610656 time: 0.1418s
INFO:root:Epoch: 0060 val_loss: 1.308675 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0065 lr: [0.0002, 0.0002] train_loss: 1.313693 train_acc: 0.610656 train_f1: 0.610656 time: 0.1524s
INFO:root:Epoch: 0065 val_loss: 1.295258 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0070 lr: [0.0002, 0.0002] train_loss: 1.299448 train_acc: 0.610656 train_f1: 0.610656 time: 0.1430s
INFO:root:Epoch: 0070 val_loss: 1.283124 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0075 lr: [0.0002, 0.0002] train_loss: 1.280180 train_acc: 0.610656 train_f1: 0.610656 time: 0.1530s
INFO:root:Epoch: 0075 val_loss: 1.271827 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0080 lr: [0.0002, 0.0002] train_loss: 1.277232 train_acc: 0.610656 train_f1: 0.610656 time: 0.1466s
INFO:root:Epoch: 0080 val_loss: 1.260613 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0085 lr: [0.0002, 0.0002] train_loss: 1.263923 train_acc: 0.610656 train_f1: 0.610656 time: 0.1489s
INFO:root:Epoch: 0085 val_loss: 1.249522 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0090 lr: [0.0002, 0.0002] train_loss: 1.253414 train_acc: 0.610656 train_f1: 0.610656 time: 0.1433s
INFO:root:Epoch: 0090 val_loss: 1.239061 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0095 lr: [0.0002, 0.0002] train_loss: 1.256563 train_acc: 0.610656 train_f1: 0.610656 time: 0.1510s
INFO:root:Epoch: 0095 val_loss: 1.229862 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0100 lr: [0.0002, 0.0002] train_loss: 1.232243 train_acc: 0.610656 train_f1: 0.610656 time: 0.1473s
INFO:root:Epoch: 0100 val_loss: 1.221460 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0105 lr: [0.0002, 0.0002] train_loss: 1.236184 train_acc: 0.610656 train_f1: 0.610656 time: 0.1490s
INFO:root:Epoch: 0105 val_loss: 1.213430 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0110 lr: [0.0002, 0.0002] train_loss: 1.219418 train_acc: 0.610656 train_f1: 0.610656 time: 0.1429s
INFO:root:Epoch: 0110 val_loss: 1.206006 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0115 lr: [0.0002, 0.0002] train_loss: 1.215674 train_acc: 0.610656 train_f1: 0.610656 time: 0.1510s
INFO:root:Epoch: 0115 val_loss: 1.198999 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0120 lr: [0.0002, 0.0002] train_loss: 1.195738 train_acc: 0.610656 train_f1: 0.610656 time: 0.1469s
INFO:root:Epoch: 0120 val_loss: 1.192187 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0125 lr: [0.0002, 0.0002] train_loss: 1.192917 train_acc: 0.610656 train_f1: 0.610656 time: 0.1432s
INFO:root:Epoch: 0125 val_loss: 1.185774 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0130 lr: [0.0002, 0.0002] train_loss: 1.196089 train_acc: 0.610656 train_f1: 0.610656 time: 0.1432s
INFO:root:Epoch: 0130 val_loss: 1.179907 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0135 lr: [0.0002, 0.0002] train_loss: 1.181646 train_acc: 0.610656 train_f1: 0.610656 time: 0.1466s
INFO:root:Epoch: 0135 val_loss: 1.174647 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0140 lr: [0.0002, 0.0002] train_loss: 1.179902 train_acc: 0.610656 train_f1: 0.610656 time: 0.1444s
INFO:root:Epoch: 0140 val_loss: 1.169903 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0145 lr: [0.0002, 0.0002] train_loss: 1.178646 train_acc: 0.610656 train_f1: 0.610656 time: 0.1446s
INFO:root:Epoch: 0145 val_loss: 1.165567 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0150 lr: [0.0002, 0.0002] train_loss: 1.174328 train_acc: 0.610656 train_f1: 0.610656 time: 0.1437s
INFO:root:Epoch: 0150 val_loss: 1.161097 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0155 lr: [0.0002, 0.0002] train_loss: 1.168510 train_acc: 0.610656 train_f1: 0.610656 time: 0.1487s
INFO:root:Epoch: 0155 val_loss: 1.156950 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0160 lr: [0.0002, 0.0002] train_loss: 1.165880 train_acc: 0.610656 train_f1: 0.610656 time: 0.1476s
INFO:root:Epoch: 0160 val_loss: 1.153092 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0165 lr: [0.0002, 0.0002] train_loss: 1.172688 train_acc: 0.610656 train_f1: 0.610656 time: 0.1456s
INFO:root:Epoch: 0165 val_loss: 1.149258 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0170 lr: [0.0002, 0.0002] train_loss: 1.158030 train_acc: 0.610656 train_f1: 0.610656 time: 0.1541s
INFO:root:Epoch: 0170 val_loss: 1.145351 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0175 lr: [0.0002, 0.0002] train_loss: 1.146239 train_acc: 0.610656 train_f1: 0.610656 time: 0.1457s
INFO:root:Epoch: 0175 val_loss: 1.141572 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0180 lr: [0.0002, 0.0002] train_loss: 1.153352 train_acc: 0.610656 train_f1: 0.610656 time: 0.1539s
INFO:root:Epoch: 0180 val_loss: 1.137522 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0185 lr: [0.0002, 0.0002] train_loss: 1.148886 train_acc: 0.610656 train_f1: 0.610656 time: 0.1473s
INFO:root:Epoch: 0185 val_loss: 1.132971 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0190 lr: [0.0002, 0.0002] train_loss: 1.140313 train_acc: 0.610656 train_f1: 0.610656 time: 0.1499s
INFO:root:Epoch: 0190 val_loss: 1.128679 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0195 lr: [0.0002, 0.0002] train_loss: 1.130576 train_acc: 0.610656 train_f1: 0.610656 time: 0.1443s
INFO:root:Epoch: 0195 val_loss: 1.124440 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0200 lr: [0.0002, 0.0002] train_loss: 1.132959 train_acc: 0.610656 train_f1: 0.610656 time: 0.1523s
INFO:root:Epoch: 0200 val_loss: 1.120017 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0205 lr: [0.0002, 0.0002] train_loss: 1.123357 train_acc: 0.610656 train_f1: 0.610656 time: 0.1440s
INFO:root:Epoch: 0205 val_loss: 1.114921 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0210 lr: [0.0002, 0.0002] train_loss: 1.124686 train_acc: 0.610656 train_f1: 0.610656 time: 0.1658s
INFO:root:Epoch: 0210 val_loss: 1.108589 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0215 lr: [0.0002, 0.0002] train_loss: 1.116185 train_acc: 0.610656 train_f1: 0.610656 time: 0.1432s
INFO:root:Epoch: 0215 val_loss: 1.100038 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0220 lr: [0.0002, 0.0002] train_loss: 1.108648 train_acc: 0.610656 train_f1: 0.610656 time: 0.1508s
INFO:root:Epoch: 0220 val_loss: 1.087752 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0225 lr: [0.0002, 0.0002] train_loss: 1.098019 train_acc: 0.610656 train_f1: 0.610656 time: 0.1439s
INFO:root:Epoch: 0225 val_loss: 1.073602 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0230 lr: [0.0002, 0.0002] train_loss: 1.083677 train_acc: 0.610656 train_f1: 0.610656 time: 0.1478s
INFO:root:Epoch: 0230 val_loss: 1.051130 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0235 lr: [0.0002, 0.0002] train_loss: 1.080334 train_acc: 0.610656 train_f1: 0.610656 time: 0.1440s
INFO:root:Epoch: 0235 val_loss: 1.026280 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0240 lr: [0.0002, 0.0002] train_loss: 1.042141 train_acc: 0.610656 train_f1: 0.610656 time: 0.1455s
INFO:root:Epoch: 0240 val_loss: 0.999065 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0245 lr: [0.0002, 0.0002] train_loss: 1.027272 train_acc: 0.610656 train_f1: 0.610656 time: 0.1443s
INFO:root:Epoch: 0245 val_loss: 0.972833 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0250 lr: [0.0002, 0.0002] train_loss: 1.026086 train_acc: 0.610656 train_f1: 0.610656 time: 0.1459s
INFO:root:Epoch: 0250 val_loss: 0.951865 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0255 lr: [0.0002, 0.0002] train_loss: 0.969470 train_acc: 0.610656 train_f1: 0.610656 time: 0.1428s
INFO:root:Epoch: 0255 val_loss: 0.932447 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0260 lr: [0.0002, 0.0002] train_loss: 0.966931 train_acc: 0.610656 train_f1: 0.610656 time: 0.1449s
INFO:root:Epoch: 0260 val_loss: 0.910703 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0265 lr: [0.0002, 0.0002] train_loss: 0.953138 train_acc: 0.610656 train_f1: 0.610656 time: 0.1458s
INFO:root:Epoch: 0265 val_loss: 0.896204 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0270 lr: [0.0002, 0.0002] train_loss: 0.936169 train_acc: 0.610656 train_f1: 0.610656 time: 0.1437s
INFO:root:Epoch: 0270 val_loss: 0.872456 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0275 lr: [0.0002, 0.0002] train_loss: 0.944434 train_acc: 0.610656 train_f1: 0.610656 time: 0.1483s
INFO:root:Epoch: 0275 val_loss: 0.865731 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0280 lr: [0.0002, 0.0002] train_loss: 0.926724 train_acc: 0.610656 train_f1: 0.610656 time: 0.1433s
INFO:root:Epoch: 0280 val_loss: 0.849145 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0285 lr: [0.0002, 0.0002] train_loss: 0.913926 train_acc: 0.610656 train_f1: 0.610656 time: 0.1542s
INFO:root:Epoch: 0285 val_loss: 0.858964 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0290 lr: [0.0002, 0.0002] train_loss: 0.881754 train_acc: 0.610656 train_f1: 0.610656 time: 0.1431s
INFO:root:Epoch: 0290 val_loss: 0.883961 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0295 lr: [0.0002, 0.0002] train_loss: 0.877482 train_acc: 0.610656 train_f1: 0.610656 time: 0.1492s
INFO:root:Epoch: 0295 val_loss: 0.853447 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0300 lr: [0.0002, 0.0002] train_loss: 0.877003 train_acc: 0.610656 train_f1: 0.610656 time: 0.1492s
INFO:root:Epoch: 0300 val_loss: 0.818709 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0305 lr: [0.0002, 0.0002] train_loss: 0.876369 train_acc: 0.610656 train_f1: 0.610656 time: 0.1521s
INFO:root:Epoch: 0305 val_loss: 0.818876 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0310 lr: [0.0002, 0.0002] train_loss: 0.870652 train_acc: 0.610656 train_f1: 0.610656 time: 0.1466s
INFO:root:Epoch: 0310 val_loss: 0.814338 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0315 lr: [0.0002, 0.0002] train_loss: 0.836182 train_acc: 0.610656 train_f1: 0.610656 time: 0.1537s
INFO:root:Epoch: 0315 val_loss: 0.801279 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0320 lr: [0.0002, 0.0002] train_loss: 0.829235 train_acc: 0.610656 train_f1: 0.610656 time: 0.1429s
INFO:root:Epoch: 0320 val_loss: 0.783417 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0325 lr: [0.0002, 0.0002] train_loss: 0.840648 train_acc: 0.655738 train_f1: 0.655738 time: 0.1525s
INFO:root:Epoch: 0325 val_loss: 0.775227 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0330 lr: [0.0002, 0.0002] train_loss: 0.808262 train_acc: 0.651639 train_f1: 0.651639 time: 0.1486s
INFO:root:Epoch: 0330 val_loss: 0.769163 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0335 lr: [0.0002, 0.0002] train_loss: 0.811984 train_acc: 0.659836 train_f1: 0.659836 time: 0.1599s
INFO:root:Epoch: 0335 val_loss: 0.764338 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0340 lr: [0.0002, 0.0002] train_loss: 0.810664 train_acc: 0.622951 train_f1: 0.622951 time: 0.1514s
INFO:root:Epoch: 0340 val_loss: 0.769814 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0345 lr: [0.0002, 0.0002] train_loss: 0.820330 train_acc: 0.635246 train_f1: 0.635246 time: 0.1516s
INFO:root:Epoch: 0345 val_loss: 0.767131 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0350 lr: [0.0002, 0.0002] train_loss: 0.787715 train_acc: 0.631148 train_f1: 0.631148 time: 0.1445s
INFO:root:Epoch: 0350 val_loss: 0.752784 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0355 lr: [0.0002, 0.0002] train_loss: 0.784574 train_acc: 0.668033 train_f1: 0.668033 time: 0.1491s
INFO:root:Epoch: 0355 val_loss: 0.750371 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0360 lr: [0.0002, 0.0002] train_loss: 0.787181 train_acc: 0.684426 train_f1: 0.684426 time: 0.1435s
INFO:root:Epoch: 0360 val_loss: 0.754325 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0365 lr: [0.0002, 0.0002] train_loss: 0.785209 train_acc: 0.659836 train_f1: 0.659836 time: 0.1534s
INFO:root:Epoch: 0365 val_loss: 0.744045 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0370 lr: [0.0002, 0.0002] train_loss: 0.761003 train_acc: 0.676230 train_f1: 0.676230 time: 0.1431s
INFO:root:Epoch: 0370 val_loss: 0.735024 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0375 lr: [0.0002, 0.0002] train_loss: 0.768784 train_acc: 0.643443 train_f1: 0.643443 time: 0.1530s
INFO:root:Epoch: 0375 val_loss: 0.733074 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0380 lr: [0.0002, 0.0002] train_loss: 0.781449 train_acc: 0.688525 train_f1: 0.688525 time: 0.1470s
INFO:root:Epoch: 0380 val_loss: 0.733683 val_acc: 0.636364 val_f1: 0.636364
INFO:root:Epoch: 0385 lr: [0.0002, 0.0002] train_loss: 0.769769 train_acc: 0.672131 train_f1: 0.672131 time: 0.1545s
INFO:root:Epoch: 0385 val_loss: 0.723661 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0390 lr: [0.0002, 0.0002] train_loss: 0.776656 train_acc: 0.684426 train_f1: 0.684426 time: 0.1501s
INFO:root:Epoch: 0390 val_loss: 0.707933 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0395 lr: [0.0002, 0.0002] train_loss: 0.771205 train_acc: 0.668033 train_f1: 0.668033 time: 0.1479s
INFO:root:Epoch: 0395 val_loss: 0.707536 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0400 lr: [0.0002, 0.0002] train_loss: 0.758761 train_acc: 0.684426 train_f1: 0.684426 time: 0.1430s
INFO:root:Epoch: 0400 val_loss: 0.693850 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0405 lr: [0.0002, 0.0002] train_loss: 0.750445 train_acc: 0.659836 train_f1: 0.659836 time: 0.1443s
INFO:root:Epoch: 0405 val_loss: 0.698709 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0410 lr: [0.0002, 0.0002] train_loss: 0.735550 train_acc: 0.684426 train_f1: 0.684426 time: 0.1447s
INFO:root:Epoch: 0410 val_loss: 0.702361 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0415 lr: [0.0002, 0.0002] train_loss: 0.716507 train_acc: 0.680328 train_f1: 0.680328 time: 0.1433s
INFO:root:Epoch: 0415 val_loss: 0.707392 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0420 lr: [0.0002, 0.0002] train_loss: 0.723928 train_acc: 0.692623 train_f1: 0.692623 time: 0.1434s
INFO:root:Epoch: 0420 val_loss: 0.695869 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0425 lr: [0.0002, 0.0002] train_loss: 0.750173 train_acc: 0.713115 train_f1: 0.713115 time: 0.1424s
INFO:root:Epoch: 0425 val_loss: 0.689916 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0430 lr: [0.0002, 0.0002] train_loss: 0.725334 train_acc: 0.672131 train_f1: 0.672131 time: 0.1445s
INFO:root:Epoch: 0430 val_loss: 0.695353 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0435 lr: [0.0002, 0.0002] train_loss: 0.723379 train_acc: 0.729508 train_f1: 0.729508 time: 0.1438s
INFO:root:Epoch: 0435 val_loss: 0.695821 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0440 lr: [0.0002, 0.0002] train_loss: 0.756285 train_acc: 0.713115 train_f1: 0.713115 time: 0.1494s
INFO:root:Epoch: 0440 val_loss: 0.692369 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0445 lr: [0.0002, 0.0002] train_loss: 0.734959 train_acc: 0.721311 train_f1: 0.721311 time: 0.1450s
INFO:root:Epoch: 0445 val_loss: 0.669373 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0450 lr: [0.0002, 0.0002] train_loss: 0.729374 train_acc: 0.704918 train_f1: 0.704918 time: 0.1550s
INFO:root:Epoch: 0450 val_loss: 0.662286 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0455 lr: [0.0002, 0.0002] train_loss: 0.723843 train_acc: 0.733607 train_f1: 0.733607 time: 0.1468s
INFO:root:Epoch: 0455 val_loss: 0.661246 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0460 lr: [0.0002, 0.0002] train_loss: 0.706033 train_acc: 0.717213 train_f1: 0.717213 time: 0.1553s
INFO:root:Epoch: 0460 val_loss: 0.656539 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0465 lr: [0.0002, 0.0002] train_loss: 0.724398 train_acc: 0.721311 train_f1: 0.721311 time: 0.1428s
INFO:root:Epoch: 0465 val_loss: 0.679630 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0470 lr: [0.0002, 0.0002] train_loss: 0.688044 train_acc: 0.709016 train_f1: 0.709016 time: 0.1489s
INFO:root:Epoch: 0470 val_loss: 0.686312 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0475 lr: [0.0002, 0.0002] train_loss: 0.704027 train_acc: 0.668033 train_f1: 0.668033 time: 0.1330s
INFO:root:Epoch: 0475 val_loss: 0.685320 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0480 lr: [0.0002, 0.0002] train_loss: 0.701913 train_acc: 0.717213 train_f1: 0.717213 time: 0.1425s
INFO:root:Epoch: 0480 val_loss: 0.671943 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0485 lr: [0.0002, 0.0002] train_loss: 0.708278 train_acc: 0.700820 train_f1: 0.700820 time: 0.1366s
INFO:root:Epoch: 0485 val_loss: 0.644218 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0490 lr: [0.0002, 0.0002] train_loss: 0.697110 train_acc: 0.729508 train_f1: 0.729508 time: 0.1395s
INFO:root:Epoch: 0490 val_loss: 0.622689 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0495 lr: [0.0002, 0.0002] train_loss: 0.692354 train_acc: 0.725410 train_f1: 0.725410 time: 0.1488s
INFO:root:Epoch: 0495 val_loss: 0.612538 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0500 lr: [0.0002, 0.0002] train_loss: 0.691667 train_acc: 0.709016 train_f1: 0.709016 time: 0.1532s
INFO:root:Epoch: 0500 val_loss: 0.607349 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0505 lr: [0.0002, 0.0002] train_loss: 0.700725 train_acc: 0.713115 train_f1: 0.713115 time: 0.1435s
INFO:root:Epoch: 0505 val_loss: 0.605462 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 79.0413s
INFO:root:Val set results: val_loss: 0.707392 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Test set results: test_loss: 0.684083 test_acc: 0.863636 test_f1: 0.863636
