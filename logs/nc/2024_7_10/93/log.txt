INFO:root:Using: cuda:7
INFO:root:Using seed 7.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(
      in_features=1703, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=False, act=None, dropout_rate=0.3
      (dropout): Dropout(p=0.3, inplace=False)
      (E_linear): Linear(in_features=1703, out_features=32, bias=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (3): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (4): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (5): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (atten): BLinear(
            in_features=32, out_features=1, c=tensor([1.], device='cuda:7'), use_bias=True, act=None, dropout_rate=0.3
            (dropout): Dropout(p=0.3, inplace=False)
            (E_linear): Linear(in_features=32, out_features=1, bias=False)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fee58ec36d0>)
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (3): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (4): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (5): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (atten): BLinear(
            in_features=32, out_features=1, c=tensor([1.], device='cuda:7'), use_bias=True, act=None, dropout_rate=0.3
            (dropout): Dropout(p=0.3, inplace=False)
            (E_linear): Linear(in_features=32, out_features=1, bias=False)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fee58ec36d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 67815
INFO:root:Epoch: 0005 lr: [0.0005, 0.0005] train_loss: 1.570458 train_acc: 0.606557 train_f1: 0.606557 time: 0.1562s
INFO:root:Epoch: 0005 val_loss: 1.562370 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0010 lr: [0.0005, 0.0005] train_loss: 1.523815 train_acc: 0.606557 train_f1: 0.606557 time: 0.1489s
INFO:root:Epoch: 0010 val_loss: 1.517692 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0015 lr: [0.0005, 0.0005] train_loss: 1.479731 train_acc: 0.606557 train_f1: 0.606557 time: 0.1527s
INFO:root:Epoch: 0015 val_loss: 1.475556 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0020 lr: [0.0005, 0.0005] train_loss: 1.438359 train_acc: 0.606557 train_f1: 0.606557 time: 0.1478s
INFO:root:Epoch: 0020 val_loss: 1.436051 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0025 lr: [0.0005, 0.0005] train_loss: 1.399785 train_acc: 0.606557 train_f1: 0.606557 time: 0.1494s
INFO:root:Epoch: 0025 val_loss: 1.399250 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0030 lr: [0.0005, 0.0005] train_loss: 1.364165 train_acc: 0.606557 train_f1: 0.606557 time: 0.1453s
INFO:root:Epoch: 0030 val_loss: 1.365183 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0035 lr: [0.0005, 0.0005] train_loss: 1.331492 train_acc: 0.606557 train_f1: 0.606557 time: 0.1495s
INFO:root:Epoch: 0035 val_loss: 1.333857 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0040 lr: [0.0005, 0.0005] train_loss: 1.301829 train_acc: 0.606557 train_f1: 0.606557 time: 0.1501s
INFO:root:Epoch: 0040 val_loss: 1.305275 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0045 lr: [0.0005, 0.0005] train_loss: 1.275269 train_acc: 0.606557 train_f1: 0.606557 time: 0.1481s
INFO:root:Epoch: 0045 val_loss: 1.279458 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0050 lr: [0.0005, 0.0005] train_loss: 1.251814 train_acc: 0.606557 train_f1: 0.606557 time: 0.1566s
INFO:root:Epoch: 0050 val_loss: 1.256439 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0055 lr: [0.0005, 0.0005] train_loss: 1.231575 train_acc: 0.606557 train_f1: 0.606557 time: 0.1537s
INFO:root:Epoch: 0055 val_loss: 1.236272 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0060 lr: [0.0005, 0.0005] train_loss: 1.214518 train_acc: 0.606557 train_f1: 0.606557 time: 0.1554s
INFO:root:Epoch: 0060 val_loss: 1.218998 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0065 lr: [0.0005, 0.0005] train_loss: 1.200752 train_acc: 0.606557 train_f1: 0.606557 time: 0.1459s
INFO:root:Epoch: 0065 val_loss: 1.204595 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0070 lr: [0.0005, 0.0005] train_loss: 1.189954 train_acc: 0.606557 train_f1: 0.606557 time: 0.1544s
INFO:root:Epoch: 0070 val_loss: 1.192903 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0075 lr: [0.0005, 0.0005] train_loss: 1.182024 train_acc: 0.606557 train_f1: 0.606557 time: 0.1513s
INFO:root:Epoch: 0075 val_loss: 1.183537 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0080 lr: [0.0005, 0.0005] train_loss: 1.176413 train_acc: 0.606557 train_f1: 0.606557 time: 0.1497s
INFO:root:Epoch: 0080 val_loss: 1.175880 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0085 lr: [0.0005, 0.0005] train_loss: 1.172159 train_acc: 0.606557 train_f1: 0.606557 time: 0.1472s
INFO:root:Epoch: 0085 val_loss: 1.169269 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0090 lr: [0.0005, 0.0005] train_loss: 1.169034 train_acc: 0.606557 train_f1: 0.606557 time: 0.1489s
INFO:root:Epoch: 0090 val_loss: 1.163253 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0095 lr: [0.0005, 0.0005] train_loss: 1.166385 train_acc: 0.606557 train_f1: 0.606557 time: 0.1497s
INFO:root:Epoch: 0095 val_loss: 1.157842 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.164110 train_acc: 0.606557 train_f1: 0.606557 time: 0.1472s
INFO:root:Epoch: 0100 val_loss: 1.153436 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0105 lr: [0.0005, 0.0005] train_loss: 1.161927 train_acc: 0.606557 train_f1: 0.606557 time: 0.1575s
INFO:root:Epoch: 0105 val_loss: 1.150292 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.160035 train_acc: 0.606557 train_f1: 0.606557 time: 0.1493s
INFO:root:Epoch: 0110 val_loss: 1.148344 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0115 lr: [0.0005, 0.0005] train_loss: 1.157750 train_acc: 0.606557 train_f1: 0.606557 time: 0.1779s
INFO:root:Epoch: 0115 val_loss: 1.147156 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.155464 train_acc: 0.606557 train_f1: 0.606557 time: 0.1523s
INFO:root:Epoch: 0120 val_loss: 1.146161 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0125 lr: [0.0005, 0.0005] train_loss: 1.153762 train_acc: 0.606557 train_f1: 0.606557 time: 0.1468s
INFO:root:Epoch: 0125 val_loss: 1.144863 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.151026 train_acc: 0.606557 train_f1: 0.606557 time: 0.1492s
INFO:root:Epoch: 0130 val_loss: 1.143241 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0135 lr: [0.0005, 0.0005] train_loss: 1.148635 train_acc: 0.606557 train_f1: 0.606557 time: 0.1464s
INFO:root:Epoch: 0135 val_loss: 1.141412 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.147069 train_acc: 0.606557 train_f1: 0.606557 time: 0.1527s
INFO:root:Epoch: 0140 val_loss: 1.139321 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0145 lr: [0.0005, 0.0005] train_loss: 1.143764 train_acc: 0.606557 train_f1: 0.606557 time: 0.1473s
INFO:root:Epoch: 0145 val_loss: 1.137209 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.142721 train_acc: 0.606557 train_f1: 0.606557 time: 0.1545s
INFO:root:Epoch: 0150 val_loss: 1.135000 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0155 lr: [0.0005, 0.0005] train_loss: 1.139515 train_acc: 0.606557 train_f1: 0.606557 time: 0.1477s
INFO:root:Epoch: 0155 val_loss: 1.132706 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.133761 train_acc: 0.606557 train_f1: 0.606557 time: 0.1539s
INFO:root:Epoch: 0160 val_loss: 1.129896 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0165 lr: [0.0005, 0.0005] train_loss: 1.132219 train_acc: 0.606557 train_f1: 0.606557 time: 0.1481s
INFO:root:Epoch: 0165 val_loss: 1.126818 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.129653 train_acc: 0.606557 train_f1: 0.606557 time: 0.2201s
INFO:root:Epoch: 0170 val_loss: 1.123761 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0175 lr: [0.0005, 0.0005] train_loss: 1.121418 train_acc: 0.606557 train_f1: 0.606557 time: 0.1494s
INFO:root:Epoch: 0175 val_loss: 1.120604 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.121761 train_acc: 0.606557 train_f1: 0.606557 time: 0.1464s
INFO:root:Epoch: 0180 val_loss: 1.116014 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0185 lr: [0.0005, 0.0005] train_loss: 1.118188 train_acc: 0.606557 train_f1: 0.606557 time: 0.1521s
INFO:root:Epoch: 0185 val_loss: 1.111823 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.105971 train_acc: 0.606557 train_f1: 0.606557 time: 0.1479s
INFO:root:Epoch: 0190 val_loss: 1.107248 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0195 lr: [0.0005, 0.0005] train_loss: 1.103593 train_acc: 0.606557 train_f1: 0.606557 time: 0.1622s
INFO:root:Epoch: 0195 val_loss: 1.102504 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 1.106428 train_acc: 0.606557 train_f1: 0.606557 time: 0.1501s
INFO:root:Epoch: 0200 val_loss: 1.097281 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0205 lr: [0.0005, 0.0005] train_loss: 1.084075 train_acc: 0.606557 train_f1: 0.606557 time: 0.1599s
INFO:root:Epoch: 0205 val_loss: 1.090623 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 1.084092 train_acc: 0.606557 train_f1: 0.606557 time: 0.1493s
INFO:root:Epoch: 0210 val_loss: 1.080963 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0215 lr: [0.0005, 0.0005] train_loss: 1.071738 train_acc: 0.606557 train_f1: 0.606557 time: 0.1630s
INFO:root:Epoch: 0215 val_loss: 1.070225 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 1.059514 train_acc: 0.606557 train_f1: 0.606557 time: 0.1480s
INFO:root:Epoch: 0220 val_loss: 1.059983 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0225 lr: [0.0005, 0.0005] train_loss: 1.043832 train_acc: 0.606557 train_f1: 0.606557 time: 0.1470s
INFO:root:Epoch: 0225 val_loss: 1.051877 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 1.030965 train_acc: 0.606557 train_f1: 0.606557 time: 0.1495s
INFO:root:Epoch: 0230 val_loss: 1.039377 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0235 lr: [0.0005, 0.0005] train_loss: 1.021038 train_acc: 0.606557 train_f1: 0.606557 time: 0.1458s
INFO:root:Epoch: 0235 val_loss: 1.026417 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 1.005620 train_acc: 0.606557 train_f1: 0.606557 time: 0.1545s
INFO:root:Epoch: 0240 val_loss: 1.016970 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0245 lr: [0.0005, 0.0005] train_loss: 1.024439 train_acc: 0.606557 train_f1: 0.606557 time: 0.1475s
INFO:root:Epoch: 0245 val_loss: 1.004463 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.997219 train_acc: 0.606557 train_f1: 0.606557 time: 0.1558s
INFO:root:Epoch: 0250 val_loss: 0.989673 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0255 lr: [0.0005, 0.0005] train_loss: 0.955228 train_acc: 0.606557 train_f1: 0.606557 time: 0.1485s
INFO:root:Epoch: 0255 val_loss: 0.971423 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.958877 train_acc: 0.606557 train_f1: 0.606557 time: 0.1774s
INFO:root:Epoch: 0260 val_loss: 0.957559 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0265 lr: [0.0005, 0.0005] train_loss: 0.976579 train_acc: 0.606557 train_f1: 0.606557 time: 0.1655s
INFO:root:Epoch: 0265 val_loss: 0.943811 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.935561 train_acc: 0.606557 train_f1: 0.606557 time: 0.1515s
INFO:root:Epoch: 0270 val_loss: 0.926843 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0275 lr: [0.0005, 0.0005] train_loss: 0.923632 train_acc: 0.606557 train_f1: 0.606557 time: 0.1491s
INFO:root:Epoch: 0275 val_loss: 0.908812 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.894325 train_acc: 0.606557 train_f1: 0.606557 time: 0.1473s
INFO:root:Epoch: 0280 val_loss: 0.908689 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0285 lr: [0.0005, 0.0005] train_loss: 0.884858 train_acc: 0.606557 train_f1: 0.606557 time: 0.1485s
INFO:root:Epoch: 0285 val_loss: 0.887479 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.905122 train_acc: 0.606557 train_f1: 0.606557 time: 0.1447s
INFO:root:Epoch: 0290 val_loss: 0.882022 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0295 lr: [0.0005, 0.0005] train_loss: 0.868906 train_acc: 0.606557 train_f1: 0.606557 time: 0.1558s
INFO:root:Epoch: 0295 val_loss: 0.871327 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0300 lr: [0.0005, 0.0005] train_loss: 0.898285 train_acc: 0.606557 train_f1: 0.606557 time: 0.1443s
INFO:root:Epoch: 0300 val_loss: 0.849088 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0305 lr: [0.0005, 0.0005] train_loss: 0.877132 train_acc: 0.606557 train_f1: 0.606557 time: 0.1813s
INFO:root:Epoch: 0305 val_loss: 0.850349 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0310 lr: [0.0005, 0.0005] train_loss: 0.848153 train_acc: 0.606557 train_f1: 0.606557 time: 0.1494s
INFO:root:Epoch: 0310 val_loss: 0.834416 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0315 lr: [0.0005, 0.0005] train_loss: 0.832266 train_acc: 0.606557 train_f1: 0.606557 time: 0.1533s
INFO:root:Epoch: 0315 val_loss: 0.839717 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0320 lr: [0.0005, 0.0005] train_loss: 0.828885 train_acc: 0.606557 train_f1: 0.606557 time: 0.1450s
INFO:root:Epoch: 0320 val_loss: 0.831454 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0325 lr: [0.0005, 0.0005] train_loss: 0.837090 train_acc: 0.606557 train_f1: 0.606557 time: 0.1508s
INFO:root:Epoch: 0325 val_loss: 0.833581 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0330 lr: [0.0005, 0.0005] train_loss: 0.814759 train_acc: 0.606557 train_f1: 0.606557 time: 0.1458s
INFO:root:Epoch: 0330 val_loss: 0.819223 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0335 lr: [0.0005, 0.0005] train_loss: 0.802128 train_acc: 0.606557 train_f1: 0.606557 time: 0.1456s
INFO:root:Epoch: 0335 val_loss: 0.809893 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0340 lr: [0.0005, 0.0005] train_loss: 0.796944 train_acc: 0.606557 train_f1: 0.606557 time: 0.1467s
INFO:root:Epoch: 0340 val_loss: 0.802542 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0345 lr: [0.0005, 0.0005] train_loss: 0.850352 train_acc: 0.606557 train_f1: 0.606557 time: 0.1461s
INFO:root:Epoch: 0345 val_loss: 0.793625 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0350 lr: [0.0005, 0.0005] train_loss: 0.802600 train_acc: 0.606557 train_f1: 0.606557 time: 0.1553s
INFO:root:Epoch: 0350 val_loss: 0.781514 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0355 lr: [0.0005, 0.0005] train_loss: 0.785220 train_acc: 0.606557 train_f1: 0.606557 time: 0.1458s
INFO:root:Epoch: 0355 val_loss: 0.779141 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0360 lr: [0.0005, 0.0005] train_loss: 0.782185 train_acc: 0.606557 train_f1: 0.606557 time: 0.1597s
INFO:root:Epoch: 0360 val_loss: 0.775185 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0365 lr: [0.0005, 0.0005] train_loss: 0.788273 train_acc: 0.606557 train_f1: 0.606557 time: 0.1446s
INFO:root:Epoch: 0365 val_loss: 0.779861 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0370 lr: [0.0005, 0.0005] train_loss: 0.768671 train_acc: 0.606557 train_f1: 0.606557 time: 0.1494s
INFO:root:Epoch: 0370 val_loss: 0.775188 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0375 lr: [0.0005, 0.0005] train_loss: 0.774334 train_acc: 0.606557 train_f1: 0.606557 time: 0.1463s
INFO:root:Epoch: 0375 val_loss: 0.774298 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0380 lr: [0.0005, 0.0005] train_loss: 0.764751 train_acc: 0.606557 train_f1: 0.606557 time: 0.1549s
INFO:root:Epoch: 0380 val_loss: 0.776701 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0385 lr: [0.0005, 0.0005] train_loss: 0.774728 train_acc: 0.606557 train_f1: 0.606557 time: 0.1448s
INFO:root:Epoch: 0385 val_loss: 0.786148 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0390 lr: [0.0005, 0.0005] train_loss: 0.759765 train_acc: 0.606557 train_f1: 0.606557 time: 0.1518s
INFO:root:Epoch: 0390 val_loss: 0.771910 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0395 lr: [0.0005, 0.0005] train_loss: 0.755831 train_acc: 0.606557 train_f1: 0.606557 time: 0.1454s
INFO:root:Epoch: 0395 val_loss: 0.759855 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0400 lr: [0.0005, 0.0005] train_loss: 0.843935 train_acc: 0.606557 train_f1: 0.606557 time: 0.1454s
INFO:root:Epoch: 0400 val_loss: 0.767724 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0405 lr: [0.0005, 0.0005] train_loss: 0.751816 train_acc: 0.610656 train_f1: 0.610656 time: 0.1468s
INFO:root:Epoch: 0405 val_loss: 0.750512 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0410 lr: [0.0005, 0.0005] train_loss: 0.757406 train_acc: 0.606557 train_f1: 0.606557 time: 0.1483s
INFO:root:Epoch: 0410 val_loss: 0.745450 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0415 lr: [0.0005, 0.0005] train_loss: 0.746046 train_acc: 0.606557 train_f1: 0.606557 time: 0.1515s
INFO:root:Epoch: 0415 val_loss: 0.750584 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0420 lr: [0.0005, 0.0005] train_loss: 0.744639 train_acc: 0.778689 train_f1: 0.778689 time: 0.1468s
INFO:root:Epoch: 0420 val_loss: 0.740280 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0425 lr: [0.0005, 0.0005] train_loss: 0.736518 train_acc: 0.606557 train_f1: 0.606557 time: 0.1539s
INFO:root:Epoch: 0425 val_loss: 0.739064 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0430 lr: [0.0005, 0.0005] train_loss: 0.755447 train_acc: 0.606557 train_f1: 0.606557 time: 0.1454s
INFO:root:Epoch: 0430 val_loss: 0.740214 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0435 lr: [0.0005, 0.0005] train_loss: 0.790042 train_acc: 0.606557 train_f1: 0.606557 time: 0.1569s
INFO:root:Epoch: 0435 val_loss: 0.745238 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0440 lr: [0.0005, 0.0005] train_loss: 0.735015 train_acc: 0.774590 train_f1: 0.774590 time: 0.1491s
INFO:root:Epoch: 0440 val_loss: 0.735297 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0445 lr: [0.0005, 0.0005] train_loss: 0.732327 train_acc: 0.606557 train_f1: 0.606557 time: 0.1486s
INFO:root:Epoch: 0445 val_loss: 0.734942 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0450 lr: [0.0005, 0.0005] train_loss: 0.740010 train_acc: 0.606557 train_f1: 0.606557 time: 0.1471s
INFO:root:Epoch: 0450 val_loss: 0.735769 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0455 lr: [0.0005, 0.0005] train_loss: 0.721730 train_acc: 0.606557 train_f1: 0.606557 time: 0.1442s
INFO:root:Epoch: 0455 val_loss: 0.735560 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0460 lr: [0.0005, 0.0005] train_loss: 0.726730 train_acc: 0.766393 train_f1: 0.766393 time: 0.1456s
INFO:root:Epoch: 0460 val_loss: 0.722978 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0465 lr: [0.0005, 0.0005] train_loss: 0.718295 train_acc: 0.762295 train_f1: 0.762295 time: 0.1482s
INFO:root:Epoch: 0465 val_loss: 0.714810 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0470 lr: [0.0005, 0.0005] train_loss: 0.729083 train_acc: 0.778689 train_f1: 0.778689 time: 0.1521s
INFO:root:Epoch: 0470 val_loss: 0.707074 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0475 lr: [0.0005, 0.0005] train_loss: 0.714002 train_acc: 0.754098 train_f1: 0.754098 time: 0.1453s
INFO:root:Epoch: 0475 val_loss: 0.706848 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0480 lr: [0.0005, 0.0005] train_loss: 0.717718 train_acc: 0.606557 train_f1: 0.606557 time: 0.1634s
INFO:root:Epoch: 0480 val_loss: 0.704828 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0485 lr: [0.0005, 0.0005] train_loss: 0.714018 train_acc: 0.606557 train_f1: 0.606557 time: 0.1453s
INFO:root:Epoch: 0485 val_loss: 0.706168 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0490 lr: [0.0005, 0.0005] train_loss: 0.710225 train_acc: 0.745902 train_f1: 0.745902 time: 0.1523s
INFO:root:Epoch: 0490 val_loss: 0.706008 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0495 lr: [0.0005, 0.0005] train_loss: 0.703442 train_acc: 0.766393 train_f1: 0.766393 time: 0.1456s
INFO:root:Epoch: 0495 val_loss: 0.695200 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0500 lr: [0.0005, 0.0005] train_loss: 0.724185 train_acc: 0.778689 train_f1: 0.778689 time: 0.1522s
INFO:root:Epoch: 0500 val_loss: 0.689478 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0505 lr: [0.0005, 0.0005] train_loss: 0.703916 train_acc: 0.606557 train_f1: 0.606557 time: 0.1465s
INFO:root:Epoch: 0505 val_loss: 0.690315 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0510 lr: [0.0005, 0.0005] train_loss: 0.696832 train_acc: 0.778689 train_f1: 0.778689 time: 0.1454s
INFO:root:Epoch: 0510 val_loss: 0.698113 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0515 lr: [0.0005, 0.0005] train_loss: 0.710599 train_acc: 0.766393 train_f1: 0.766393 time: 0.1464s
INFO:root:Epoch: 0515 val_loss: 0.698173 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0520 lr: [0.0005, 0.0005] train_loss: 0.707057 train_acc: 0.778689 train_f1: 0.778689 time: 0.1448s
INFO:root:Epoch: 0520 val_loss: 0.696125 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0525 lr: [0.0005, 0.0005] train_loss: 0.707423 train_acc: 0.778689 train_f1: 0.778689 time: 0.1544s
INFO:root:Epoch: 0525 val_loss: 0.695009 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0530 lr: [0.0005, 0.0005] train_loss: 0.706372 train_acc: 0.778689 train_f1: 0.778689 time: 0.1488s
INFO:root:Epoch: 0530 val_loss: 0.698482 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0535 lr: [0.0005, 0.0005] train_loss: 0.699078 train_acc: 0.778689 train_f1: 0.778689 time: 0.1562s
INFO:root:Epoch: 0535 val_loss: 0.702012 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0540 lr: [0.0005, 0.0005] train_loss: 0.683396 train_acc: 0.778689 train_f1: 0.778689 time: 0.1462s
INFO:root:Epoch: 0540 val_loss: 0.703150 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0545 lr: [0.0005, 0.0005] train_loss: 0.685482 train_acc: 0.778689 train_f1: 0.778689 time: 0.1536s
INFO:root:Epoch: 0545 val_loss: 0.703594 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0550 lr: [0.0005, 0.0005] train_loss: 0.692705 train_acc: 0.770492 train_f1: 0.770492 time: 0.1463s
INFO:root:Epoch: 0550 val_loss: 0.694479 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0555 lr: [0.0005, 0.0005] train_loss: 0.681505 train_acc: 0.778689 train_f1: 0.778689 time: 0.1516s
INFO:root:Epoch: 0555 val_loss: 0.684975 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0560 lr: [0.0005, 0.0005] train_loss: 0.678487 train_acc: 0.778689 train_f1: 0.778689 time: 0.1443s
INFO:root:Epoch: 0560 val_loss: 0.676284 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0565 lr: [0.0005, 0.0005] train_loss: 0.686015 train_acc: 0.778689 train_f1: 0.778689 time: 0.1510s
INFO:root:Epoch: 0565 val_loss: 0.671333 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0570 lr: [0.0005, 0.0005] train_loss: 0.683254 train_acc: 0.778689 train_f1: 0.778689 time: 0.1484s
INFO:root:Epoch: 0570 val_loss: 0.672884 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0575 lr: [0.0005, 0.0005] train_loss: 0.675559 train_acc: 0.778689 train_f1: 0.778689 time: 0.1469s
INFO:root:Epoch: 0575 val_loss: 0.676489 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0580 lr: [0.0005, 0.0005] train_loss: 0.686043 train_acc: 0.778689 train_f1: 0.778689 time: 0.1476s
INFO:root:Epoch: 0580 val_loss: 0.676579 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0585 lr: [0.0005, 0.0005] train_loss: 0.696976 train_acc: 0.606557 train_f1: 0.606557 time: 0.1452s
INFO:root:Epoch: 0585 val_loss: 0.681240 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0590 lr: [0.0005, 0.0005] train_loss: 0.673696 train_acc: 0.774590 train_f1: 0.774590 time: 0.1524s
INFO:root:Epoch: 0590 val_loss: 0.687572 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0595 lr: [0.0005, 0.0005] train_loss: 0.668094 train_acc: 0.778689 train_f1: 0.778689 time: 0.1462s
INFO:root:Epoch: 0595 val_loss: 0.684897 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0600 lr: [0.0005, 0.0005] train_loss: 0.664153 train_acc: 0.778689 train_f1: 0.778689 time: 0.1519s
INFO:root:Epoch: 0600 val_loss: 0.670841 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0605 lr: [0.0005, 0.0005] train_loss: 0.665189 train_acc: 0.778689 train_f1: 0.778689 time: 0.1482s
INFO:root:Epoch: 0605 val_loss: 0.664070 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0610 lr: [0.0005, 0.0005] train_loss: 0.660432 train_acc: 0.778689 train_f1: 0.778689 time: 0.1510s
INFO:root:Epoch: 0610 val_loss: 0.663104 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0615 lr: [0.0005, 0.0005] train_loss: 0.679023 train_acc: 0.778689 train_f1: 0.778689 time: 0.1465s
INFO:root:Epoch: 0615 val_loss: 0.658534 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0620 lr: [0.0005, 0.0005] train_loss: 0.658627 train_acc: 0.778689 train_f1: 0.778689 time: 0.1506s
INFO:root:Epoch: 0620 val_loss: 0.658336 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0625 lr: [0.0005, 0.0005] train_loss: 0.662205 train_acc: 0.778689 train_f1: 0.778689 time: 0.1465s
INFO:root:Epoch: 0625 val_loss: 0.658970 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0630 lr: [0.0005, 0.0005] train_loss: 0.657732 train_acc: 0.778689 train_f1: 0.778689 time: 0.1450s
INFO:root:Epoch: 0630 val_loss: 0.660858 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0635 lr: [0.0005, 0.0005] train_loss: 0.653282 train_acc: 0.778689 train_f1: 0.778689 time: 0.1497s
INFO:root:Epoch: 0635 val_loss: 0.660792 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0640 lr: [0.0005, 0.0005] train_loss: 0.672342 train_acc: 0.778689 train_f1: 0.778689 time: 0.1462s
INFO:root:Epoch: 0640 val_loss: 0.660063 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0645 lr: [0.0005, 0.0005] train_loss: 0.653307 train_acc: 0.778689 train_f1: 0.778689 time: 0.1498s
INFO:root:Epoch: 0645 val_loss: 0.661601 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0650 lr: [0.0005, 0.0005] train_loss: 0.655135 train_acc: 0.778689 train_f1: 0.778689 time: 0.1458s
INFO:root:Epoch: 0650 val_loss: 0.662830 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0655 lr: [0.0005, 0.0005] train_loss: 0.649255 train_acc: 0.774590 train_f1: 0.774590 time: 0.1539s
INFO:root:Epoch: 0655 val_loss: 0.660604 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0660 lr: [0.0005, 0.0005] train_loss: 0.645780 train_acc: 0.778689 train_f1: 0.778689 time: 0.1510s
INFO:root:Epoch: 0660 val_loss: 0.662949 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0665 lr: [0.0005, 0.0005] train_loss: 0.646030 train_acc: 0.778689 train_f1: 0.778689 time: 0.1521s
INFO:root:Epoch: 0665 val_loss: 0.662629 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0670 lr: [0.0005, 0.0005] train_loss: 0.642470 train_acc: 0.778689 train_f1: 0.778689 time: 0.1464s
INFO:root:Epoch: 0670 val_loss: 0.658496 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0675 lr: [0.0005, 0.0005] train_loss: 0.643197 train_acc: 0.778689 train_f1: 0.778689 time: 0.1491s
INFO:root:Epoch: 0675 val_loss: 0.655088 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0680 lr: [0.0005, 0.0005] train_loss: 0.643202 train_acc: 0.778689 train_f1: 0.778689 time: 0.1459s
INFO:root:Epoch: 0680 val_loss: 0.651881 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0685 lr: [0.0005, 0.0005] train_loss: 0.638215 train_acc: 0.778689 train_f1: 0.778689 time: 0.1452s
INFO:root:Epoch: 0685 val_loss: 0.649193 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0690 lr: [0.0005, 0.0005] train_loss: 0.636618 train_acc: 0.778689 train_f1: 0.778689 time: 0.1472s
INFO:root:Epoch: 0690 val_loss: 0.646594 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0695 lr: [0.0005, 0.0005] train_loss: 0.639425 train_acc: 0.778689 train_f1: 0.778689 time: 0.1499s
INFO:root:Epoch: 0695 val_loss: 0.646082 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0700 lr: [0.0005, 0.0005] train_loss: 0.651745 train_acc: 0.778689 train_f1: 0.778689 time: 0.1550s
INFO:root:Epoch: 0700 val_loss: 0.646130 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0705 lr: [0.0005, 0.0005] train_loss: 0.634565 train_acc: 0.778689 train_f1: 0.778689 time: 0.1460s
INFO:root:Epoch: 0705 val_loss: 0.644772 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0710 lr: [0.0005, 0.0005] train_loss: 0.636579 train_acc: 0.778689 train_f1: 0.778689 time: 0.1531s
INFO:root:Epoch: 0710 val_loss: 0.639792 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0715 lr: [0.0005, 0.0005] train_loss: 0.642733 train_acc: 0.778689 train_f1: 0.778689 time: 0.1458s
INFO:root:Epoch: 0715 val_loss: 0.637743 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0720 lr: [0.0005, 0.0005] train_loss: 0.641499 train_acc: 0.778689 train_f1: 0.778689 time: 0.1531s
INFO:root:Epoch: 0720 val_loss: 0.638235 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0725 lr: [0.0005, 0.0005] train_loss: 0.630913 train_acc: 0.778689 train_f1: 0.778689 time: 0.1487s
INFO:root:Epoch: 0725 val_loss: 0.636983 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 112.8906s
INFO:root:Val set results: val_loss: 0.689478 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Test set results: test_loss: 0.638699 test_acc: 0.818182 test_f1: 0.818182
