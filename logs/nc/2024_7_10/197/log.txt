INFO:root:Using: cuda:7
INFO:root:Using seed 7.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=False, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (4): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (5): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fcc0d3ab6d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fcc0d3ab6d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fcc0d3ab6d0>)
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (4): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (5): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fcc0d3ab6d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fcc0d3ab6d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fcc0d3ab6d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 234565
INFO:root:Epoch: 0005 lr: [0.0002, 0.0002] train_loss: 1.540946 train_acc: 0.606557 train_f1: 0.606557 time: 0.2729s
INFO:root:Epoch: 0005 val_loss: 1.527245 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0010 lr: [0.0002, 0.0002] train_loss: 1.459343 train_acc: 0.606557 train_f1: 0.606557 time: 0.2736s
INFO:root:Epoch: 0010 val_loss: 1.449127 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0015 lr: [0.0002, 0.0002] train_loss: 1.392499 train_acc: 0.606557 train_f1: 0.606557 time: 0.2742s
INFO:root:Epoch: 0015 val_loss: 1.387051 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0020 lr: [0.0002, 0.0002] train_loss: 1.346802 train_acc: 0.606557 train_f1: 0.606557 time: 0.2769s
INFO:root:Epoch: 0020 val_loss: 1.344062 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0025 lr: [0.0002, 0.0002] train_loss: 1.314760 train_acc: 0.606557 train_f1: 0.606557 time: 0.2786s
INFO:root:Epoch: 0025 val_loss: 1.313257 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0030 lr: [0.0002, 0.0002] train_loss: 1.289427 train_acc: 0.606557 train_f1: 0.606557 time: 0.2828s
INFO:root:Epoch: 0030 val_loss: 1.288709 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0035 lr: [0.0002, 0.0002] train_loss: 1.267107 train_acc: 0.606557 train_f1: 0.606557 time: 0.2812s
INFO:root:Epoch: 0035 val_loss: 1.267553 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0040 lr: [0.0002, 0.0002] train_loss: 1.246337 train_acc: 0.606557 train_f1: 0.606557 time: 0.2737s
INFO:root:Epoch: 0040 val_loss: 1.248919 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0045 lr: [0.0002, 0.0002] train_loss: 1.225584 train_acc: 0.606557 train_f1: 0.606557 time: 0.2772s
INFO:root:Epoch: 0045 val_loss: 1.231126 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0050 lr: [0.0002, 0.0002] train_loss: 1.203628 train_acc: 0.606557 train_f1: 0.606557 time: 0.2943s
INFO:root:Epoch: 0050 val_loss: 1.210887 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0055 lr: [0.0002, 0.0002] train_loss: 1.179079 train_acc: 0.606557 train_f1: 0.606557 time: 0.2770s
INFO:root:Epoch: 0055 val_loss: 1.187945 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0060 lr: [0.0002, 0.0002] train_loss: 1.150251 train_acc: 0.606557 train_f1: 0.606557 time: 0.2876s
INFO:root:Epoch: 0060 val_loss: 1.160255 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0065 lr: [0.0002, 0.0002] train_loss: 1.117249 train_acc: 0.606557 train_f1: 0.606557 time: 0.2794s
INFO:root:Epoch: 0065 val_loss: 1.129235 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0070 lr: [0.0002, 0.0002] train_loss: 1.079006 train_acc: 0.606557 train_f1: 0.606557 time: 0.3017s
INFO:root:Epoch: 0070 val_loss: 1.092310 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0075 lr: [0.0002, 0.0002] train_loss: 1.038404 train_acc: 0.606557 train_f1: 0.606557 time: 0.2857s
INFO:root:Epoch: 0075 val_loss: 1.056308 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0080 lr: [0.0002, 0.0002] train_loss: 0.998914 train_acc: 0.606557 train_f1: 0.606557 time: 0.2940s
INFO:root:Epoch: 0080 val_loss: 1.020962 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0085 lr: [0.0002, 0.0002] train_loss: 0.962501 train_acc: 0.606557 train_f1: 0.606557 time: 0.3582s
INFO:root:Epoch: 0085 val_loss: 0.985888 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0090 lr: [0.0002, 0.0002] train_loss: 0.932559 train_acc: 0.606557 train_f1: 0.606557 time: 0.2893s
INFO:root:Epoch: 0090 val_loss: 0.959146 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0095 lr: [0.0002, 0.0002] train_loss: 0.906123 train_acc: 0.606557 train_f1: 0.606557 time: 0.2825s
INFO:root:Epoch: 0095 val_loss: 0.940710 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0100 lr: [0.0002, 0.0002] train_loss: 0.881736 train_acc: 0.606557 train_f1: 0.606557 time: 0.2838s
INFO:root:Epoch: 0100 val_loss: 0.914691 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0105 lr: [0.0002, 0.0002] train_loss: 0.860220 train_acc: 0.606557 train_f1: 0.606557 time: 0.2872s
INFO:root:Epoch: 0105 val_loss: 0.901560 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0110 lr: [0.0002, 0.0002] train_loss: 0.841047 train_acc: 0.606557 train_f1: 0.606557 time: 0.2832s
INFO:root:Epoch: 0110 val_loss: 0.889073 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0115 lr: [0.0002, 0.0002] train_loss: 0.822662 train_acc: 0.606557 train_f1: 0.606557 time: 0.2825s
INFO:root:Epoch: 0115 val_loss: 0.868851 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0120 lr: [0.0002, 0.0002] train_loss: 0.805362 train_acc: 0.606557 train_f1: 0.606557 time: 0.2738s
INFO:root:Epoch: 0120 val_loss: 0.844862 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0125 lr: [0.0002, 0.0002] train_loss: 0.788959 train_acc: 0.606557 train_f1: 0.606557 time: 0.2769s
INFO:root:Epoch: 0125 val_loss: 0.824847 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0130 lr: [0.0002, 0.0002] train_loss: 0.772967 train_acc: 0.778689 train_f1: 0.778689 time: 0.2744s
INFO:root:Epoch: 0130 val_loss: 0.802498 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0135 lr: [0.0002, 0.0002] train_loss: 0.757750 train_acc: 0.778689 train_f1: 0.778689 time: 0.2715s
INFO:root:Epoch: 0135 val_loss: 0.785378 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0140 lr: [0.0002, 0.0002] train_loss: 0.743399 train_acc: 0.778689 train_f1: 0.778689 time: 0.2716s
INFO:root:Epoch: 0140 val_loss: 0.766596 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0145 lr: [0.0002, 0.0002] train_loss: 0.729789 train_acc: 0.778689 train_f1: 0.778689 time: 0.2762s
INFO:root:Epoch: 0145 val_loss: 0.749805 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0150 lr: [0.0002, 0.0002] train_loss: 0.716780 train_acc: 0.778689 train_f1: 0.778689 time: 0.2730s
INFO:root:Epoch: 0150 val_loss: 0.740676 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0155 lr: [0.0002, 0.0002] train_loss: 0.703969 train_acc: 0.778689 train_f1: 0.778689 time: 0.2738s
INFO:root:Epoch: 0155 val_loss: 0.723218 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0160 lr: [0.0002, 0.0002] train_loss: 0.691851 train_acc: 0.778689 train_f1: 0.778689 time: 0.2743s
INFO:root:Epoch: 0160 val_loss: 0.711993 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0165 lr: [0.0002, 0.0002] train_loss: 0.680447 train_acc: 0.778689 train_f1: 0.778689 time: 0.2706s
INFO:root:Epoch: 0165 val_loss: 0.701892 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0170 lr: [0.0002, 0.0002] train_loss: 0.669576 train_acc: 0.778689 train_f1: 0.778689 time: 0.2709s
INFO:root:Epoch: 0170 val_loss: 0.690768 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0175 lr: [0.0002, 0.0002] train_loss: 0.659213 train_acc: 0.778689 train_f1: 0.778689 time: 0.2732s
INFO:root:Epoch: 0175 val_loss: 0.678296 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0180 lr: [0.0002, 0.0002] train_loss: 0.649312 train_acc: 0.778689 train_f1: 0.778689 time: 0.2733s
INFO:root:Epoch: 0180 val_loss: 0.668167 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0185 lr: [0.0002, 0.0002] train_loss: 0.639836 train_acc: 0.778689 train_f1: 0.778689 time: 0.2720s
INFO:root:Epoch: 0185 val_loss: 0.657243 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0190 lr: [0.0002, 0.0002] train_loss: 0.630769 train_acc: 0.778689 train_f1: 0.778689 time: 0.2714s
INFO:root:Epoch: 0190 val_loss: 0.647894 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0195 lr: [0.0002, 0.0002] train_loss: 0.622072 train_acc: 0.778689 train_f1: 0.778689 time: 0.2784s
INFO:root:Epoch: 0195 val_loss: 0.636508 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0200 lr: [0.0002, 0.0002] train_loss: 0.613679 train_acc: 0.778689 train_f1: 0.778689 time: 0.2713s
INFO:root:Epoch: 0200 val_loss: 0.627233 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0205 lr: [0.0002, 0.0002] train_loss: 0.605256 train_acc: 0.778689 train_f1: 0.778689 time: 0.2705s
INFO:root:Epoch: 0205 val_loss: 0.618316 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0210 lr: [0.0002, 0.0002] train_loss: 0.597186 train_acc: 0.778689 train_f1: 0.778689 time: 0.2738s
INFO:root:Epoch: 0210 val_loss: 0.610214 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0215 lr: [0.0002, 0.0002] train_loss: 0.589530 train_acc: 0.778689 train_f1: 0.778689 time: 0.2720s
INFO:root:Epoch: 0215 val_loss: 0.601782 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0220 lr: [0.0002, 0.0002] train_loss: 0.582177 train_acc: 0.778689 train_f1: 0.778689 time: 0.2710s
INFO:root:Epoch: 0220 val_loss: 0.593009 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0225 lr: [0.0002, 0.0002] train_loss: 0.575104 train_acc: 0.778689 train_f1: 0.778689 time: 0.2737s
INFO:root:Epoch: 0225 val_loss: 0.584963 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0230 lr: [0.0002, 0.0002] train_loss: 0.568299 train_acc: 0.778689 train_f1: 0.778689 time: 0.2738s
INFO:root:Epoch: 0230 val_loss: 0.576634 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0235 lr: [0.0002, 0.0002] train_loss: 0.561732 train_acc: 0.778689 train_f1: 0.778689 time: 0.2728s
INFO:root:Epoch: 0235 val_loss: 0.568602 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0240 lr: [0.0002, 0.0002] train_loss: 0.555383 train_acc: 0.778689 train_f1: 0.778689 time: 0.2737s
INFO:root:Epoch: 0240 val_loss: 0.561631 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0245 lr: [0.0002, 0.0002] train_loss: 0.549218 train_acc: 0.778689 train_f1: 0.778689 time: 0.2698s
INFO:root:Epoch: 0245 val_loss: 0.555201 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0250 lr: [0.0002, 0.0002] train_loss: 0.542891 train_acc: 0.778689 train_f1: 0.778689 time: 0.2708s
INFO:root:Epoch: 0250 val_loss: 0.541806 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0255 lr: [0.0002, 0.0002] train_loss: 0.536303 train_acc: 0.778689 train_f1: 0.778689 time: 0.2732s
INFO:root:Epoch: 0255 val_loss: 0.535931 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0260 lr: [0.0002, 0.0002] train_loss: 0.530109 train_acc: 0.778689 train_f1: 0.778689 time: 0.2742s
INFO:root:Epoch: 0260 val_loss: 0.527774 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0265 lr: [0.0002, 0.0002] train_loss: 0.522839 train_acc: 0.778689 train_f1: 0.778689 time: 0.2723s
INFO:root:Epoch: 0265 val_loss: 0.514811 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0270 lr: [0.0002, 0.0002] train_loss: 0.515696 train_acc: 0.778689 train_f1: 0.778689 time: 0.2716s
INFO:root:Epoch: 0270 val_loss: 0.509740 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0275 lr: [0.0002, 0.0002] train_loss: 0.509245 train_acc: 0.778689 train_f1: 0.778689 time: 0.2766s
INFO:root:Epoch: 0275 val_loss: 0.502784 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0280 lr: [0.0002, 0.0002] train_loss: 0.502953 train_acc: 0.778689 train_f1: 0.778689 time: 0.2712s
INFO:root:Epoch: 0280 val_loss: 0.492950 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0285 lr: [0.0002, 0.0002] train_loss: 0.495938 train_acc: 0.778689 train_f1: 0.778689 time: 0.2693s
INFO:root:Epoch: 0285 val_loss: 0.485630 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0290 lr: [0.0002, 0.0002] train_loss: 0.489290 train_acc: 0.778689 train_f1: 0.778689 time: 0.2729s
INFO:root:Epoch: 0290 val_loss: 0.478792 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0295 lr: [0.0002, 0.0002] train_loss: 0.482911 train_acc: 0.778689 train_f1: 0.778689 time: 0.2739s
INFO:root:Epoch: 0295 val_loss: 0.472058 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0300 lr: [0.0002, 0.0002] train_loss: 0.476806 train_acc: 0.778689 train_f1: 0.778689 time: 0.2742s
INFO:root:Epoch: 0300 val_loss: 0.466472 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0305 lr: [0.0002, 0.0002] train_loss: 0.470853 train_acc: 0.778689 train_f1: 0.778689 time: 0.2770s
INFO:root:Epoch: 0305 val_loss: 0.460990 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0310 lr: [0.0002, 0.0002] train_loss: 0.465369 train_acc: 0.778689 train_f1: 0.778689 time: 0.2769s
INFO:root:Epoch: 0310 val_loss: 0.457767 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0315 lr: [0.0002, 0.0002] train_loss: 0.460337 train_acc: 0.778689 train_f1: 0.778689 time: 0.2755s
INFO:root:Epoch: 0315 val_loss: 0.455125 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0320 lr: [0.0002, 0.0002] train_loss: 0.456139 train_acc: 0.778689 train_f1: 0.778689 time: 0.2817s
INFO:root:Epoch: 0320 val_loss: 0.452038 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0325 lr: [0.0002, 0.0002] train_loss: 0.453751 train_acc: 0.778689 train_f1: 0.778689 time: 0.2788s
INFO:root:Epoch: 0325 val_loss: 0.452280 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0330 lr: [0.0002, 0.0002] train_loss: 0.453818 train_acc: 0.778689 train_f1: 0.778689 time: 0.2747s
INFO:root:Epoch: 0330 val_loss: 0.454074 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0335 lr: [0.0002, 0.0002] train_loss: 0.457545 train_acc: 0.778689 train_f1: 0.778689 time: 0.2786s
INFO:root:Epoch: 0335 val_loss: 0.460883 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0340 lr: [0.0002, 0.0002] train_loss: 0.464822 train_acc: 0.778689 train_f1: 0.778689 time: 0.2795s
INFO:root:Epoch: 0340 val_loss: 0.489578 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0345 lr: [0.0002, 0.0002] train_loss: 0.468601 train_acc: 0.778689 train_f1: 0.778689 time: 0.2979s
INFO:root:Epoch: 0345 val_loss: 0.457156 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0350 lr: [0.0002, 0.0002] train_loss: 0.462009 train_acc: 0.778689 train_f1: 0.778689 time: 0.2802s
INFO:root:Epoch: 0350 val_loss: 0.443798 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0355 lr: [0.0002, 0.0002] train_loss: 0.462698 train_acc: 0.778689 train_f1: 0.778689 time: 0.2829s
INFO:root:Epoch: 0355 val_loss: 0.455176 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0360 lr: [0.0002, 0.0002] train_loss: 0.455293 train_acc: 0.778689 train_f1: 0.778689 time: 0.2749s
INFO:root:Epoch: 0360 val_loss: 0.442122 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0365 lr: [0.0002, 0.0002] train_loss: 0.453889 train_acc: 0.778689 train_f1: 0.778689 time: 0.2881s
INFO:root:Epoch: 0365 val_loss: 0.447987 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0370 lr: [0.0002, 0.0002] train_loss: 0.455689 train_acc: 0.778689 train_f1: 0.778689 time: 0.2839s
INFO:root:Epoch: 0370 val_loss: 0.448207 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0375 lr: [0.0002, 0.0002] train_loss: 0.450455 train_acc: 0.778689 train_f1: 0.778689 time: 0.2886s
INFO:root:Epoch: 0375 val_loss: 0.450308 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0380 lr: [0.0002, 0.0002] train_loss: 0.455496 train_acc: 0.778689 train_f1: 0.778689 time: 0.2836s
INFO:root:Epoch: 0380 val_loss: 0.458128 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0385 lr: [0.0002, 0.0002] train_loss: 0.455901 train_acc: 0.778689 train_f1: 0.778689 time: 0.2985s
INFO:root:Epoch: 0385 val_loss: 0.446756 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0390 lr: [0.0002, 0.0002] train_loss: 0.462219 train_acc: 0.778689 train_f1: 0.778689 time: 0.2919s
INFO:root:Epoch: 0390 val_loss: 0.474396 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0395 lr: [0.0002, 0.0002] train_loss: 0.457717 train_acc: 0.778689 train_f1: 0.778689 time: 0.2865s
INFO:root:Epoch: 0395 val_loss: 0.446623 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0400 lr: [0.0002, 0.0002] train_loss: 0.460303 train_acc: 0.778689 train_f1: 0.778689 time: 0.2926s
INFO:root:Epoch: 0400 val_loss: 0.439697 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0405 lr: [0.0002, 0.0002] train_loss: 0.466961 train_acc: 0.778689 train_f1: 0.778689 time: 0.2827s
INFO:root:Epoch: 0405 val_loss: 0.474304 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0410 lr: [0.0002, 0.0002] train_loss: 0.468512 train_acc: 0.778689 train_f1: 0.778689 time: 0.2744s
INFO:root:Epoch: 0410 val_loss: 0.460153 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0415 lr: [0.0002, 0.0002] train_loss: 0.457703 train_acc: 0.778689 train_f1: 0.778689 time: 0.2783s
INFO:root:Epoch: 0415 val_loss: 0.444328 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 118.9011s
INFO:root:Val set results: val_loss: 0.514811 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Test set results: test_loss: 0.476742 test_acc: 0.818182 test_f1: 0.818182
