INFO:root:Using: cuda:7
INFO:root:Using seed 18.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=False, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f2f1c9176d0>)
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f2f1c9176d0>)
        )
      )
      (2): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f2f1c9176d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 160069
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 1.502430 train_acc: 0.606557 train_f1: 0.606557 time: 0.1985s
INFO:root:Epoch: 0005 val_loss: 1.475779 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.385072 train_acc: 0.606557 train_f1: 0.606557 time: 0.1953s
INFO:root:Epoch: 0010 val_loss: 1.364802 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 1.287283 train_acc: 0.606557 train_f1: 0.606557 time: 0.2019s
INFO:root:Epoch: 0015 val_loss: 1.277575 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.212611 train_acc: 0.606557 train_f1: 0.606557 time: 0.1996s
INFO:root:Epoch: 0020 val_loss: 1.215975 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 1.166559 train_acc: 0.606557 train_f1: 0.606557 time: 0.1939s
INFO:root:Epoch: 0025 val_loss: 1.186158 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.152219 train_acc: 0.606557 train_f1: 0.606557 time: 0.1941s
INFO:root:Epoch: 0030 val_loss: 1.189156 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 1.145752 train_acc: 0.606557 train_f1: 0.606557 time: 0.2054s
INFO:root:Epoch: 0035 val_loss: 1.198688 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.131551 train_acc: 0.606557 train_f1: 0.606557 time: 0.1980s
INFO:root:Epoch: 0040 val_loss: 1.185733 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 1.108782 train_acc: 0.606557 train_f1: 0.606557 time: 0.1957s
INFO:root:Epoch: 0045 val_loss: 1.154409 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.087104 train_acc: 0.606557 train_f1: 0.606557 time: 0.2148s
INFO:root:Epoch: 0050 val_loss: 1.128589 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 1.065538 train_acc: 0.606557 train_f1: 0.606557 time: 0.1965s
INFO:root:Epoch: 0055 val_loss: 1.106885 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.041053 train_acc: 0.606557 train_f1: 0.606557 time: 0.1954s
INFO:root:Epoch: 0060 val_loss: 1.085749 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 1.015473 train_acc: 0.606557 train_f1: 0.606557 time: 0.2074s
INFO:root:Epoch: 0065 val_loss: 1.064780 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.990312 train_acc: 0.606557 train_f1: 0.606557 time: 0.1978s
INFO:root:Epoch: 0070 val_loss: 1.044759 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 0.965427 train_acc: 0.606557 train_f1: 0.606557 time: 0.1967s
INFO:root:Epoch: 0075 val_loss: 1.026081 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.940913 train_acc: 0.606557 train_f1: 0.606557 time: 0.1999s
INFO:root:Epoch: 0080 val_loss: 1.008046 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 0.915235 train_acc: 0.606557 train_f1: 0.606557 time: 0.2164s
INFO:root:Epoch: 0085 val_loss: 0.986307 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.889384 train_acc: 0.606557 train_f1: 0.606557 time: 0.1960s
INFO:root:Epoch: 0090 val_loss: 0.964813 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 0.864354 train_acc: 0.606557 train_f1: 0.606557 time: 0.1963s
INFO:root:Epoch: 0095 val_loss: 0.947936 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 0.840326 train_acc: 0.606557 train_f1: 0.606557 time: 0.2028s
INFO:root:Epoch: 0100 val_loss: 0.929456 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0105 lr: [0.001, 0.001] train_loss: 0.818077 train_acc: 0.606557 train_f1: 0.606557 time: 0.2004s
INFO:root:Epoch: 0105 val_loss: 0.911517 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.797731 train_acc: 0.606557 train_f1: 0.606557 time: 0.1950s
INFO:root:Epoch: 0110 val_loss: 0.897108 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0115 lr: [0.001, 0.001] train_loss: 0.779133 train_acc: 0.606557 train_f1: 0.606557 time: 0.2094s
INFO:root:Epoch: 0115 val_loss: 0.886571 val_acc: 0.613636 val_f1: 0.613636
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.761989 train_acc: 0.795082 train_f1: 0.795082 time: 0.2110s
INFO:root:Epoch: 0120 val_loss: 0.878227 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0125 lr: [0.001, 0.001] train_loss: 0.745637 train_acc: 0.795082 train_f1: 0.795082 time: 0.2009s
INFO:root:Epoch: 0125 val_loss: 0.873344 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.730299 train_acc: 0.795082 train_f1: 0.795082 time: 0.2005s
INFO:root:Epoch: 0130 val_loss: 0.871827 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0135 lr: [0.001, 0.001] train_loss: 0.716131 train_acc: 0.795082 train_f1: 0.795082 time: 0.2030s
INFO:root:Epoch: 0135 val_loss: 0.871615 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.703226 train_acc: 0.795082 train_f1: 0.795082 time: 0.2212s
INFO:root:Epoch: 0140 val_loss: 0.871563 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0145 lr: [0.001, 0.001] train_loss: 0.691521 train_acc: 0.795082 train_f1: 0.795082 time: 0.2015s
INFO:root:Epoch: 0145 val_loss: 0.872837 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 0.687058 train_acc: 0.795082 train_f1: 0.795082 time: 0.2035s
INFO:root:Epoch: 0150 val_loss: 0.839376 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0155 lr: [0.001, 0.001] train_loss: 0.676301 train_acc: 0.795082 train_f1: 0.795082 time: 0.2067s
INFO:root:Epoch: 0155 val_loss: 0.863032 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 0.669448 train_acc: 0.795082 train_f1: 0.795082 time: 0.2157s
INFO:root:Epoch: 0160 val_loss: 0.868670 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0165 lr: [0.001, 0.001] train_loss: 0.663501 train_acc: 0.795082 train_f1: 0.795082 time: 0.2065s
INFO:root:Epoch: 0165 val_loss: 0.885929 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 0.657231 train_acc: 0.795082 train_f1: 0.795082 time: 0.2011s
INFO:root:Epoch: 0170 val_loss: 0.894027 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0175 lr: [0.001, 0.001] train_loss: 0.650765 train_acc: 0.795082 train_f1: 0.795082 time: 0.2018s
INFO:root:Epoch: 0175 val_loss: 0.899407 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 0.644787 train_acc: 0.795082 train_f1: 0.795082 time: 0.2147s
INFO:root:Epoch: 0180 val_loss: 0.896483 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0185 lr: [0.001, 0.001] train_loss: 0.638632 train_acc: 0.795082 train_f1: 0.795082 time: 0.2012s
INFO:root:Epoch: 0185 val_loss: 0.892049 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 0.631899 train_acc: 0.795082 train_f1: 0.795082 time: 0.2017s
INFO:root:Epoch: 0190 val_loss: 0.883474 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0195 lr: [0.001, 0.001] train_loss: 0.625269 train_acc: 0.795082 train_f1: 0.795082 time: 0.2117s
INFO:root:Epoch: 0195 val_loss: 0.894015 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0200 lr: [0.001, 0.001] train_loss: 0.629970 train_acc: 0.795082 train_f1: 0.795082 time: 0.2222s
INFO:root:Epoch: 0200 val_loss: 0.861463 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0205 lr: [0.001, 0.001] train_loss: 0.615481 train_acc: 0.795082 train_f1: 0.795082 time: 0.2026s
INFO:root:Epoch: 0205 val_loss: 0.866416 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0210 lr: [0.001, 0.001] train_loss: 0.613235 train_acc: 0.795082 train_f1: 0.795082 time: 0.2050s
INFO:root:Epoch: 0210 val_loss: 0.911273 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0215 lr: [0.001, 0.001] train_loss: 0.608833 train_acc: 0.795082 train_f1: 0.795082 time: 0.2079s
INFO:root:Epoch: 0215 val_loss: 0.895824 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0220 lr: [0.001, 0.001] train_loss: 0.604189 train_acc: 0.795082 train_f1: 0.795082 time: 0.2122s
INFO:root:Epoch: 0220 val_loss: 0.914248 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0225 lr: [0.001, 0.001] train_loss: 0.599552 train_acc: 0.795082 train_f1: 0.795082 time: 0.2000s
INFO:root:Epoch: 0225 val_loss: 0.905214 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0230 lr: [0.001, 0.001] train_loss: 0.594845 train_acc: 0.795082 train_f1: 0.795082 time: 0.2106s
INFO:root:Epoch: 0230 val_loss: 0.907019 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0235 lr: [0.001, 0.001] train_loss: 0.590206 train_acc: 0.795082 train_f1: 0.795082 time: 0.2309s
INFO:root:Epoch: 0235 val_loss: 0.910042 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0240 lr: [0.001, 0.001] train_loss: 0.586071 train_acc: 0.795082 train_f1: 0.795082 time: 0.2092s
INFO:root:Epoch: 0240 val_loss: 0.905032 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0245 lr: [0.001, 0.001] train_loss: 0.582018 train_acc: 0.795082 train_f1: 0.795082 time: 0.2073s
INFO:root:Epoch: 0245 val_loss: 0.902508 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0250 lr: [0.001, 0.001] train_loss: 0.578319 train_acc: 0.795082 train_f1: 0.795082 time: 0.2014s
INFO:root:Epoch: 0250 val_loss: 0.909049 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0255 lr: [0.001, 0.001] train_loss: 0.574875 train_acc: 0.795082 train_f1: 0.795082 time: 0.2200s
INFO:root:Epoch: 0255 val_loss: 0.904491 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0260 lr: [0.001, 0.001] train_loss: 0.571930 train_acc: 0.795082 train_f1: 0.795082 time: 0.2009s
INFO:root:Epoch: 0260 val_loss: 0.913802 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0265 lr: [0.001, 0.001] train_loss: 0.568491 train_acc: 0.795082 train_f1: 0.795082 time: 0.1995s
INFO:root:Epoch: 0265 val_loss: 0.911159 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0270 lr: [0.001, 0.001] train_loss: 0.565418 train_acc: 0.795082 train_f1: 0.795082 time: 0.2020s
INFO:root:Epoch: 0270 val_loss: 0.911918 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0275 lr: [0.001, 0.001] train_loss: 0.562190 train_acc: 0.795082 train_f1: 0.795082 time: 0.2130s
INFO:root:Epoch: 0275 val_loss: 0.913034 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0280 lr: [0.001, 0.001] train_loss: 0.559053 train_acc: 0.795082 train_f1: 0.795082 time: 0.2008s
INFO:root:Epoch: 0280 val_loss: 0.912485 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0285 lr: [0.001, 0.001] train_loss: 0.555990 train_acc: 0.795082 train_f1: 0.795082 time: 0.2001s
INFO:root:Epoch: 0285 val_loss: 0.913138 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0290 lr: [0.001, 0.001] train_loss: 0.553018 train_acc: 0.795082 train_f1: 0.795082 time: 0.2103s
INFO:root:Epoch: 0290 val_loss: 0.912339 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0295 lr: [0.001, 0.001] train_loss: 0.550080 train_acc: 0.795082 train_f1: 0.795082 time: 0.2079s
INFO:root:Epoch: 0295 val_loss: 0.913399 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0300 lr: [0.001, 0.001] train_loss: 0.547205 train_acc: 0.795082 train_f1: 0.795082 time: 0.2001s
INFO:root:Epoch: 0300 val_loss: 0.914310 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0305 lr: [0.001, 0.001] train_loss: 0.545759 train_acc: 0.795082 train_f1: 0.795082 time: 0.2033s
INFO:root:Epoch: 0305 val_loss: 0.913670 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0310 lr: [0.001, 0.001] train_loss: 0.542052 train_acc: 0.795082 train_f1: 0.795082 time: 0.2218s
INFO:root:Epoch: 0310 val_loss: 0.915293 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0315 lr: [0.001, 0.001] train_loss: 0.539295 train_acc: 0.795082 train_f1: 0.795082 time: 0.2009s
INFO:root:Epoch: 0315 val_loss: 0.915674 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0320 lr: [0.001, 0.001] train_loss: 0.536567 train_acc: 0.795082 train_f1: 0.795082 time: 0.1997s
INFO:root:Epoch: 0320 val_loss: 0.918851 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0325 lr: [0.001, 0.001] train_loss: 0.533974 train_acc: 0.795082 train_f1: 0.795082 time: 0.2113s
INFO:root:Epoch: 0325 val_loss: 0.916778 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0330 lr: [0.001, 0.001] train_loss: 0.531528 train_acc: 0.795082 train_f1: 0.795082 time: 0.2138s
INFO:root:Epoch: 0330 val_loss: 0.916892 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0335 lr: [0.001, 0.001] train_loss: 0.528955 train_acc: 0.795082 train_f1: 0.795082 time: 0.2071s
INFO:root:Epoch: 0335 val_loss: 0.915972 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0340 lr: [0.001, 0.001] train_loss: 0.526769 train_acc: 0.795082 train_f1: 0.795082 time: 0.2008s
INFO:root:Epoch: 0340 val_loss: 0.916291 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0345 lr: [0.001, 0.001] train_loss: 0.531922 train_acc: 0.790984 train_f1: 0.790984 time: 0.2025s
INFO:root:Epoch: 0345 val_loss: 0.917217 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0350 lr: [0.001, 0.001] train_loss: 0.527582 train_acc: 0.790984 train_f1: 0.790984 time: 0.2137s
INFO:root:Epoch: 0350 val_loss: 0.920469 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0355 lr: [0.001, 0.001] train_loss: 0.524201 train_acc: 0.795082 train_f1: 0.795082 time: 0.2101s
INFO:root:Epoch: 0355 val_loss: 0.921459 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0360 lr: [0.001, 0.001] train_loss: 0.521226 train_acc: 0.795082 train_f1: 0.795082 time: 0.2018s
INFO:root:Epoch: 0360 val_loss: 0.920442 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0365 lr: [0.001, 0.001] train_loss: 0.518217 train_acc: 0.795082 train_f1: 0.795082 time: 0.2116s
INFO:root:Epoch: 0365 val_loss: 0.920405 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0370 lr: [0.001, 0.001] train_loss: 0.515219 train_acc: 0.795082 train_f1: 0.795082 time: 0.2094s
INFO:root:Epoch: 0370 val_loss: 0.914534 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0375 lr: [0.001, 0.001] train_loss: 0.512498 train_acc: 0.795082 train_f1: 0.795082 time: 0.2034s
INFO:root:Epoch: 0375 val_loss: 0.914542 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0380 lr: [0.001, 0.001] train_loss: 0.509974 train_acc: 0.795082 train_f1: 0.795082 time: 0.2034s
INFO:root:Epoch: 0380 val_loss: 0.914465 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0385 lr: [0.001, 0.001] train_loss: 0.507677 train_acc: 0.795082 train_f1: 0.795082 time: 0.2133s
INFO:root:Epoch: 0385 val_loss: 0.916047 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0390 lr: [0.001, 0.001] train_loss: 0.506063 train_acc: 0.795082 train_f1: 0.795082 time: 0.2093s
INFO:root:Epoch: 0390 val_loss: 0.915791 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0395 lr: [0.001, 0.001] train_loss: 0.504234 train_acc: 0.795082 train_f1: 0.795082 time: 0.2065s
INFO:root:Epoch: 0395 val_loss: 0.911369 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0400 lr: [0.001, 0.001] train_loss: 0.502102 train_acc: 0.795082 train_f1: 0.795082 time: 0.2032s
INFO:root:Epoch: 0400 val_loss: 0.916475 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0405 lr: [0.001, 0.001] train_loss: 0.499570 train_acc: 0.795082 train_f1: 0.795082 time: 0.2167s
INFO:root:Epoch: 0405 val_loss: 0.912876 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0410 lr: [0.001, 0.001] train_loss: 0.496967 train_acc: 0.795082 train_f1: 0.795082 time: 0.2043s
INFO:root:Epoch: 0410 val_loss: 0.912518 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0415 lr: [0.001, 0.001] train_loss: 0.494610 train_acc: 0.795082 train_f1: 0.795082 time: 0.2033s
INFO:root:Epoch: 0415 val_loss: 0.913809 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0420 lr: [0.001, 0.001] train_loss: 0.492571 train_acc: 0.795082 train_f1: 0.795082 time: 0.2020s
INFO:root:Epoch: 0420 val_loss: 0.915219 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0425 lr: [0.001, 0.001] train_loss: 0.490862 train_acc: 0.795082 train_f1: 0.795082 time: 0.2104s
INFO:root:Epoch: 0425 val_loss: 0.912251 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0430 lr: [0.001, 0.001] train_loss: 0.489384 train_acc: 0.795082 train_f1: 0.795082 time: 0.2023s
INFO:root:Epoch: 0430 val_loss: 0.910583 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0435 lr: [0.001, 0.001] train_loss: 0.488045 train_acc: 0.795082 train_f1: 0.795082 time: 0.2025s
INFO:root:Epoch: 0435 val_loss: 0.910374 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0440 lr: [0.001, 0.001] train_loss: 0.486906 train_acc: 0.795082 train_f1: 0.795082 time: 0.2101s
INFO:root:Epoch: 0440 val_loss: 0.906200 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0445 lr: [0.001, 0.001] train_loss: 0.486920 train_acc: 0.795082 train_f1: 0.795082 time: 0.2063s
INFO:root:Epoch: 0445 val_loss: 0.912843 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0450 lr: [0.001, 0.001] train_loss: 0.484821 train_acc: 0.795082 train_f1: 0.795082 time: 0.1962s
INFO:root:Epoch: 0450 val_loss: 0.905059 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0455 lr: [0.001, 0.001] train_loss: 0.483730 train_acc: 0.795082 train_f1: 0.795082 time: 0.2086s
INFO:root:Epoch: 0455 val_loss: 0.908477 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0460 lr: [0.001, 0.001] train_loss: 0.482574 train_acc: 0.795082 train_f1: 0.795082 time: 0.2165s
INFO:root:Epoch: 0460 val_loss: 0.904254 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0465 lr: [0.001, 0.001] train_loss: 0.481342 train_acc: 0.795082 train_f1: 0.795082 time: 0.2062s
INFO:root:Epoch: 0465 val_loss: 0.905641 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0470 lr: [0.001, 0.001] train_loss: 0.480489 train_acc: 0.790984 train_f1: 0.790984 time: 0.2036s
INFO:root:Epoch: 0470 val_loss: 0.902472 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 100.9919s
INFO:root:Val set results: val_loss: 0.917217 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Test set results: test_loss: 0.791014 test_acc: 0.772727 test_f1: 0.772727
