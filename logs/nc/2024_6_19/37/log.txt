INFO:root:Using: cuda:0
INFO:root:Using seed 18.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (6): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (7): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 117989
INFO:root:Epoch: 0005 lr: [1e-06, 1e-06] train_loss: 1.6094 train_acc: 0.5861 train_f1: 0.5861 time: 0.0548s
INFO:root:Epoch: 0005 val_loss: 1.6094 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0010 lr: [1e-06, 1e-06] train_loss: 1.6093 train_acc: 0.5861 train_f1: 0.5861 time: 0.0544s
INFO:root:Epoch: 0010 val_loss: 1.6093 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0015 lr: [1e-06, 1e-06] train_loss: 1.6093 train_acc: 0.5861 train_f1: 0.5861 time: 0.0551s
INFO:root:Epoch: 0015 val_loss: 1.6092 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0020 lr: [1e-06, 1e-06] train_loss: 1.6092 train_acc: 0.5861 train_f1: 0.5861 time: 0.0547s
INFO:root:Epoch: 0020 val_loss: 1.6091 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0025 lr: [1e-06, 1e-06] train_loss: 1.6091 train_acc: 0.5861 train_f1: 0.5861 time: 0.0543s
INFO:root:Epoch: 0025 val_loss: 1.6090 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0030 lr: [1e-06, 1e-06] train_loss: 1.6091 train_acc: 0.5861 train_f1: 0.5861 time: 0.0544s
INFO:root:Epoch: 0030 val_loss: 1.6090 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0035 lr: [1e-06, 1e-06] train_loss: 1.6090 train_acc: 0.5861 train_f1: 0.5861 time: 0.0576s
INFO:root:Epoch: 0035 val_loss: 1.6089 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0040 lr: [1e-06, 1e-06] train_loss: 1.6089 train_acc: 0.5861 train_f1: 0.5861 time: 0.0590s
INFO:root:Epoch: 0040 val_loss: 1.6088 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0045 lr: [1e-06, 1e-06] train_loss: 1.6089 train_acc: 0.5861 train_f1: 0.5861 time: 0.0544s
INFO:root:Epoch: 0045 val_loss: 1.6087 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0050 lr: [1e-06, 1e-06] train_loss: 1.6088 train_acc: 0.5861 train_f1: 0.5861 time: 0.0543s
INFO:root:Epoch: 0050 val_loss: 1.6087 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0055 lr: [1e-06, 1e-06] train_loss: 1.6087 train_acc: 0.5861 train_f1: 0.5861 time: 0.0553s
INFO:root:Epoch: 0055 val_loss: 1.6086 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0060 lr: [1e-06, 1e-06] train_loss: 1.6087 train_acc: 0.5861 train_f1: 0.5861 time: 0.0550s
INFO:root:Epoch: 0060 val_loss: 1.6085 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0065 lr: [1e-06, 1e-06] train_loss: 1.6086 train_acc: 0.5861 train_f1: 0.5861 time: 0.0565s
INFO:root:Epoch: 0065 val_loss: 1.6084 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0070 lr: [1e-06, 1e-06] train_loss: 1.6085 train_acc: 0.5861 train_f1: 0.5861 time: 0.0582s
INFO:root:Epoch: 0070 val_loss: 1.6083 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0075 lr: [1e-06, 1e-06] train_loss: 1.6085 train_acc: 0.5861 train_f1: 0.5861 time: 0.0545s
INFO:root:Epoch: 0075 val_loss: 1.6083 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0080 lr: [1e-06, 1e-06] train_loss: 1.6084 train_acc: 0.5861 train_f1: 0.5861 time: 0.0558s
INFO:root:Epoch: 0080 val_loss: 1.6082 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0085 lr: [1e-06, 1e-06] train_loss: 1.6083 train_acc: 0.5861 train_f1: 0.5861 time: 0.0550s
INFO:root:Epoch: 0085 val_loss: 1.6081 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0090 lr: [1e-06, 1e-06] train_loss: 1.6083 train_acc: 0.5861 train_f1: 0.5861 time: 0.0542s
INFO:root:Epoch: 0090 val_loss: 1.6080 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0095 lr: [1e-06, 1e-06] train_loss: 1.6082 train_acc: 0.5861 train_f1: 0.5861 time: 0.0546s
INFO:root:Epoch: 0095 val_loss: 1.6080 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0100 lr: [1e-06, 1e-06] train_loss: 1.6081 train_acc: 0.5861 train_f1: 0.5861 time: 0.0543s
INFO:root:Epoch: 0100 val_loss: 1.6079 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0105 lr: [1e-06, 1e-06] train_loss: 1.6081 train_acc: 0.5861 train_f1: 0.5861 time: 0.0549s
INFO:root:Epoch: 0105 val_loss: 1.6078 val_acc: 0.6591 val_f1: 0.6591
