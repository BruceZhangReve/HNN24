INFO:root:Using: cuda:0
INFO:root:Using seed 18.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (6): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (7): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (6): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (7): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 120293
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 1.5588 train_acc: 0.5861 train_f1: 0.5861 time: 0.0906s
INFO:root:Epoch: 0005 val_loss: 1.5340 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.4998 train_acc: 0.5861 train_f1: 0.5861 time: 0.0928s
INFO:root:Epoch: 0010 val_loss: 1.4636 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 1.4457 train_acc: 0.5861 train_f1: 0.5861 time: 0.0928s
INFO:root:Epoch: 0015 val_loss: 1.3982 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.3964 train_acc: 0.5861 train_f1: 0.5861 time: 0.0912s
INFO:root:Epoch: 0020 val_loss: 1.3381 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 1.3520 train_acc: 0.5861 train_f1: 0.5861 time: 0.0913s
INFO:root:Epoch: 0025 val_loss: 1.2832 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.3126 train_acc: 0.5861 train_f1: 0.5861 time: 0.0904s
INFO:root:Epoch: 0030 val_loss: 1.2336 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 1.2787 train_acc: 0.5861 train_f1: 0.5861 time: 0.0939s
INFO:root:Epoch: 0035 val_loss: 1.1896 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.2507 train_acc: 0.5861 train_f1: 0.5861 time: 0.0961s
INFO:root:Epoch: 0040 val_loss: 1.1517 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 1.2293 train_acc: 0.5861 train_f1: 0.5861 time: 0.0964s
INFO:root:Epoch: 0045 val_loss: 1.1206 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.2147 train_acc: 0.5861 train_f1: 0.5861 time: 0.0905s
INFO:root:Epoch: 0050 val_loss: 1.0972 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 1.2063 train_acc: 0.5861 train_f1: 0.5861 time: 0.0908s
INFO:root:Epoch: 0055 val_loss: 1.0819 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.2020 train_acc: 0.5861 train_f1: 0.5861 time: 0.0910s
INFO:root:Epoch: 0060 val_loss: 1.0740 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 1.1991 train_acc: 0.5861 train_f1: 0.5861 time: 0.0909s
INFO:root:Epoch: 0065 val_loss: 1.0714 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.1959 train_acc: 0.5861 train_f1: 0.5861 time: 0.0905s
INFO:root:Epoch: 0070 val_loss: 1.0705 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 1.1919 train_acc: 0.5861 train_f1: 0.5861 time: 0.0940s
INFO:root:Epoch: 0075 val_loss: 1.0696 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.1882 train_acc: 0.5861 train_f1: 0.5861 time: 0.0948s
INFO:root:Epoch: 0080 val_loss: 1.0700 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 1.1852 train_acc: 0.5861 train_f1: 0.5861 time: 0.0926s
INFO:root:Epoch: 0085 val_loss: 1.0713 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.1827 train_acc: 0.5861 train_f1: 0.5861 time: 0.0912s
INFO:root:Epoch: 0090 val_loss: 1.0722 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 1.1803 train_acc: 0.5861 train_f1: 0.5861 time: 0.0910s
INFO:root:Epoch: 0095 val_loss: 1.0714 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 1.1780 train_acc: 0.5861 train_f1: 0.5861 time: 0.0962s
INFO:root:Epoch: 0100 val_loss: 1.0693 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0105 lr: [0.001, 0.001] train_loss: 1.1757 train_acc: 0.5861 train_f1: 0.5861 time: 0.0939s
INFO:root:Epoch: 0105 val_loss: 1.0669 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 1.1737 train_acc: 0.5861 train_f1: 0.5861 time: 0.0907s
INFO:root:Epoch: 0110 val_loss: 1.0649 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0115 lr: [0.001, 0.001] train_loss: 1.1717 train_acc: 0.5861 train_f1: 0.5861 time: 0.0942s
INFO:root:Epoch: 0115 val_loss: 1.0633 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 1.1698 train_acc: 0.5861 train_f1: 0.5861 time: 0.0931s
INFO:root:Epoch: 0120 val_loss: 1.0619 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0125 lr: [0.001, 0.001] train_loss: 1.1679 train_acc: 0.5861 train_f1: 0.5861 time: 0.0912s
INFO:root:Epoch: 0125 val_loss: 1.0606 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 1.1660 train_acc: 0.5861 train_f1: 0.5861 time: 0.0918s
INFO:root:Epoch: 0130 val_loss: 1.0592 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0135 lr: [0.001, 0.001] train_loss: 1.1642 train_acc: 0.5861 train_f1: 0.5861 time: 0.0940s
INFO:root:Epoch: 0135 val_loss: 1.0571 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 1.1624 train_acc: 0.5861 train_f1: 0.5861 time: 0.0907s
INFO:root:Epoch: 0140 val_loss: 1.0546 val_acc: 0.6591 val_f1: 0.6591
