INFO:root:Using: cuda:7
INFO:root:Using seed 42.
INFO:root:Dataset: wisconsin
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.23, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
            (3): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
            (3): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.23, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 63441.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.646765 train_acc: 0.560510 train_f1: 0.560510 time: 0.0558s
INFO:root:Epoch: 0010 val_loss: 1.524123 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.527913 train_acc: 0.582803 train_f1: 0.582803 time: 0.0590s
INFO:root:Epoch: 0020 val_loss: 1.436237 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.457265 train_acc: 0.621019 train_f1: 0.621019 time: 0.0644s
INFO:root:Epoch: 0030 val_loss: 1.387379 val_acc: 0.666667 val_f1: 0.666667
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.367535 train_acc: 0.662420 train_f1: 0.662420 time: 0.0545s
INFO:root:Epoch: 0040 val_loss: 1.332423 val_acc: 0.722222 val_f1: 0.722222
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.287217 train_acc: 0.703822 train_f1: 0.703822 time: 0.0539s
INFO:root:Epoch: 0050 val_loss: 1.287925 val_acc: 0.740741 val_f1: 0.740741
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.209718 train_acc: 0.767516 train_f1: 0.767516 time: 0.0572s
INFO:root:Epoch: 0060 val_loss: 1.265564 val_acc: 0.759259 val_f1: 0.759259
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.171525 train_acc: 0.802548 train_f1: 0.802548 time: 0.0571s
INFO:root:Epoch: 0070 val_loss: 1.249837 val_acc: 0.777778 val_f1: 0.777778
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.146483 train_acc: 0.812102 train_f1: 0.812102 time: 0.0708s
INFO:root:Epoch: 0080 val_loss: 1.233921 val_acc: 0.796296 val_f1: 0.796296
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.110513 train_acc: 0.831210 train_f1: 0.831210 time: 0.0607s
INFO:root:Epoch: 0090 val_loss: 1.218468 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.090316 train_acc: 0.850318 train_f1: 0.850318 time: 0.0684s
INFO:root:Epoch: 0100 val_loss: 1.200853 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.085672 train_acc: 0.843949 train_f1: 0.843949 time: 0.0649s
INFO:root:Epoch: 0110 val_loss: 1.195915 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.075093 train_acc: 0.853503 train_f1: 0.853503 time: 0.0683s
INFO:root:Epoch: 0120 val_loss: 1.193764 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.062562 train_acc: 0.856688 train_f1: 0.856688 time: 0.0644s
INFO:root:Epoch: 0130 val_loss: 1.190418 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.061036 train_acc: 0.859873 train_f1: 0.859873 time: 0.0736s
INFO:root:Epoch: 0140 val_loss: 1.187530 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.053293 train_acc: 0.859873 train_f1: 0.859873 time: 0.0653s
INFO:root:Epoch: 0150 val_loss: 1.183360 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.048585 train_acc: 0.856688 train_f1: 0.856688 time: 0.0651s
INFO:root:Epoch: 0160 val_loss: 1.179694 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.039361 train_acc: 0.869427 train_f1: 0.869427 time: 0.0629s
INFO:root:Epoch: 0170 val_loss: 1.173487 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.029320 train_acc: 0.869427 train_f1: 0.869427 time: 0.0611s
INFO:root:Epoch: 0180 val_loss: 1.173012 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.024741 train_acc: 0.869427 train_f1: 0.869427 time: 0.0623s
INFO:root:Epoch: 0190 val_loss: 1.169683 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 1.031624 train_acc: 0.859873 train_f1: 0.859873 time: 0.0645s
INFO:root:Epoch: 0200 val_loss: 1.165166 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 1.027404 train_acc: 0.869427 train_f1: 0.869427 time: 0.0599s
INFO:root:Epoch: 0210 val_loss: 1.160141 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 1.015514 train_acc: 0.866242 train_f1: 0.866242 time: 0.0614s
INFO:root:Epoch: 0220 val_loss: 1.158948 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 1.018492 train_acc: 0.872611 train_f1: 0.872611 time: 0.0710s
INFO:root:Epoch: 0230 val_loss: 1.157854 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 1.018191 train_acc: 0.863057 train_f1: 0.863057 time: 0.0646s
INFO:root:Epoch: 0240 val_loss: 1.157073 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 1.008121 train_acc: 0.872611 train_f1: 0.872611 time: 0.0654s
INFO:root:Epoch: 0250 val_loss: 1.156402 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 1.007287 train_acc: 0.869427 train_f1: 0.869427 time: 0.0613s
INFO:root:Epoch: 0260 val_loss: 1.154484 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 1.008950 train_acc: 0.866242 train_f1: 0.866242 time: 0.0628s
INFO:root:Epoch: 0270 val_loss: 1.152601 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 1.005295 train_acc: 0.872611 train_f1: 0.872611 time: 0.0640s
INFO:root:Epoch: 0280 val_loss: 1.151414 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 1.004687 train_acc: 0.872611 train_f1: 0.872611 time: 0.0663s
INFO:root:Epoch: 0290 val_loss: 1.148633 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 1.004277 train_acc: 0.866242 train_f1: 0.866242 time: 0.0623s
INFO:root:Epoch: 0300 val_loss: 1.144339 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 0.998790 train_acc: 0.872611 train_f1: 0.872611 time: 0.0675s
INFO:root:Epoch: 0310 val_loss: 1.143520 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 1.003766 train_acc: 0.869427 train_f1: 0.869427 time: 0.0619s
INFO:root:Epoch: 0320 val_loss: 1.142665 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 0.996440 train_acc: 0.872611 train_f1: 0.872611 time: 0.0658s
INFO:root:Epoch: 0330 val_loss: 1.140806 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 0.997717 train_acc: 0.875796 train_f1: 0.875796 time: 0.0648s
INFO:root:Epoch: 0340 val_loss: 1.139257 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 0.996017 train_acc: 0.872611 train_f1: 0.872611 time: 0.0637s
INFO:root:Epoch: 0350 val_loss: 1.140142 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 0.992347 train_acc: 0.872611 train_f1: 0.872611 time: 0.0669s
INFO:root:Epoch: 0360 val_loss: 1.140854 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 1.002670 train_acc: 0.872611 train_f1: 0.872611 time: 0.0635s
INFO:root:Epoch: 0370 val_loss: 1.141119 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 0.991738 train_acc: 0.872611 train_f1: 0.872611 time: 0.0667s
INFO:root:Epoch: 0380 val_loss: 1.141009 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 0.988759 train_acc: 0.872611 train_f1: 0.872611 time: 0.0634s
INFO:root:Epoch: 0390 val_loss: 1.139434 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 0.997444 train_acc: 0.869427 train_f1: 0.869427 time: 0.0747s
INFO:root:Epoch: 0400 val_loss: 1.138607 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 0.994567 train_acc: 0.866242 train_f1: 0.866242 time: 0.0648s
INFO:root:Epoch: 0410 val_loss: 1.138389 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 0.991196 train_acc: 0.872611 train_f1: 0.872611 time: 0.0676s
INFO:root:Epoch: 0420 val_loss: 1.138156 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 0.990955 train_acc: 0.872611 train_f1: 0.872611 time: 0.0655s
INFO:root:Epoch: 0430 val_loss: 1.137582 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 0.990082 train_acc: 0.872611 train_f1: 0.872611 time: 0.0698s
INFO:root:Epoch: 0440 val_loss: 1.137583 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 0.987105 train_acc: 0.875796 train_f1: 0.875796 time: 0.0610s
INFO:root:Epoch: 0450 val_loss: 1.137626 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 0.994132 train_acc: 0.872611 train_f1: 0.872611 time: 0.0666s
INFO:root:Epoch: 0460 val_loss: 1.136982 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 0.990527 train_acc: 0.872611 train_f1: 0.872611 time: 0.0630s
INFO:root:Epoch: 0470 val_loss: 1.136326 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 0.987466 train_acc: 0.875796 train_f1: 0.875796 time: 0.0618s
INFO:root:Epoch: 0480 val_loss: 1.135897 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 0.988022 train_acc: 0.875796 train_f1: 0.875796 time: 0.0629s
INFO:root:Epoch: 0490 val_loss: 1.135928 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 0.983882 train_acc: 0.872611 train_f1: 0.872611 time: 0.0658s
INFO:root:Epoch: 0500 val_loss: 1.136062 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 0.989860 train_acc: 0.869427 train_f1: 0.869427 time: 0.0653s
INFO:root:Epoch: 0510 val_loss: 1.136003 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 0.986089 train_acc: 0.875796 train_f1: 0.875796 time: 0.0622s
INFO:root:Epoch: 0520 val_loss: 1.135830 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 0.991125 train_acc: 0.872611 train_f1: 0.872611 time: 0.0628s
INFO:root:Epoch: 0530 val_loss: 1.135407 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 0.990637 train_acc: 0.872611 train_f1: 0.872611 time: 0.0633s
INFO:root:Epoch: 0540 val_loss: 1.134937 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 0.986855 train_acc: 0.872611 train_f1: 0.872611 time: 0.0708s
INFO:root:Epoch: 0550 val_loss: 1.134610 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 0.990409 train_acc: 0.869427 train_f1: 0.869427 time: 0.0637s
INFO:root:Epoch: 0560 val_loss: 1.134399 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 0.986791 train_acc: 0.869427 train_f1: 0.869427 time: 0.0658s
INFO:root:Epoch: 0570 val_loss: 1.134232 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 0.983043 train_acc: 0.872611 train_f1: 0.872611 time: 0.0624s
INFO:root:Epoch: 0580 val_loss: 1.133975 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 0.983097 train_acc: 0.872611 train_f1: 0.872611 time: 0.0630s
INFO:root:Epoch: 0590 val_loss: 1.133361 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.981696 train_acc: 0.872611 train_f1: 0.872611 time: 0.0624s
INFO:root:Epoch: 0600 val_loss: 1.132839 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0610 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.985228 train_acc: 0.872611 train_f1: 0.872611 time: 0.0751s
INFO:root:Epoch: 0610 val_loss: 1.132737 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0620 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.985784 train_acc: 0.872611 train_f1: 0.872611 time: 0.0635s
INFO:root:Epoch: 0620 val_loss: 1.132687 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0630 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.984604 train_acc: 0.872611 train_f1: 0.872611 time: 0.0633s
INFO:root:Epoch: 0630 val_loss: 1.132579 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0640 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.982921 train_acc: 0.872611 train_f1: 0.872611 time: 0.0632s
INFO:root:Epoch: 0640 val_loss: 1.132282 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0650 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.982290 train_acc: 0.872611 train_f1: 0.872611 time: 0.0627s
INFO:root:Epoch: 0650 val_loss: 1.132121 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0660 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.986656 train_acc: 0.872611 train_f1: 0.872611 time: 0.0623s
INFO:root:Epoch: 0660 val_loss: 1.131958 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0670 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.984359 train_acc: 0.872611 train_f1: 0.872611 time: 0.0606s
INFO:root:Epoch: 0670 val_loss: 1.131650 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0680 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.983556 train_acc: 0.872611 train_f1: 0.872611 time: 0.0691s
INFO:root:Epoch: 0680 val_loss: 1.131393 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 46.3496s
INFO:root:Val set results: val_loss: 1.173012 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Test set results: test_loss: 1.165052 test_acc: 0.777778 test_f1: 0.777778
