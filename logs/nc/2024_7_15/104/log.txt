INFO:root:Using: cuda:7
INFO:root:Using seed 1.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7fc2b62df6d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 59077
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.457073 train_acc: 0.598361 train_f1: 0.598361 time: 0.0540s
INFO:root:Epoch: 0010 val_loss: 1.416716 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.320179 train_acc: 0.598361 train_f1: 0.598361 time: 0.0581s
INFO:root:Epoch: 0020 val_loss: 1.264439 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.222145 train_acc: 0.598361 train_f1: 0.598361 time: 0.0648s
INFO:root:Epoch: 0030 val_loss: 1.151602 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.178610 train_acc: 0.598361 train_f1: 0.598361 time: 0.0553s
INFO:root:Epoch: 0040 val_loss: 1.096555 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.173578 train_acc: 0.598361 train_f1: 0.598361 time: 0.0669s
INFO:root:Epoch: 0050 val_loss: 1.098860 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.159827 train_acc: 0.598361 train_f1: 0.598361 time: 0.0649s
INFO:root:Epoch: 0060 val_loss: 1.081754 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.151030 train_acc: 0.598361 train_f1: 0.598361 time: 0.0729s
INFO:root:Epoch: 0070 val_loss: 1.075683 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.142081 train_acc: 0.598361 train_f1: 0.598361 time: 0.0673s
INFO:root:Epoch: 0080 val_loss: 1.066058 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.133928 train_acc: 0.598361 train_f1: 0.598361 time: 0.0689s
INFO:root:Epoch: 0090 val_loss: 1.058865 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.126497 train_acc: 0.598361 train_f1: 0.598361 time: 0.0632s
INFO:root:Epoch: 0100 val_loss: 1.051024 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.121282 train_acc: 0.598361 train_f1: 0.598361 time: 0.0646s
INFO:root:Epoch: 0110 val_loss: 1.048339 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.117898 train_acc: 0.598361 train_f1: 0.598361 time: 0.0606s
INFO:root:Epoch: 0120 val_loss: 1.044906 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.113901 train_acc: 0.598361 train_f1: 0.598361 time: 0.0647s
INFO:root:Epoch: 0130 val_loss: 1.042282 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.111166 train_acc: 0.598361 train_f1: 0.598361 time: 0.0609s
INFO:root:Epoch: 0140 val_loss: 1.039389 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.107088 train_acc: 0.598361 train_f1: 0.598361 time: 0.0630s
INFO:root:Epoch: 0150 val_loss: 1.036483 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.103701 train_acc: 0.598361 train_f1: 0.598361 time: 0.0692s
INFO:root:Epoch: 0160 val_loss: 1.033539 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.098850 train_acc: 0.598361 train_f1: 0.598361 time: 0.0607s
INFO:root:Epoch: 0170 val_loss: 1.030657 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.097048 train_acc: 0.598361 train_f1: 0.598361 time: 0.0700s
INFO:root:Epoch: 0180 val_loss: 1.027802 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.093798 train_acc: 0.598361 train_f1: 0.598361 time: 0.0641s
INFO:root:Epoch: 0190 val_loss: 1.024668 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 1.089744 train_acc: 0.598361 train_f1: 0.598361 time: 0.0613s
INFO:root:Epoch: 0200 val_loss: 1.022320 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 1.088709 train_acc: 0.598361 train_f1: 0.598361 time: 0.0607s
INFO:root:Epoch: 0210 val_loss: 1.020579 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 1.086765 train_acc: 0.598361 train_f1: 0.598361 time: 0.0604s
INFO:root:Epoch: 0220 val_loss: 1.019368 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 1.086133 train_acc: 0.598361 train_f1: 0.598361 time: 0.0611s
INFO:root:Epoch: 0230 val_loss: 1.017750 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 1.084167 train_acc: 0.598361 train_f1: 0.598361 time: 0.0617s
INFO:root:Epoch: 0240 val_loss: 1.016478 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 1.081461 train_acc: 0.598361 train_f1: 0.598361 time: 0.0606s
INFO:root:Epoch: 0250 val_loss: 1.015062 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 1.082391 train_acc: 0.598361 train_f1: 0.598361 time: 0.0606s
INFO:root:Epoch: 0260 val_loss: 1.010036 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 1.082349 train_acc: 0.598361 train_f1: 0.598361 time: 0.0623s
INFO:root:Epoch: 0270 val_loss: 1.023183 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 1.080292 train_acc: 0.598361 train_f1: 0.598361 time: 0.0611s
INFO:root:Epoch: 0280 val_loss: 1.007897 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 1.078784 train_acc: 0.598361 train_f1: 0.598361 time: 0.0611s
INFO:root:Epoch: 0290 val_loss: 1.013551 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 1.078439 train_acc: 0.598361 train_f1: 0.598361 time: 0.0633s
INFO:root:Epoch: 0300 val_loss: 1.009807 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 1.076597 train_acc: 0.598361 train_f1: 0.598361 time: 0.0625s
INFO:root:Epoch: 0310 val_loss: 1.010148 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 1.076900 train_acc: 0.598361 train_f1: 0.598361 time: 0.0607s
INFO:root:Epoch: 0320 val_loss: 1.011003 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 1.075819 train_acc: 0.598361 train_f1: 0.598361 time: 0.0612s
INFO:root:Epoch: 0330 val_loss: 1.009926 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 1.076736 train_acc: 0.598361 train_f1: 0.598361 time: 0.0606s
INFO:root:Epoch: 0340 val_loss: 1.009033 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 1.078207 train_acc: 0.598361 train_f1: 0.598361 time: 0.0608s
INFO:root:Epoch: 0350 val_loss: 1.008116 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 1.077583 train_acc: 0.598361 train_f1: 0.598361 time: 0.0611s
INFO:root:Epoch: 0360 val_loss: 1.007864 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 1.077535 train_acc: 0.598361 train_f1: 0.598361 time: 0.0603s
INFO:root:Epoch: 0370 val_loss: 1.012304 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 1.075868 train_acc: 0.598361 train_f1: 0.598361 time: 0.0684s
INFO:root:Epoch: 0380 val_loss: 1.010835 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 1.077223 train_acc: 0.598361 train_f1: 0.598361 time: 0.0607s
INFO:root:Epoch: 0390 val_loss: 1.010496 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 1.076050 train_acc: 0.598361 train_f1: 0.598361 time: 0.0711s
INFO:root:Epoch: 0400 val_loss: 1.009677 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 1.074325 train_acc: 0.598361 train_f1: 0.598361 time: 0.0609s
INFO:root:Epoch: 0410 val_loss: 1.008801 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 1.074582 train_acc: 0.598361 train_f1: 0.598361 time: 0.0610s
INFO:root:Epoch: 0420 val_loss: 1.009625 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 1.075048 train_acc: 0.598361 train_f1: 0.598361 time: 0.0611s
INFO:root:Epoch: 0430 val_loss: 1.008702 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 1.075482 train_acc: 0.598361 train_f1: 0.598361 time: 0.0630s
INFO:root:Epoch: 0440 val_loss: 1.009200 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 1.076262 train_acc: 0.598361 train_f1: 0.598361 time: 0.0610s
INFO:root:Epoch: 0450 val_loss: 1.008755 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 1.073677 train_acc: 0.598361 train_f1: 0.598361 time: 0.0608s
INFO:root:Epoch: 0460 val_loss: 1.009034 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 1.075266 train_acc: 0.598361 train_f1: 0.598361 time: 0.0610s
INFO:root:Epoch: 0470 val_loss: 1.009502 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 1.075707 train_acc: 0.598361 train_f1: 0.598361 time: 0.0607s
INFO:root:Epoch: 0480 val_loss: 1.007445 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 1.072532 train_acc: 0.598361 train_f1: 0.598361 time: 0.0619s
INFO:root:Epoch: 0490 val_loss: 1.008780 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 1.075581 train_acc: 0.598361 train_f1: 0.598361 time: 0.0609s
INFO:root:Epoch: 0500 val_loss: 1.002002 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 1.073834 train_acc: 0.598361 train_f1: 0.598361 time: 0.0686s
INFO:root:Epoch: 0510 val_loss: 1.010957 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 34.0155s
INFO:root:Val set results: val_loss: 1.416716 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Test set results: test_loss: 1.434651 test_acc: 0.613636 test_f1: 0.613636
