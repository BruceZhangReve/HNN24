INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f172d4836d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 57989
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.444424 train_acc: 0.581967 train_f1: 0.581967 time: 0.0513s
INFO:root:Epoch: 0010 val_loss: 1.385845 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.299742 train_acc: 0.581967 train_f1: 0.581967 time: 0.0541s
INFO:root:Epoch: 0020 val_loss: 1.209204 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.206093 train_acc: 0.581967 train_f1: 0.581967 time: 0.0483s
INFO:root:Epoch: 0030 val_loss: 1.087506 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.157509 train_acc: 0.581967 train_f1: 0.581967 time: 0.0479s
INFO:root:Epoch: 0040 val_loss: 1.030325 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.121395 train_acc: 0.581967 train_f1: 0.581967 time: 0.0540s
INFO:root:Epoch: 0050 val_loss: 1.005636 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.071763 train_acc: 0.581967 train_f1: 0.581967 time: 0.0478s
INFO:root:Epoch: 0060 val_loss: 0.975616 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.032214 train_acc: 0.581967 train_f1: 0.581967 time: 0.0486s
INFO:root:Epoch: 0070 val_loss: 0.931660 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.979896 train_acc: 0.581967 train_f1: 0.581967 time: 0.0507s
INFO:root:Epoch: 0080 val_loss: 0.891187 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.927922 train_acc: 0.581967 train_f1: 0.581967 time: 0.0480s
INFO:root:Epoch: 0090 val_loss: 0.839640 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 0.878392 train_acc: 0.774590 train_f1: 0.774590 time: 0.0480s
INFO:root:Epoch: 0100 val_loss: 0.800993 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 0.848452 train_acc: 0.786885 train_f1: 0.786885 time: 0.0487s
INFO:root:Epoch: 0110 val_loss: 0.777556 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 0.838220 train_acc: 0.786885 train_f1: 0.786885 time: 0.0504s
INFO:root:Epoch: 0120 val_loss: 0.765146 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 0.821578 train_acc: 0.786885 train_f1: 0.786885 time: 0.0493s
INFO:root:Epoch: 0130 val_loss: 0.747147 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 0.799173 train_acc: 0.786885 train_f1: 0.786885 time: 0.0483s
INFO:root:Epoch: 0140 val_loss: 0.734718 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.779746 train_acc: 0.786885 train_f1: 0.786885 time: 0.0485s
INFO:root:Epoch: 0150 val_loss: 0.721869 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.767327 train_acc: 0.786885 train_f1: 0.786885 time: 0.0523s
INFO:root:Epoch: 0160 val_loss: 0.707173 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.761096 train_acc: 0.786885 train_f1: 0.786885 time: 0.0482s
INFO:root:Epoch: 0170 val_loss: 0.698986 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.757536 train_acc: 0.786885 train_f1: 0.786885 time: 0.0483s
INFO:root:Epoch: 0180 val_loss: 0.681504 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.740641 train_acc: 0.786885 train_f1: 0.786885 time: 0.0481s
INFO:root:Epoch: 0190 val_loss: 0.673084 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 0.726121 train_acc: 0.786885 train_f1: 0.786885 time: 0.0483s
INFO:root:Epoch: 0200 val_loss: 0.664278 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 0.723927 train_acc: 0.786885 train_f1: 0.786885 time: 0.0480s
INFO:root:Epoch: 0210 val_loss: 0.665915 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 0.716237 train_acc: 0.786885 train_f1: 0.786885 time: 0.0525s
INFO:root:Epoch: 0220 val_loss: 0.660138 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 0.722590 train_acc: 0.786885 train_f1: 0.786885 time: 0.0477s
INFO:root:Epoch: 0230 val_loss: 0.650495 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 0.718654 train_acc: 0.786885 train_f1: 0.786885 time: 0.0485s
INFO:root:Epoch: 0240 val_loss: 0.651987 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 0.710246 train_acc: 0.786885 train_f1: 0.786885 time: 0.0484s
INFO:root:Epoch: 0250 val_loss: 0.647509 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 0.709902 train_acc: 0.786885 train_f1: 0.786885 time: 0.0479s
INFO:root:Epoch: 0260 val_loss: 0.644341 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 0.702130 train_acc: 0.786885 train_f1: 0.786885 time: 0.0482s
INFO:root:Epoch: 0270 val_loss: 0.642729 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 0.701672 train_acc: 0.786885 train_f1: 0.786885 time: 0.0481s
INFO:root:Epoch: 0280 val_loss: 0.635147 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 0.689727 train_acc: 0.786885 train_f1: 0.786885 time: 0.0638s
INFO:root:Epoch: 0290 val_loss: 0.632899 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 0.704621 train_acc: 0.786885 train_f1: 0.786885 time: 0.0495s
INFO:root:Epoch: 0300 val_loss: 0.627053 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 0.691701 train_acc: 0.786885 train_f1: 0.786885 time: 0.0478s
INFO:root:Epoch: 0310 val_loss: 0.627774 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 0.688331 train_acc: 0.786885 train_f1: 0.786885 time: 0.0491s
INFO:root:Epoch: 0320 val_loss: 0.629281 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 0.692229 train_acc: 0.786885 train_f1: 0.786885 time: 0.0485s
INFO:root:Epoch: 0330 val_loss: 0.627704 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 0.691997 train_acc: 0.786885 train_f1: 0.786885 time: 0.0480s
INFO:root:Epoch: 0340 val_loss: 0.621035 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 0.678441 train_acc: 0.786885 train_f1: 0.786885 time: 0.0481s
INFO:root:Epoch: 0350 val_loss: 0.621780 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 0.680518 train_acc: 0.786885 train_f1: 0.786885 time: 0.0477s
INFO:root:Epoch: 0360 val_loss: 0.623053 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 0.681318 train_acc: 0.786885 train_f1: 0.786885 time: 0.0481s
INFO:root:Epoch: 0370 val_loss: 0.618178 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 0.681971 train_acc: 0.786885 train_f1: 0.786885 time: 0.0483s
INFO:root:Epoch: 0380 val_loss: 0.616616 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 0.677416 train_acc: 0.786885 train_f1: 0.786885 time: 0.0480s
INFO:root:Epoch: 0390 val_loss: 0.619411 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 0.676351 train_acc: 0.786885 train_f1: 0.786885 time: 0.0489s
INFO:root:Epoch: 0400 val_loss: 0.615366 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 0.672835 train_acc: 0.786885 train_f1: 0.786885 time: 0.0481s
INFO:root:Epoch: 0410 val_loss: 0.614474 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 0.678762 train_acc: 0.786885 train_f1: 0.786885 time: 0.0487s
INFO:root:Epoch: 0420 val_loss: 0.612280 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 0.679391 train_acc: 0.786885 train_f1: 0.786885 time: 0.0478s
INFO:root:Epoch: 0430 val_loss: 0.613709 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 0.674019 train_acc: 0.786885 train_f1: 0.786885 time: 0.0533s
INFO:root:Epoch: 0440 val_loss: 0.613944 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 0.676546 train_acc: 0.786885 train_f1: 0.786885 time: 0.0482s
INFO:root:Epoch: 0450 val_loss: 0.608879 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 0.680054 train_acc: 0.786885 train_f1: 0.786885 time: 0.0480s
INFO:root:Epoch: 0460 val_loss: 0.613736 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 0.672915 train_acc: 0.786885 train_f1: 0.786885 time: 0.0480s
INFO:root:Epoch: 0470 val_loss: 0.607958 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 0.682621 train_acc: 0.786885 train_f1: 0.786885 time: 0.0481s
INFO:root:Epoch: 0480 val_loss: 0.610828 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 0.674917 train_acc: 0.786885 train_f1: 0.786885 time: 0.0512s
INFO:root:Epoch: 0490 val_loss: 0.611544 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 0.671507 train_acc: 0.786885 train_f1: 0.786885 time: 0.0482s
INFO:root:Epoch: 0500 val_loss: 0.604718 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 0.665439 train_acc: 0.786885 train_f1: 0.786885 time: 0.0481s
INFO:root:Epoch: 0510 val_loss: 0.608036 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 0.664189 train_acc: 0.786885 train_f1: 0.786885 time: 0.0509s
INFO:root:Epoch: 0520 val_loss: 0.606000 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 0.674063 train_acc: 0.786885 train_f1: 0.786885 time: 0.0480s
INFO:root:Epoch: 0530 val_loss: 0.606907 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 0.671175 train_acc: 0.786885 train_f1: 0.786885 time: 0.0484s
INFO:root:Epoch: 0540 val_loss: 0.605752 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 0.671170 train_acc: 0.786885 train_f1: 0.786885 time: 0.0479s
INFO:root:Epoch: 0550 val_loss: 0.604812 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 0.663395 train_acc: 0.786885 train_f1: 0.786885 time: 0.0480s
INFO:root:Epoch: 0560 val_loss: 0.604454 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 0.666219 train_acc: 0.786885 train_f1: 0.786885 time: 0.0479s
INFO:root:Epoch: 0570 val_loss: 0.605990 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 0.668475 train_acc: 0.786885 train_f1: 0.786885 time: 0.0570s
INFO:root:Epoch: 0580 val_loss: 0.604180 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 0.669397 train_acc: 0.786885 train_f1: 0.786885 time: 0.0535s
INFO:root:Epoch: 0590 val_loss: 0.606237 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.675640 train_acc: 0.786885 train_f1: 0.786885 time: 0.0537s
INFO:root:Epoch: 0600 val_loss: 0.602589 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 32.2402s
INFO:root:Val set results: val_loss: 0.800993 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Test set results: test_loss: 0.859267 test_acc: 0.750000 test_f1: 0.750000
