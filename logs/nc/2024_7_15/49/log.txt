INFO:root:Using: cuda:7
INFO:root:Using seed 28.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 57996.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.634544 train_acc: 0.651639 train_f1: 0.651639 time: 0.0277s
INFO:root:Epoch: 0010 val_loss: 1.509353 val_acc: 0.636364 val_f1: 0.636364
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.430753 train_acc: 0.684426 train_f1: 0.684426 time: 0.0311s
INFO:root:Epoch: 0020 val_loss: 1.319432 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.287724 train_acc: 0.836066 train_f1: 0.836066 time: 0.0273s
INFO:root:Epoch: 0030 val_loss: 1.174435 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.204126 train_acc: 0.852459 train_f1: 0.852459 time: 0.0264s
INFO:root:Epoch: 0040 val_loss: 1.153290 val_acc: 0.772727 val_f1: 0.772727
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.138225 train_acc: 0.889344 train_f1: 0.889344 time: 0.0250s
INFO:root:Epoch: 0050 val_loss: 1.064991 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.126862 train_acc: 0.901639 train_f1: 0.901639 time: 0.0341s
INFO:root:Epoch: 0060 val_loss: 1.095943 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.106297 train_acc: 0.913934 train_f1: 0.913934 time: 0.0337s
INFO:root:Epoch: 0070 val_loss: 1.047874 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.100138 train_acc: 0.909836 train_f1: 0.909836 time: 0.0293s
INFO:root:Epoch: 0080 val_loss: 1.066269 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.083447 train_acc: 0.922131 train_f1: 0.922131 time: 0.0297s
INFO:root:Epoch: 0090 val_loss: 1.050161 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.066505 train_acc: 0.926230 train_f1: 0.926230 time: 0.0276s
INFO:root:Epoch: 0100 val_loss: 1.066013 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.064115 train_acc: 0.934426 train_f1: 0.934426 time: 0.0279s
INFO:root:Epoch: 0110 val_loss: 1.042801 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.058179 train_acc: 0.934426 train_f1: 0.934426 time: 0.0317s
INFO:root:Epoch: 0120 val_loss: 1.041662 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.054860 train_acc: 0.930328 train_f1: 0.930328 time: 0.0310s
INFO:root:Epoch: 0130 val_loss: 1.058916 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.052708 train_acc: 0.930328 train_f1: 0.930328 time: 0.0306s
INFO:root:Epoch: 0140 val_loss: 1.071398 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.048776 train_acc: 0.926230 train_f1: 0.926230 time: 0.0305s
INFO:root:Epoch: 0150 val_loss: 1.054570 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.041625 train_acc: 0.934426 train_f1: 0.934426 time: 0.0301s
INFO:root:Epoch: 0160 val_loss: 1.037896 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.037628 train_acc: 0.934426 train_f1: 0.934426 time: 0.0301s
INFO:root:Epoch: 0170 val_loss: 1.034846 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.034719 train_acc: 0.934426 train_f1: 0.934426 time: 0.0307s
INFO:root:Epoch: 0180 val_loss: 1.037526 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.037059 train_acc: 0.934426 train_f1: 0.934426 time: 0.0298s
INFO:root:Epoch: 0190 val_loss: 1.043079 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 1.030086 train_acc: 0.934426 train_f1: 0.934426 time: 0.0321s
INFO:root:Epoch: 0200 val_loss: 1.052299 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 1.028311 train_acc: 0.934426 train_f1: 0.934426 time: 0.0254s
INFO:root:Epoch: 0210 val_loss: 1.051515 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 1.023822 train_acc: 0.934426 train_f1: 0.934426 time: 0.0306s
INFO:root:Epoch: 0220 val_loss: 1.052858 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 1.025529 train_acc: 0.934426 train_f1: 0.934426 time: 0.0328s
INFO:root:Epoch: 0230 val_loss: 1.045185 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 1.024913 train_acc: 0.934426 train_f1: 0.934426 time: 0.0311s
INFO:root:Epoch: 0240 val_loss: 1.036577 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 1.022171 train_acc: 0.934426 train_f1: 0.934426 time: 0.0269s
INFO:root:Epoch: 0250 val_loss: 1.038100 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 1.019510 train_acc: 0.934426 train_f1: 0.934426 time: 0.0297s
INFO:root:Epoch: 0260 val_loss: 1.049823 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 1.022321 train_acc: 0.934426 train_f1: 0.934426 time: 0.0299s
INFO:root:Epoch: 0270 val_loss: 1.062058 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 1.016771 train_acc: 0.934426 train_f1: 0.934426 time: 0.0299s
INFO:root:Epoch: 0280 val_loss: 1.052603 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 1.017545 train_acc: 0.934426 train_f1: 0.934426 time: 0.0373s
INFO:root:Epoch: 0290 val_loss: 1.054596 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 1.012628 train_acc: 0.934426 train_f1: 0.934426 time: 0.0319s
INFO:root:Epoch: 0300 val_loss: 1.055010 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 1.014112 train_acc: 0.930328 train_f1: 0.930328 time: 0.0313s
INFO:root:Epoch: 0310 val_loss: 1.043578 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 1.012699 train_acc: 0.934426 train_f1: 0.934426 time: 0.0307s
INFO:root:Epoch: 0320 val_loss: 1.033535 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 1.008741 train_acc: 0.934426 train_f1: 0.934426 time: 0.0310s
INFO:root:Epoch: 0330 val_loss: 1.025779 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 1.009152 train_acc: 0.934426 train_f1: 0.934426 time: 0.0333s
INFO:root:Epoch: 0340 val_loss: 1.023016 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 1.007633 train_acc: 0.934426 train_f1: 0.934426 time: 0.0315s
INFO:root:Epoch: 0350 val_loss: 1.027834 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 1.008417 train_acc: 0.934426 train_f1: 0.934426 time: 0.0308s
INFO:root:Epoch: 0360 val_loss: 1.035447 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 1.007172 train_acc: 0.934426 train_f1: 0.934426 time: 0.0296s
INFO:root:Epoch: 0370 val_loss: 1.040477 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 1.005949 train_acc: 0.934426 train_f1: 0.934426 time: 0.0286s
INFO:root:Epoch: 0380 val_loss: 1.038685 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 1.006336 train_acc: 0.934426 train_f1: 0.934426 time: 0.0295s
INFO:root:Epoch: 0390 val_loss: 1.029619 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 1.005371 train_acc: 0.934426 train_f1: 0.934426 time: 0.0317s
INFO:root:Epoch: 0400 val_loss: 1.026438 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 1.003111 train_acc: 0.934426 train_f1: 0.934426 time: 0.0296s
INFO:root:Epoch: 0410 val_loss: 1.024770 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 1.003281 train_acc: 0.934426 train_f1: 0.934426 time: 0.0298s
INFO:root:Epoch: 0420 val_loss: 1.024975 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 1.003622 train_acc: 0.934426 train_f1: 0.934426 time: 0.0315s
INFO:root:Epoch: 0430 val_loss: 1.025934 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 1.002414 train_acc: 0.934426 train_f1: 0.934426 time: 0.0304s
INFO:root:Epoch: 0440 val_loss: 1.031237 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 1.002143 train_acc: 0.934426 train_f1: 0.934426 time: 0.0307s
INFO:root:Epoch: 0450 val_loss: 1.036507 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 1.004112 train_acc: 0.934426 train_f1: 0.934426 time: 0.0291s
INFO:root:Epoch: 0460 val_loss: 1.038126 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 1.004420 train_acc: 0.934426 train_f1: 0.934426 time: 0.0352s
INFO:root:Epoch: 0470 val_loss: 1.036496 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 1.005207 train_acc: 0.930328 train_f1: 0.930328 time: 0.0292s
INFO:root:Epoch: 0480 val_loss: 1.035136 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 1.001910 train_acc: 0.934426 train_f1: 0.934426 time: 0.0309s
INFO:root:Epoch: 0490 val_loss: 1.033222 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 1.003483 train_acc: 0.930328 train_f1: 0.930328 time: 0.0300s
INFO:root:Epoch: 0500 val_loss: 1.033076 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 1.001695 train_acc: 0.934426 train_f1: 0.934426 time: 0.0300s
INFO:root:Epoch: 0510 val_loss: 1.033268 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 1.002074 train_acc: 0.934426 train_f1: 0.934426 time: 0.0294s
INFO:root:Epoch: 0520 val_loss: 1.033468 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 1.000546 train_acc: 0.934426 train_f1: 0.934426 time: 0.0320s
INFO:root:Epoch: 0530 val_loss: 1.032985 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 1.000007 train_acc: 0.934426 train_f1: 0.934426 time: 0.0295s
INFO:root:Epoch: 0540 val_loss: 1.033617 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 0.998868 train_acc: 0.934426 train_f1: 0.934426 time: 0.0302s
INFO:root:Epoch: 0550 val_loss: 1.034466 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 1.004243 train_acc: 0.926230 train_f1: 0.926230 time: 0.0299s
INFO:root:Epoch: 0560 val_loss: 1.037390 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 0.998817 train_acc: 0.934426 train_f1: 0.934426 time: 0.0309s
INFO:root:Epoch: 0570 val_loss: 1.039149 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 1.000336 train_acc: 0.934426 train_f1: 0.934426 time: 0.0298s
INFO:root:Epoch: 0580 val_loss: 1.040112 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 1.001233 train_acc: 0.934426 train_f1: 0.934426 time: 0.0302s
INFO:root:Epoch: 0590 val_loss: 1.040930 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 20.5531s
INFO:root:Val set results: val_loss: 1.050161 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Test set results: test_loss: 1.179975 test_acc: 0.886364 test_f1: 0.886364
