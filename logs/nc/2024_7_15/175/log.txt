INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: wisconsin
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=32, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fe6e8c9b6d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=64, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=<function relu at 0x7fe6e8c9b6d0>)
            (linear2): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 68485
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.361743 train_acc: 0.576433 train_f1: 0.576433 time: 0.1153s
INFO:root:Epoch: 0010 val_loss: 1.407552 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.252867 train_acc: 0.576433 train_f1: 0.576433 time: 0.1146s
INFO:root:Epoch: 0020 val_loss: 1.351355 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.223248 train_acc: 0.576433 train_f1: 0.576433 time: 0.1391s
INFO:root:Epoch: 0030 val_loss: 1.335394 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.195590 train_acc: 0.576433 train_f1: 0.576433 time: 0.1381s
INFO:root:Epoch: 0040 val_loss: 1.315361 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.179271 train_acc: 0.576433 train_f1: 0.576433 time: 0.1392s
INFO:root:Epoch: 0050 val_loss: 1.289771 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.129470 train_acc: 0.576433 train_f1: 0.576433 time: 0.1384s
INFO:root:Epoch: 0060 val_loss: 1.236574 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.068314 train_acc: 0.576433 train_f1: 0.576433 time: 0.1360s
INFO:root:Epoch: 0070 val_loss: 1.150142 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.938255 train_acc: 0.576433 train_f1: 0.576433 time: 0.1214s
INFO:root:Epoch: 0080 val_loss: 1.058081 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.904198 train_acc: 0.576433 train_f1: 0.576433 time: 0.1243s
INFO:root:Epoch: 0090 val_loss: 0.977500 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 0.823256 train_acc: 0.576433 train_f1: 0.576433 time: 0.1203s
INFO:root:Epoch: 0100 val_loss: 0.913381 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 0.815933 train_acc: 0.576433 train_f1: 0.576433 time: 0.1242s
INFO:root:Epoch: 0110 val_loss: 0.882703 val_acc: 0.629630 val_f1: 0.629630
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 0.813584 train_acc: 0.576433 train_f1: 0.576433 time: 0.1209s
INFO:root:Epoch: 0120 val_loss: 0.851846 val_acc: 0.740741 val_f1: 0.740741
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 0.754317 train_acc: 0.729299 train_f1: 0.729299 time: 0.1272s
INFO:root:Epoch: 0130 val_loss: 0.826853 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 0.723840 train_acc: 0.878981 train_f1: 0.878981 time: 0.1330s
INFO:root:Epoch: 0140 val_loss: 0.804052 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.717469 train_acc: 0.824841 train_f1: 0.824841 time: 0.1294s
INFO:root:Epoch: 0150 val_loss: 0.786670 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.713915 train_acc: 0.878981 train_f1: 0.878981 time: 0.1229s
INFO:root:Epoch: 0160 val_loss: 0.770375 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.694011 train_acc: 0.872611 train_f1: 0.872611 time: 0.1209s
INFO:root:Epoch: 0170 val_loss: 0.764157 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.702226 train_acc: 0.754777 train_f1: 0.754777 time: 0.1244s
INFO:root:Epoch: 0180 val_loss: 0.745700 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.664325 train_acc: 0.767516 train_f1: 0.767516 time: 0.1206s
INFO:root:Epoch: 0190 val_loss: 0.732504 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 0.668847 train_acc: 0.745223 train_f1: 0.745223 time: 0.1202s
INFO:root:Epoch: 0200 val_loss: 0.721046 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 0.671812 train_acc: 0.732484 train_f1: 0.732484 time: 0.1205s
INFO:root:Epoch: 0210 val_loss: 0.724029 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 0.684272 train_acc: 0.773885 train_f1: 0.773885 time: 0.1210s
INFO:root:Epoch: 0220 val_loss: 0.725553 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 0.650101 train_acc: 0.882166 train_f1: 0.882166 time: 0.1239s
INFO:root:Epoch: 0230 val_loss: 0.712787 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 0.628523 train_acc: 0.882166 train_f1: 0.882166 time: 0.1331s
INFO:root:Epoch: 0240 val_loss: 0.707036 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 0.669823 train_acc: 0.882166 train_f1: 0.882166 time: 0.1296s
INFO:root:Epoch: 0250 val_loss: 0.705346 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 0.666014 train_acc: 0.732484 train_f1: 0.732484 time: 0.1243s
INFO:root:Epoch: 0260 val_loss: 0.702791 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 0.640228 train_acc: 0.882166 train_f1: 0.882166 time: 0.1212s
INFO:root:Epoch: 0270 val_loss: 0.696840 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 0.619617 train_acc: 0.882166 train_f1: 0.882166 time: 0.1265s
INFO:root:Epoch: 0280 val_loss: 0.694695 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 0.632317 train_acc: 0.875796 train_f1: 0.875796 time: 0.1209s
INFO:root:Epoch: 0290 val_loss: 0.693059 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 0.604199 train_acc: 0.885350 train_f1: 0.885350 time: 0.1218s
INFO:root:Epoch: 0300 val_loss: 0.691915 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 0.653880 train_acc: 0.878981 train_f1: 0.878981 time: 0.1204s
INFO:root:Epoch: 0310 val_loss: 0.690682 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 0.617492 train_acc: 0.872611 train_f1: 0.872611 time: 0.1212s
INFO:root:Epoch: 0320 val_loss: 0.688471 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 0.619483 train_acc: 0.732484 train_f1: 0.732484 time: 0.1206s
INFO:root:Epoch: 0330 val_loss: 0.689071 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 0.620549 train_acc: 0.882166 train_f1: 0.882166 time: 0.1301s
INFO:root:Epoch: 0340 val_loss: 0.690053 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 0.624040 train_acc: 0.732484 train_f1: 0.732484 time: 0.1346s
INFO:root:Epoch: 0350 val_loss: 0.689785 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 0.610976 train_acc: 0.875796 train_f1: 0.875796 time: 0.1296s
INFO:root:Epoch: 0360 val_loss: 0.686343 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 0.614900 train_acc: 0.882166 train_f1: 0.882166 time: 0.1210s
INFO:root:Epoch: 0370 val_loss: 0.682556 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 0.630000 train_acc: 0.882166 train_f1: 0.882166 time: 0.1238s
INFO:root:Epoch: 0380 val_loss: 0.682276 val_acc: 0.759259 val_f1: 0.759259
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 0.632881 train_acc: 0.837580 train_f1: 0.837580 time: 0.1206s
INFO:root:Epoch: 0390 val_loss: 0.685946 val_acc: 0.703704 val_f1: 0.703704
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 0.619868 train_acc: 0.732484 train_f1: 0.732484 time: 0.1234s
INFO:root:Epoch: 0400 val_loss: 0.683033 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 0.606391 train_acc: 0.882166 train_f1: 0.882166 time: 0.1212s
INFO:root:Epoch: 0410 val_loss: 0.682897 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 0.614917 train_acc: 0.882166 train_f1: 0.882166 time: 0.1210s
INFO:root:Epoch: 0420 val_loss: 0.682877 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 0.597102 train_acc: 0.882166 train_f1: 0.882166 time: 0.1208s
INFO:root:Epoch: 0430 val_loss: 0.681914 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 0.606141 train_acc: 0.792994 train_f1: 0.792994 time: 0.1264s
INFO:root:Epoch: 0440 val_loss: 0.679629 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 0.604434 train_acc: 0.828025 train_f1: 0.828025 time: 0.1257s
INFO:root:Epoch: 0450 val_loss: 0.679049 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 0.616528 train_acc: 0.885350 train_f1: 0.885350 time: 0.1261s
INFO:root:Epoch: 0460 val_loss: 0.680043 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 0.592127 train_acc: 0.882166 train_f1: 0.882166 time: 0.1266s
INFO:root:Epoch: 0470 val_loss: 0.680247 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 0.610919 train_acc: 0.882166 train_f1: 0.882166 time: 0.1266s
INFO:root:Epoch: 0480 val_loss: 0.680267 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 0.614932 train_acc: 0.732484 train_f1: 0.732484 time: 0.1220s
INFO:root:Epoch: 0490 val_loss: 0.678427 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 0.624551 train_acc: 0.751592 train_f1: 0.751592 time: 0.1232s
INFO:root:Epoch: 0500 val_loss: 0.681913 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 0.618525 train_acc: 0.878981 train_f1: 0.878981 time: 0.1216s
INFO:root:Epoch: 0510 val_loss: 0.682181 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 0.605368 train_acc: 0.732484 train_f1: 0.732484 time: 0.1229s
INFO:root:Epoch: 0520 val_loss: 0.681368 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 0.602193 train_acc: 0.885350 train_f1: 0.885350 time: 0.1212s
INFO:root:Epoch: 0530 val_loss: 0.680264 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 0.605978 train_acc: 0.732484 train_f1: 0.732484 time: 0.1219s
INFO:root:Epoch: 0540 val_loss: 0.679895 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 0.615259 train_acc: 0.882166 train_f1: 0.882166 time: 0.1248s
INFO:root:Epoch: 0550 val_loss: 0.679551 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 0.620873 train_acc: 0.882166 train_f1: 0.882166 time: 0.1249s
INFO:root:Epoch: 0560 val_loss: 0.679152 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 0.612614 train_acc: 0.789809 train_f1: 0.789809 time: 0.1331s
INFO:root:Epoch: 0570 val_loss: 0.677940 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 0.609310 train_acc: 0.866242 train_f1: 0.866242 time: 0.1244s
INFO:root:Epoch: 0580 val_loss: 0.676938 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 0.613210 train_acc: 0.882166 train_f1: 0.882166 time: 0.1233s
INFO:root:Epoch: 0590 val_loss: 0.676298 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.613138 train_acc: 0.757962 train_f1: 0.757962 time: 0.1208s
INFO:root:Epoch: 0600 val_loss: 0.676150 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0610 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.603737 train_acc: 0.745223 train_f1: 0.745223 time: 0.1217s
INFO:root:Epoch: 0610 val_loss: 0.676059 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0620 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.635424 train_acc: 0.732484 train_f1: 0.732484 time: 0.1215s
INFO:root:Epoch: 0620 val_loss: 0.675883 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0630 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.615022 train_acc: 0.882166 train_f1: 0.882166 time: 0.1241s
INFO:root:Epoch: 0630 val_loss: 0.676015 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0640 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.602007 train_acc: 0.853503 train_f1: 0.853503 time: 0.1206s
INFO:root:Epoch: 0640 val_loss: 0.676027 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0650 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.631425 train_acc: 0.847134 train_f1: 0.847134 time: 0.1215s
INFO:root:Epoch: 0650 val_loss: 0.675939 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0660 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.617312 train_acc: 0.882166 train_f1: 0.882166 time: 0.1261s
INFO:root:Epoch: 0660 val_loss: 0.675710 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0670 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.595710 train_acc: 0.882166 train_f1: 0.882166 time: 0.1252s
INFO:root:Epoch: 0670 val_loss: 0.675195 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0680 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.622483 train_acc: 0.882166 train_f1: 0.882166 time: 0.1267s
INFO:root:Epoch: 0680 val_loss: 0.674615 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0690 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.596830 train_acc: 0.885350 train_f1: 0.885350 time: 0.1230s
INFO:root:Epoch: 0690 val_loss: 0.674596 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0700 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.610452 train_acc: 0.834395 train_f1: 0.834395 time: 0.1212s
INFO:root:Epoch: 0700 val_loss: 0.674667 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 90.9645s
INFO:root:Val set results: val_loss: 0.721046 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Test set results: test_loss: 0.775485 test_acc: 0.814815 test_f1: 0.814815
