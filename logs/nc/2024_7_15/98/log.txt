INFO:root:Using: cuda:7
INFO:root:Using seed 1.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (3): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 59085.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.340566 train_acc: 0.606557 train_f1: 0.606557 time: 0.0297s
INFO:root:Epoch: 0010 val_loss: 1.219729 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.210565 train_acc: 0.606557 train_f1: 0.606557 time: 0.0292s
INFO:root:Epoch: 0020 val_loss: 1.063329 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.076990 train_acc: 0.688525 train_f1: 0.688525 time: 0.0305s
INFO:root:Epoch: 0030 val_loss: 0.966212 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 0.957304 train_acc: 0.737705 train_f1: 0.737705 time: 0.0328s
INFO:root:Epoch: 0040 val_loss: 0.905298 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 0.893072 train_acc: 0.758197 train_f1: 0.758197 time: 0.0311s
INFO:root:Epoch: 0050 val_loss: 0.873138 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 0.866132 train_acc: 0.754098 train_f1: 0.754098 time: 0.0320s
INFO:root:Epoch: 0060 val_loss: 0.848689 val_acc: 0.704545 val_f1: 0.704545
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.833341 train_acc: 0.770492 train_f1: 0.770492 time: 0.0330s
INFO:root:Epoch: 0070 val_loss: 0.834072 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.791608 train_acc: 0.799180 train_f1: 0.799180 time: 0.0338s
INFO:root:Epoch: 0080 val_loss: 0.810432 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.773484 train_acc: 0.803279 train_f1: 0.803279 time: 0.0333s
INFO:root:Epoch: 0090 val_loss: 0.797765 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 0.759183 train_acc: 0.807377 train_f1: 0.807377 time: 0.0349s
INFO:root:Epoch: 0100 val_loss: 0.800221 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 0.755200 train_acc: 0.807377 train_f1: 0.807377 time: 0.0365s
INFO:root:Epoch: 0110 val_loss: 0.795368 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 0.753186 train_acc: 0.807377 train_f1: 0.807377 time: 0.0316s
INFO:root:Epoch: 0120 val_loss: 0.786702 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 0.753064 train_acc: 0.803279 train_f1: 0.803279 time: 0.0328s
INFO:root:Epoch: 0130 val_loss: 0.800849 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 0.739950 train_acc: 0.807377 train_f1: 0.807377 time: 0.0320s
INFO:root:Epoch: 0140 val_loss: 0.819080 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.733655 train_acc: 0.807377 train_f1: 0.807377 time: 0.0329s
INFO:root:Epoch: 0150 val_loss: 0.798928 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.735655 train_acc: 0.807377 train_f1: 0.807377 time: 0.0348s
INFO:root:Epoch: 0160 val_loss: 0.782748 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.735309 train_acc: 0.807377 train_f1: 0.807377 time: 0.0313s
INFO:root:Epoch: 0170 val_loss: 0.791578 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.726878 train_acc: 0.807377 train_f1: 0.807377 time: 0.0322s
INFO:root:Epoch: 0180 val_loss: 0.818189 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.725994 train_acc: 0.807377 train_f1: 0.807377 time: 0.0337s
INFO:root:Epoch: 0190 val_loss: 0.799542 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 0.724558 train_acc: 0.807377 train_f1: 0.807377 time: 0.0412s
INFO:root:Epoch: 0200 val_loss: 0.793834 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 0.720499 train_acc: 0.807377 train_f1: 0.807377 time: 0.0320s
INFO:root:Epoch: 0210 val_loss: 0.793771 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 0.723816 train_acc: 0.807377 train_f1: 0.807377 time: 0.0314s
INFO:root:Epoch: 0220 val_loss: 0.798082 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 0.724392 train_acc: 0.807377 train_f1: 0.807377 time: 0.0334s
INFO:root:Epoch: 0230 val_loss: 0.784987 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 0.721516 train_acc: 0.807377 train_f1: 0.807377 time: 0.0346s
INFO:root:Epoch: 0240 val_loss: 0.766165 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 0.722947 train_acc: 0.803279 train_f1: 0.803279 time: 0.0353s
INFO:root:Epoch: 0250 val_loss: 0.762751 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 0.718807 train_acc: 0.807377 train_f1: 0.807377 time: 0.0325s
INFO:root:Epoch: 0260 val_loss: 0.765985 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 0.713728 train_acc: 0.807377 train_f1: 0.807377 time: 0.0319s
INFO:root:Epoch: 0270 val_loss: 0.771042 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 0.713138 train_acc: 0.807377 train_f1: 0.807377 time: 0.0372s
INFO:root:Epoch: 0280 val_loss: 0.774274 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 0.720308 train_acc: 0.799180 train_f1: 0.799180 time: 0.0379s
INFO:root:Epoch: 0290 val_loss: 0.774307 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 0.714553 train_acc: 0.807377 train_f1: 0.807377 time: 0.0386s
INFO:root:Epoch: 0300 val_loss: 0.771658 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 0.713777 train_acc: 0.807377 train_f1: 0.807377 time: 0.0356s
INFO:root:Epoch: 0310 val_loss: 0.772397 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 0.711550 train_acc: 0.807377 train_f1: 0.807377 time: 0.0373s
INFO:root:Epoch: 0320 val_loss: 0.774390 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 0.724841 train_acc: 0.799180 train_f1: 0.799180 time: 0.0348s
INFO:root:Epoch: 0330 val_loss: 0.774964 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 0.709698 train_acc: 0.807377 train_f1: 0.807377 time: 0.0339s
INFO:root:Epoch: 0340 val_loss: 0.779579 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 0.711101 train_acc: 0.807377 train_f1: 0.807377 time: 0.0341s
INFO:root:Epoch: 0350 val_loss: 0.779965 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 0.712265 train_acc: 0.807377 train_f1: 0.807377 time: 0.0376s
INFO:root:Epoch: 0360 val_loss: 0.776452 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 0.710645 train_acc: 0.807377 train_f1: 0.807377 time: 0.0325s
INFO:root:Epoch: 0370 val_loss: 0.773336 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 0.708120 train_acc: 0.807377 train_f1: 0.807377 time: 0.0336s
INFO:root:Epoch: 0380 val_loss: 0.769788 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 0.708373 train_acc: 0.807377 train_f1: 0.807377 time: 0.0332s
INFO:root:Epoch: 0390 val_loss: 0.765092 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 0.708513 train_acc: 0.807377 train_f1: 0.807377 time: 0.0324s
INFO:root:Epoch: 0400 val_loss: 0.760087 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 0.708608 train_acc: 0.807377 train_f1: 0.807377 time: 0.0340s
INFO:root:Epoch: 0410 val_loss: 0.759972 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 0.732242 train_acc: 0.803279 train_f1: 0.803279 time: 0.0299s
INFO:root:Epoch: 0420 val_loss: 0.760242 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 0.728949 train_acc: 0.803279 train_f1: 0.803279 time: 0.0336s
INFO:root:Epoch: 0430 val_loss: 0.761647 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 0.715345 train_acc: 0.807377 train_f1: 0.807377 time: 0.0339s
INFO:root:Epoch: 0440 val_loss: 0.763911 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 0.706506 train_acc: 0.807377 train_f1: 0.807377 time: 0.0315s
INFO:root:Epoch: 0450 val_loss: 0.766632 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 0.707624 train_acc: 0.807377 train_f1: 0.807377 time: 0.0330s
INFO:root:Epoch: 0460 val_loss: 0.766818 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 0.705952 train_acc: 0.807377 train_f1: 0.807377 time: 0.0338s
INFO:root:Epoch: 0470 val_loss: 0.767141 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 0.707502 train_acc: 0.807377 train_f1: 0.807377 time: 0.0332s
INFO:root:Epoch: 0480 val_loss: 0.765292 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 0.706711 train_acc: 0.807377 train_f1: 0.807377 time: 0.0351s
INFO:root:Epoch: 0490 val_loss: 0.763439 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 0.708445 train_acc: 0.807377 train_f1: 0.807377 time: 0.0366s
INFO:root:Epoch: 0500 val_loss: 0.763138 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 0.704583 train_acc: 0.807377 train_f1: 0.807377 time: 0.0333s
INFO:root:Epoch: 0510 val_loss: 0.763492 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 0.707793 train_acc: 0.807377 train_f1: 0.807377 time: 0.0300s
INFO:root:Epoch: 0520 val_loss: 0.763343 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 0.705893 train_acc: 0.807377 train_f1: 0.807377 time: 0.0312s
INFO:root:Epoch: 0530 val_loss: 0.762623 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 0.714827 train_acc: 0.803279 train_f1: 0.803279 time: 0.0318s
INFO:root:Epoch: 0540 val_loss: 0.762096 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 20.5564s
INFO:root:Val set results: val_loss: 0.905298 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Test set results: test_loss: 1.108701 test_acc: 0.704545 test_f1: 0.704545
