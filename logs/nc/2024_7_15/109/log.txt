INFO:root:Using: cuda:7
INFO:root:Using seed 1.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=32, out_features=32, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f82ece836d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 59077
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.439587 train_acc: 0.598361 train_f1: 0.598361 time: 0.0564s
INFO:root:Epoch: 0010 val_loss: 1.396110 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.290258 train_acc: 0.598361 train_f1: 0.598361 time: 0.0572s
INFO:root:Epoch: 0020 val_loss: 1.233350 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.194958 train_acc: 0.598361 train_f1: 0.598361 time: 0.0637s
INFO:root:Epoch: 0030 val_loss: 1.124646 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.152390 train_acc: 0.598361 train_f1: 0.598361 time: 0.0558s
INFO:root:Epoch: 0040 val_loss: 1.075510 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.131418 train_acc: 0.598361 train_f1: 0.598361 time: 0.0588s
INFO:root:Epoch: 0050 val_loss: 1.058290 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.092763 train_acc: 0.598361 train_f1: 0.598361 time: 0.0556s
INFO:root:Epoch: 0060 val_loss: 1.019490 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.050477 train_acc: 0.598361 train_f1: 0.598361 time: 0.0590s
INFO:root:Epoch: 0070 val_loss: 0.979650 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.991716 train_acc: 0.598361 train_f1: 0.598361 time: 0.0579s
INFO:root:Epoch: 0080 val_loss: 0.925014 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.936628 train_acc: 0.598361 train_f1: 0.598361 time: 0.0554s
INFO:root:Epoch: 0090 val_loss: 0.867474 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 0.892087 train_acc: 0.598361 train_f1: 0.598361 time: 0.0564s
INFO:root:Epoch: 0100 val_loss: 0.812973 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 0.859589 train_acc: 0.598361 train_f1: 0.598361 time: 0.0571s
INFO:root:Epoch: 0110 val_loss: 0.796806 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 0.837603 train_acc: 0.598361 train_f1: 0.598361 time: 0.0559s
INFO:root:Epoch: 0120 val_loss: 0.769638 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 0.822007 train_acc: 0.598361 train_f1: 0.598361 time: 0.0561s
INFO:root:Epoch: 0130 val_loss: 0.755429 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 0.814496 train_acc: 0.598361 train_f1: 0.598361 time: 0.0567s
INFO:root:Epoch: 0140 val_loss: 0.738065 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.792992 train_acc: 0.598361 train_f1: 0.598361 time: 0.0591s
INFO:root:Epoch: 0150 val_loss: 0.721921 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.775141 train_acc: 0.750000 train_f1: 0.750000 time: 0.0567s
INFO:root:Epoch: 0160 val_loss: 0.711486 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.756357 train_acc: 0.598361 train_f1: 0.598361 time: 0.0565s
INFO:root:Epoch: 0170 val_loss: 0.694901 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.753664 train_acc: 0.754098 train_f1: 0.754098 time: 0.0567s
INFO:root:Epoch: 0180 val_loss: 0.687642 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.740733 train_acc: 0.786885 train_f1: 0.786885 time: 0.0555s
INFO:root:Epoch: 0190 val_loss: 0.675459 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 0.724431 train_acc: 0.786885 train_f1: 0.786885 time: 0.0576s
INFO:root:Epoch: 0200 val_loss: 0.663697 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 0.729064 train_acc: 0.786885 train_f1: 0.786885 time: 0.0567s
INFO:root:Epoch: 0210 val_loss: 0.658289 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 0.720426 train_acc: 0.786885 train_f1: 0.786885 time: 0.0564s
INFO:root:Epoch: 0220 val_loss: 0.653923 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 0.713281 train_acc: 0.786885 train_f1: 0.786885 time: 0.0549s
INFO:root:Epoch: 0230 val_loss: 0.652076 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 0.704372 train_acc: 0.786885 train_f1: 0.786885 time: 0.0565s
INFO:root:Epoch: 0240 val_loss: 0.645182 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 0.705989 train_acc: 0.786885 train_f1: 0.786885 time: 0.0572s
INFO:root:Epoch: 0250 val_loss: 0.639605 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 0.707966 train_acc: 0.786885 train_f1: 0.786885 time: 0.0561s
INFO:root:Epoch: 0260 val_loss: 0.637975 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 0.695655 train_acc: 0.786885 train_f1: 0.786885 time: 0.0653s
INFO:root:Epoch: 0270 val_loss: 0.633042 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 0.693908 train_acc: 0.786885 train_f1: 0.786885 time: 0.0559s
INFO:root:Epoch: 0280 val_loss: 0.631080 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 0.688916 train_acc: 0.786885 train_f1: 0.786885 time: 0.0590s
INFO:root:Epoch: 0290 val_loss: 0.624258 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 0.683450 train_acc: 0.786885 train_f1: 0.786885 time: 0.0567s
INFO:root:Epoch: 0300 val_loss: 0.621947 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 0.675485 train_acc: 0.786885 train_f1: 0.786885 time: 0.0572s
INFO:root:Epoch: 0310 val_loss: 0.617935 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 0.680947 train_acc: 0.786885 train_f1: 0.786885 time: 0.0576s
INFO:root:Epoch: 0320 val_loss: 0.618196 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 0.679791 train_acc: 0.786885 train_f1: 0.786885 time: 0.0568s
INFO:root:Epoch: 0330 val_loss: 0.615945 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 0.675574 train_acc: 0.786885 train_f1: 0.786885 time: 0.0633s
INFO:root:Epoch: 0340 val_loss: 0.615642 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 0.667331 train_acc: 0.786885 train_f1: 0.786885 time: 0.0566s
INFO:root:Epoch: 0350 val_loss: 0.613737 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 0.677653 train_acc: 0.786885 train_f1: 0.786885 time: 0.0567s
INFO:root:Epoch: 0360 val_loss: 0.613284 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 0.672469 train_acc: 0.786885 train_f1: 0.786885 time: 0.0568s
INFO:root:Epoch: 0370 val_loss: 0.612725 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 0.666722 train_acc: 0.786885 train_f1: 0.786885 time: 0.0561s
INFO:root:Epoch: 0380 val_loss: 0.608422 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 0.672460 train_acc: 0.786885 train_f1: 0.786885 time: 0.0588s
INFO:root:Epoch: 0390 val_loss: 0.602924 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 0.665946 train_acc: 0.786885 train_f1: 0.786885 time: 0.0569s
INFO:root:Epoch: 0400 val_loss: 0.602014 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 0.664403 train_acc: 0.786885 train_f1: 0.786885 time: 0.0594s
INFO:root:Epoch: 0410 val_loss: 0.602849 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 0.663792 train_acc: 0.786885 train_f1: 0.786885 time: 0.0571s
INFO:root:Epoch: 0420 val_loss: 0.606879 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 0.668157 train_acc: 0.786885 train_f1: 0.786885 time: 0.0573s
INFO:root:Epoch: 0430 val_loss: 0.605736 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 0.664112 train_acc: 0.786885 train_f1: 0.786885 time: 0.0582s
INFO:root:Epoch: 0440 val_loss: 0.604881 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 0.670362 train_acc: 0.786885 train_f1: 0.786885 time: 0.0575s
INFO:root:Epoch: 0450 val_loss: 0.599168 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 0.660732 train_acc: 0.786885 train_f1: 0.786885 time: 0.0581s
INFO:root:Epoch: 0460 val_loss: 0.601767 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 0.656990 train_acc: 0.786885 train_f1: 0.786885 time: 0.0548s
INFO:root:Epoch: 0470 val_loss: 0.599867 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 0.661191 train_acc: 0.786885 train_f1: 0.786885 time: 0.0564s
INFO:root:Epoch: 0480 val_loss: 0.600126 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 0.660932 train_acc: 0.786885 train_f1: 0.786885 time: 0.0551s
INFO:root:Epoch: 0490 val_loss: 0.600426 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 0.656364 train_acc: 0.786885 train_f1: 0.786885 time: 0.0569s
INFO:root:Epoch: 0500 val_loss: 0.598699 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 0.655329 train_acc: 0.786885 train_f1: 0.786885 time: 0.0588s
INFO:root:Epoch: 0510 val_loss: 0.597156 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 0.654235 train_acc: 0.786885 train_f1: 0.786885 time: 0.0549s
INFO:root:Epoch: 0520 val_loss: 0.597063 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 0.654849 train_acc: 0.786885 train_f1: 0.786885 time: 0.0565s
INFO:root:Epoch: 0530 val_loss: 0.598843 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 0.660950 train_acc: 0.786885 train_f1: 0.786885 time: 0.0568s
INFO:root:Epoch: 0540 val_loss: 0.597464 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 0.668334 train_acc: 0.786885 train_f1: 0.786885 time: 0.0559s
INFO:root:Epoch: 0550 val_loss: 0.596298 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 0.655690 train_acc: 0.786885 train_f1: 0.786885 time: 0.0571s
INFO:root:Epoch: 0560 val_loss: 0.596169 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 0.658941 train_acc: 0.786885 train_f1: 0.786885 time: 0.0568s
INFO:root:Epoch: 0570 val_loss: 0.595928 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 0.656232 train_acc: 0.786885 train_f1: 0.786885 time: 0.0571s
INFO:root:Epoch: 0580 val_loss: 0.596744 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 0.655247 train_acc: 0.786885 train_f1: 0.786885 time: 0.0558s
INFO:root:Epoch: 0590 val_loss: 0.597912 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.662521 train_acc: 0.786885 train_f1: 0.786885 time: 0.0573s
INFO:root:Epoch: 0600 val_loss: 0.597462 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0610 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.658224 train_acc: 0.786885 train_f1: 0.786885 time: 0.0552s
INFO:root:Epoch: 0610 val_loss: 0.593966 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0620 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.659327 train_acc: 0.786885 train_f1: 0.786885 time: 0.0568s
INFO:root:Epoch: 0620 val_loss: 0.597148 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0630 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.650631 train_acc: 0.786885 train_f1: 0.786885 time: 0.0644s
INFO:root:Epoch: 0630 val_loss: 0.594573 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0640 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.654889 train_acc: 0.786885 train_f1: 0.786885 time: 0.0569s
INFO:root:Epoch: 0640 val_loss: 0.596316 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0650 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.648445 train_acc: 0.786885 train_f1: 0.786885 time: 0.0593s
INFO:root:Epoch: 0650 val_loss: 0.594056 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0660 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.652753 train_acc: 0.786885 train_f1: 0.786885 time: 0.0562s
INFO:root:Epoch: 0660 val_loss: 0.595468 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 40.0112s
INFO:root:Val set results: val_loss: 0.711486 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Test set results: test_loss: 0.825546 test_acc: 0.750000 test_f1: 0.750000
