INFO:root:Using: cuda:7
INFO:root:Using seed 28.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 57996.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.679256 train_acc: 0.618852 train_f1: 0.618852 time: 0.0325s
INFO:root:Epoch: 0010 val_loss: 1.540739 val_acc: 0.568182 val_f1: 0.568182
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.502505 train_acc: 0.635246 train_f1: 0.635246 time: 0.0285s
INFO:root:Epoch: 0020 val_loss: 1.363932 val_acc: 0.590909 val_f1: 0.590909
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.374186 train_acc: 0.737705 train_f1: 0.737705 time: 0.0256s
INFO:root:Epoch: 0030 val_loss: 1.274824 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.268234 train_acc: 0.836066 train_f1: 0.836066 time: 0.0302s
INFO:root:Epoch: 0040 val_loss: 1.197432 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.178215 train_acc: 0.877049 train_f1: 0.877049 time: 0.0281s
INFO:root:Epoch: 0050 val_loss: 1.126734 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.151980 train_acc: 0.905738 train_f1: 0.905738 time: 0.0333s
INFO:root:Epoch: 0060 val_loss: 1.121656 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.121033 train_acc: 0.913934 train_f1: 0.913934 time: 0.0338s
INFO:root:Epoch: 0070 val_loss: 1.089867 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.108436 train_acc: 0.913934 train_f1: 0.913934 time: 0.0282s
INFO:root:Epoch: 0080 val_loss: 1.078671 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.093466 train_acc: 0.901639 train_f1: 0.901639 time: 0.0294s
INFO:root:Epoch: 0090 val_loss: 1.080951 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.078810 train_acc: 0.918033 train_f1: 0.918033 time: 0.0341s
INFO:root:Epoch: 0100 val_loss: 1.060218 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.073004 train_acc: 0.930328 train_f1: 0.930328 time: 0.0311s
INFO:root:Epoch: 0110 val_loss: 1.064884 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.068893 train_acc: 0.930328 train_f1: 0.930328 time: 0.0301s
INFO:root:Epoch: 0120 val_loss: 1.061577 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.062428 train_acc: 0.930328 train_f1: 0.930328 time: 0.0287s
INFO:root:Epoch: 0130 val_loss: 1.056471 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.060851 train_acc: 0.922131 train_f1: 0.922131 time: 0.0282s
INFO:root:Epoch: 0140 val_loss: 1.070380 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.058136 train_acc: 0.930328 train_f1: 0.930328 time: 0.0299s
INFO:root:Epoch: 0150 val_loss: 1.077586 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.049371 train_acc: 0.930328 train_f1: 0.930328 time: 0.0300s
INFO:root:Epoch: 0160 val_loss: 1.052145 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.049947 train_acc: 0.930328 train_f1: 0.930328 time: 0.0304s
INFO:root:Epoch: 0170 val_loss: 1.044185 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.041552 train_acc: 0.930328 train_f1: 0.930328 time: 0.0324s
INFO:root:Epoch: 0180 val_loss: 1.050515 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.044006 train_acc: 0.930328 train_f1: 0.930328 time: 0.0277s
INFO:root:Epoch: 0190 val_loss: 1.053539 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 1.036988 train_acc: 0.930328 train_f1: 0.930328 time: 0.0305s
INFO:root:Epoch: 0200 val_loss: 1.043406 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 1.037738 train_acc: 0.926230 train_f1: 0.926230 time: 0.0277s
INFO:root:Epoch: 0210 val_loss: 1.038900 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 1.031664 train_acc: 0.930328 train_f1: 0.930328 time: 0.0310s
INFO:root:Epoch: 0220 val_loss: 1.049301 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 1.032046 train_acc: 0.930328 train_f1: 0.930328 time: 0.0312s
INFO:root:Epoch: 0230 val_loss: 1.052711 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 1.029992 train_acc: 0.930328 train_f1: 0.930328 time: 0.0343s
INFO:root:Epoch: 0240 val_loss: 1.053234 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 1.029819 train_acc: 0.926230 train_f1: 0.926230 time: 0.0284s
INFO:root:Epoch: 0250 val_loss: 1.050062 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 1.026502 train_acc: 0.934426 train_f1: 0.934426 time: 0.0291s
INFO:root:Epoch: 0260 val_loss: 1.047954 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 1.026532 train_acc: 0.934426 train_f1: 0.934426 time: 0.0291s
INFO:root:Epoch: 0270 val_loss: 1.048069 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 1.021483 train_acc: 0.934426 train_f1: 0.934426 time: 0.0292s
INFO:root:Epoch: 0280 val_loss: 1.044380 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 1.022874 train_acc: 0.934426 train_f1: 0.934426 time: 0.0304s
INFO:root:Epoch: 0290 val_loss: 1.045445 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 1.018860 train_acc: 0.934426 train_f1: 0.934426 time: 0.0273s
INFO:root:Epoch: 0300 val_loss: 1.039631 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 1.017874 train_acc: 0.930328 train_f1: 0.930328 time: 0.0320s
INFO:root:Epoch: 0310 val_loss: 1.035112 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 1.016912 train_acc: 0.934426 train_f1: 0.934426 time: 0.0298s
INFO:root:Epoch: 0320 val_loss: 1.034716 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 1.015000 train_acc: 0.934426 train_f1: 0.934426 time: 0.0305s
INFO:root:Epoch: 0330 val_loss: 1.032107 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 1.013745 train_acc: 0.930328 train_f1: 0.930328 time: 0.0312s
INFO:root:Epoch: 0340 val_loss: 1.031373 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 1.013730 train_acc: 0.934426 train_f1: 0.934426 time: 0.0304s
INFO:root:Epoch: 0350 val_loss: 1.035555 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 1.015191 train_acc: 0.934426 train_f1: 0.934426 time: 0.0284s
INFO:root:Epoch: 0360 val_loss: 1.039021 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 1.013870 train_acc: 0.934426 train_f1: 0.934426 time: 0.0307s
INFO:root:Epoch: 0370 val_loss: 1.043984 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 1.011307 train_acc: 0.934426 train_f1: 0.934426 time: 0.0368s
INFO:root:Epoch: 0380 val_loss: 1.045349 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 1.012874 train_acc: 0.934426 train_f1: 0.934426 time: 0.0292s
INFO:root:Epoch: 0390 val_loss: 1.046534 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 1.010718 train_acc: 0.930328 train_f1: 0.930328 time: 0.0282s
INFO:root:Epoch: 0400 val_loss: 1.041825 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 1.008307 train_acc: 0.934426 train_f1: 0.934426 time: 0.0285s
INFO:root:Epoch: 0410 val_loss: 1.038304 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 1.008695 train_acc: 0.934426 train_f1: 0.934426 time: 0.0298s
INFO:root:Epoch: 0420 val_loss: 1.037045 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 1.009626 train_acc: 0.934426 train_f1: 0.934426 time: 0.0384s
INFO:root:Epoch: 0430 val_loss: 1.036928 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 1.008566 train_acc: 0.930328 train_f1: 0.930328 time: 0.0292s
INFO:root:Epoch: 0440 val_loss: 1.036045 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 1.009838 train_acc: 0.934426 train_f1: 0.934426 time: 0.0294s
INFO:root:Epoch: 0450 val_loss: 1.035820 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 1.009366 train_acc: 0.934426 train_f1: 0.934426 time: 0.0291s
INFO:root:Epoch: 0460 val_loss: 1.035351 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 1.007631 train_acc: 0.930328 train_f1: 0.930328 time: 0.0296s
INFO:root:Epoch: 0470 val_loss: 1.033127 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 1.009857 train_acc: 0.934426 train_f1: 0.934426 time: 0.0303s
INFO:root:Epoch: 0480 val_loss: 1.032984 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 1.006720 train_acc: 0.930328 train_f1: 0.930328 time: 0.0304s
INFO:root:Epoch: 0490 val_loss: 1.033288 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 1.008741 train_acc: 0.934426 train_f1: 0.934426 time: 0.0296s
INFO:root:Epoch: 0500 val_loss: 1.035820 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 1.005680 train_acc: 0.934426 train_f1: 0.934426 time: 0.0295s
INFO:root:Epoch: 0510 val_loss: 1.035797 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 1.006030 train_acc: 0.934426 train_f1: 0.934426 time: 0.0311s
INFO:root:Epoch: 0520 val_loss: 1.035871 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 1.004493 train_acc: 0.934426 train_f1: 0.934426 time: 0.0302s
INFO:root:Epoch: 0530 val_loss: 1.035491 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 1.005282 train_acc: 0.934426 train_f1: 0.934426 time: 0.0294s
INFO:root:Epoch: 0540 val_loss: 1.034430 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 1.004650 train_acc: 0.934426 train_f1: 0.934426 time: 0.0298s
INFO:root:Epoch: 0550 val_loss: 1.033856 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 1.006684 train_acc: 0.934426 train_f1: 0.934426 time: 0.0285s
INFO:root:Epoch: 0560 val_loss: 1.034564 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 1.002882 train_acc: 0.934426 train_f1: 0.934426 time: 0.0311s
INFO:root:Epoch: 0570 val_loss: 1.034329 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 1.003861 train_acc: 0.934426 train_f1: 0.934426 time: 0.0286s
INFO:root:Epoch: 0580 val_loss: 1.034140 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 1.004814 train_acc: 0.934426 train_f1: 0.934426 time: 0.0290s
INFO:root:Epoch: 0590 val_loss: 1.034898 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.002900 train_acc: 0.934426 train_f1: 0.934426 time: 0.0312s
INFO:root:Epoch: 0600 val_loss: 1.035911 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0610 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.004152 train_acc: 0.934426 train_f1: 0.934426 time: 0.0280s
INFO:root:Epoch: 0610 val_loss: 1.036377 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0620 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.003284 train_acc: 0.934426 train_f1: 0.934426 time: 0.0298s
INFO:root:Epoch: 0620 val_loss: 1.036357 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0630 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.002880 train_acc: 0.934426 train_f1: 0.934426 time: 0.0297s
INFO:root:Epoch: 0630 val_loss: 1.036226 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0640 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.003903 train_acc: 0.934426 train_f1: 0.934426 time: 0.0293s
INFO:root:Epoch: 0640 val_loss: 1.035780 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0650 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.002784 train_acc: 0.934426 train_f1: 0.934426 time: 0.0342s
INFO:root:Epoch: 0650 val_loss: 1.035257 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0660 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.003084 train_acc: 0.934426 train_f1: 0.934426 time: 0.0277s
INFO:root:Epoch: 0660 val_loss: 1.034806 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Epoch: 0670 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.003192 train_acc: 0.934426 train_f1: 0.934426 time: 0.0293s
INFO:root:Epoch: 0670 val_loss: 1.033996 val_acc: 0.840909 val_f1: 0.840909
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 22.5863s
INFO:root:Val set results: val_loss: 1.044185 val_acc: 0.863636 val_f1: 0.863636
INFO:root:Test set results: test_loss: 1.152506 test_acc: 0.909091 test_f1: 0.909091
