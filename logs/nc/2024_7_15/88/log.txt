INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (3): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 59085.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.636204 train_acc: 0.418033 train_f1: 0.418033 time: 0.0268s
INFO:root:Epoch: 0010 val_loss: 1.568740 val_acc: 0.409091 val_f1: 0.409091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.472780 train_acc: 0.422131 train_f1: 0.422131 time: 0.0257s
INFO:root:Epoch: 0020 val_loss: 1.512738 val_acc: 0.386364 val_f1: 0.386364
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.398972 train_acc: 0.422131 train_f1: 0.422131 time: 0.0260s
INFO:root:Epoch: 0030 val_loss: 1.512015 val_acc: 0.386364 val_f1: 0.386364
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.333395 train_acc: 0.467213 train_f1: 0.467213 time: 0.0288s
INFO:root:Epoch: 0040 val_loss: 1.479502 val_acc: 0.386364 val_f1: 0.386364
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.279602 train_acc: 0.512295 train_f1: 0.512295 time: 0.0272s
INFO:root:Epoch: 0050 val_loss: 1.437963 val_acc: 0.386364 val_f1: 0.386364
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.221923 train_acc: 0.733607 train_f1: 0.733607 time: 0.0264s
INFO:root:Epoch: 0060 val_loss: 1.401568 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.181778 train_acc: 0.758197 train_f1: 0.758197 time: 0.0267s
INFO:root:Epoch: 0070 val_loss: 1.382355 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.165527 train_acc: 0.762295 train_f1: 0.762295 time: 0.0273s
INFO:root:Epoch: 0080 val_loss: 1.360881 val_acc: 0.750000 val_f1: 0.750000
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.144241 train_acc: 0.774590 train_f1: 0.774590 time: 0.0293s
INFO:root:Epoch: 0090 val_loss: 1.340796 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.133634 train_acc: 0.790984 train_f1: 0.790984 time: 0.0281s
INFO:root:Epoch: 0100 val_loss: 1.330301 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.131001 train_acc: 0.790984 train_f1: 0.790984 time: 0.0352s
INFO:root:Epoch: 0110 val_loss: 1.324777 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.128757 train_acc: 0.790984 train_f1: 0.790984 time: 0.0292s
INFO:root:Epoch: 0120 val_loss: 1.318418 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.120594 train_acc: 0.790984 train_f1: 0.790984 time: 0.0308s
INFO:root:Epoch: 0130 val_loss: 1.314993 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.117867 train_acc: 0.790984 train_f1: 0.790984 time: 0.0315s
INFO:root:Epoch: 0140 val_loss: 1.310444 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.117747 train_acc: 0.790984 train_f1: 0.790984 time: 0.0303s
INFO:root:Epoch: 0150 val_loss: 1.309233 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.116150 train_acc: 0.790984 train_f1: 0.790984 time: 0.0343s
INFO:root:Epoch: 0160 val_loss: 1.306836 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.116764 train_acc: 0.790984 train_f1: 0.790984 time: 0.0342s
INFO:root:Epoch: 0170 val_loss: 1.302664 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.112826 train_acc: 0.790984 train_f1: 0.790984 time: 0.0293s
INFO:root:Epoch: 0180 val_loss: 1.298110 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.109531 train_acc: 0.790984 train_f1: 0.790984 time: 0.0301s
INFO:root:Epoch: 0190 val_loss: 1.292405 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 1.109613 train_acc: 0.790984 train_f1: 0.790984 time: 0.0301s
INFO:root:Epoch: 0200 val_loss: 1.292152 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 1.108636 train_acc: 0.790984 train_f1: 0.790984 time: 0.0342s
INFO:root:Epoch: 0210 val_loss: 1.291911 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 1.107741 train_acc: 0.786885 train_f1: 0.786885 time: 0.0297s
INFO:root:Epoch: 0220 val_loss: 1.291776 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 1.105217 train_acc: 0.790984 train_f1: 0.790984 time: 0.0327s
INFO:root:Epoch: 0230 val_loss: 1.290648 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 1.105287 train_acc: 0.790984 train_f1: 0.790984 time: 0.0330s
INFO:root:Epoch: 0240 val_loss: 1.288645 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 1.104626 train_acc: 0.790984 train_f1: 0.790984 time: 0.0402s
INFO:root:Epoch: 0250 val_loss: 1.286078 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 1.105228 train_acc: 0.790984 train_f1: 0.790984 time: 0.0335s
INFO:root:Epoch: 0260 val_loss: 1.284752 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 1.104013 train_acc: 0.790984 train_f1: 0.790984 time: 0.0387s
INFO:root:Epoch: 0270 val_loss: 1.283652 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 1.101039 train_acc: 0.790984 train_f1: 0.790984 time: 0.0337s
INFO:root:Epoch: 0280 val_loss: 1.282989 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 1.106240 train_acc: 0.790984 train_f1: 0.790984 time: 0.0327s
INFO:root:Epoch: 0290 val_loss: 1.281481 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 1.099164 train_acc: 0.790984 train_f1: 0.790984 time: 0.0359s
INFO:root:Epoch: 0300 val_loss: 1.278550 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 1.099353 train_acc: 0.790984 train_f1: 0.790984 time: 0.0357s
INFO:root:Epoch: 0310 val_loss: 1.277284 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 1.101599 train_acc: 0.786885 train_f1: 0.786885 time: 0.0319s
INFO:root:Epoch: 0320 val_loss: 1.276527 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 1.098887 train_acc: 0.790984 train_f1: 0.790984 time: 0.0331s
INFO:root:Epoch: 0330 val_loss: 1.275473 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 1.098445 train_acc: 0.790984 train_f1: 0.790984 time: 0.0342s
INFO:root:Epoch: 0340 val_loss: 1.274405 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 1.098789 train_acc: 0.790984 train_f1: 0.790984 time: 0.0344s
INFO:root:Epoch: 0350 val_loss: 1.273220 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 1.096982 train_acc: 0.790984 train_f1: 0.790984 time: 0.0345s
INFO:root:Epoch: 0360 val_loss: 1.272654 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 1.097691 train_acc: 0.790984 train_f1: 0.790984 time: 0.0329s
INFO:root:Epoch: 0370 val_loss: 1.272231 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 1.095522 train_acc: 0.790984 train_f1: 0.790984 time: 0.0355s
INFO:root:Epoch: 0380 val_loss: 1.271148 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 1.095089 train_acc: 0.790984 train_f1: 0.790984 time: 0.0370s
INFO:root:Epoch: 0390 val_loss: 1.270516 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 1.097221 train_acc: 0.790984 train_f1: 0.790984 time: 0.0360s
INFO:root:Epoch: 0400 val_loss: 1.270250 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 1.094916 train_acc: 0.790984 train_f1: 0.790984 time: 0.0361s
INFO:root:Epoch: 0410 val_loss: 1.269704 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 1.095983 train_acc: 0.790984 train_f1: 0.790984 time: 0.0337s
INFO:root:Epoch: 0420 val_loss: 1.269158 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 1.095887 train_acc: 0.790984 train_f1: 0.790984 time: 0.0335s
INFO:root:Epoch: 0430 val_loss: 1.268529 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 1.094742 train_acc: 0.790984 train_f1: 0.790984 time: 0.0325s
INFO:root:Epoch: 0440 val_loss: 1.268365 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 1.095654 train_acc: 0.790984 train_f1: 0.790984 time: 0.0395s
INFO:root:Epoch: 0450 val_loss: 1.268293 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 1.093828 train_acc: 0.790984 train_f1: 0.790984 time: 0.0414s
INFO:root:Epoch: 0460 val_loss: 1.268468 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 1.094124 train_acc: 0.790984 train_f1: 0.790984 time: 0.0333s
INFO:root:Epoch: 0470 val_loss: 1.268157 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 1.093640 train_acc: 0.790984 train_f1: 0.790984 time: 0.0310s
INFO:root:Epoch: 0480 val_loss: 1.267821 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 1.094018 train_acc: 0.790984 train_f1: 0.790984 time: 0.0360s
INFO:root:Epoch: 0490 val_loss: 1.267775 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 1.094467 train_acc: 0.790984 train_f1: 0.790984 time: 0.0319s
INFO:root:Epoch: 0500 val_loss: 1.267307 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 1.093180 train_acc: 0.790984 train_f1: 0.790984 time: 0.0346s
INFO:root:Epoch: 0510 val_loss: 1.267078 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 1.093293 train_acc: 0.790984 train_f1: 0.790984 time: 0.0311s
INFO:root:Epoch: 0520 val_loss: 1.266803 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 1.094085 train_acc: 0.790984 train_f1: 0.790984 time: 0.0320s
INFO:root:Epoch: 0530 val_loss: 1.266630 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 1.095832 train_acc: 0.790984 train_f1: 0.790984 time: 0.0332s
INFO:root:Epoch: 0540 val_loss: 1.266340 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 1.093720 train_acc: 0.790984 train_f1: 0.790984 time: 0.0395s
INFO:root:Epoch: 0550 val_loss: 1.266125 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 1.092320 train_acc: 0.790984 train_f1: 0.790984 time: 0.0367s
INFO:root:Epoch: 0560 val_loss: 1.265954 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 1.094121 train_acc: 0.790984 train_f1: 0.790984 time: 0.0347s
INFO:root:Epoch: 0570 val_loss: 1.266000 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 1.091514 train_acc: 0.790984 train_f1: 0.790984 time: 0.0343s
INFO:root:Epoch: 0580 val_loss: 1.265863 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 1.093164 train_acc: 0.790984 train_f1: 0.790984 time: 0.0385s
INFO:root:Epoch: 0590 val_loss: 1.265360 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.093045 train_acc: 0.790984 train_f1: 0.790984 time: 0.0358s
INFO:root:Epoch: 0600 val_loss: 1.265052 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0610 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.093547 train_acc: 0.790984 train_f1: 0.790984 time: 0.0323s
INFO:root:Epoch: 0610 val_loss: 1.264967 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0620 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.092807 train_acc: 0.790984 train_f1: 0.790984 time: 0.0327s
INFO:root:Epoch: 0620 val_loss: 1.264911 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 23.0704s
INFO:root:Val set results: val_loss: 1.318418 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Test set results: test_loss: 0.930563 test_acc: 0.886364 test_f1: 0.886364
