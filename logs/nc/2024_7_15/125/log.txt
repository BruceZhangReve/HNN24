INFO:root:Using: cuda:7
INFO:root:Using seed 1.
INFO:root:Dataset: wisconsin
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (3): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 59085.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.366409 train_acc: 0.675159 train_f1: 0.675159 time: 0.0391s
INFO:root:Epoch: 0010 val_loss: 1.307488 val_acc: 0.722222 val_f1: 0.722222
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.190635 train_acc: 0.742038 train_f1: 0.742038 time: 0.0330s
INFO:root:Epoch: 0020 val_loss: 1.115401 val_acc: 0.759259 val_f1: 0.759259
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 0.950507 train_acc: 0.869427 train_f1: 0.869427 time: 0.0359s
INFO:root:Epoch: 0030 val_loss: 0.964342 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 0.826655 train_acc: 0.875796 train_f1: 0.875796 time: 0.0350s
INFO:root:Epoch: 0040 val_loss: 0.851194 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 0.725605 train_acc: 0.907643 train_f1: 0.907643 time: 0.0337s
INFO:root:Epoch: 0050 val_loss: 0.801616 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 0.663608 train_acc: 0.917197 train_f1: 0.917197 time: 0.0388s
INFO:root:Epoch: 0060 val_loss: 0.793603 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.649904 train_acc: 0.920382 train_f1: 0.920382 time: 0.0386s
INFO:root:Epoch: 0070 val_loss: 0.780341 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.622953 train_acc: 0.923567 train_f1: 0.923567 time: 0.0387s
INFO:root:Epoch: 0080 val_loss: 0.776948 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.617876 train_acc: 0.920382 train_f1: 0.920382 time: 0.0342s
INFO:root:Epoch: 0090 val_loss: 0.771441 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 0.592268 train_acc: 0.926752 train_f1: 0.926752 time: 0.0359s
INFO:root:Epoch: 0100 val_loss: 0.759491 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 0.591858 train_acc: 0.923567 train_f1: 0.923567 time: 0.0368s
INFO:root:Epoch: 0110 val_loss: 0.756348 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 0.584958 train_acc: 0.926752 train_f1: 0.926752 time: 0.0354s
INFO:root:Epoch: 0120 val_loss: 0.758996 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 0.580159 train_acc: 0.926752 train_f1: 0.926752 time: 0.0376s
INFO:root:Epoch: 0130 val_loss: 0.756433 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 0.577339 train_acc: 0.926752 train_f1: 0.926752 time: 0.0356s
INFO:root:Epoch: 0140 val_loss: 0.753544 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.573055 train_acc: 0.926752 train_f1: 0.926752 time: 0.0422s
INFO:root:Epoch: 0150 val_loss: 0.755046 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.569051 train_acc: 0.926752 train_f1: 0.926752 time: 0.0391s
INFO:root:Epoch: 0160 val_loss: 0.751456 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.567924 train_acc: 0.926752 train_f1: 0.926752 time: 0.0341s
INFO:root:Epoch: 0170 val_loss: 0.747788 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.563338 train_acc: 0.926752 train_f1: 0.926752 time: 0.0352s
INFO:root:Epoch: 0180 val_loss: 0.753130 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.560366 train_acc: 0.926752 train_f1: 0.926752 time: 0.0468s
INFO:root:Epoch: 0190 val_loss: 0.749470 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 0.560824 train_acc: 0.926752 train_f1: 0.926752 time: 0.0384s
INFO:root:Epoch: 0200 val_loss: 0.746445 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 0.559093 train_acc: 0.926752 train_f1: 0.926752 time: 0.0335s
INFO:root:Epoch: 0210 val_loss: 0.745270 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 0.561920 train_acc: 0.923567 train_f1: 0.923567 time: 0.0379s
INFO:root:Epoch: 0220 val_loss: 0.745473 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 0.557492 train_acc: 0.926752 train_f1: 0.926752 time: 0.0375s
INFO:root:Epoch: 0230 val_loss: 0.742652 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 0.554836 train_acc: 0.926752 train_f1: 0.926752 time: 0.0360s
INFO:root:Epoch: 0240 val_loss: 0.739059 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 0.552269 train_acc: 0.926752 train_f1: 0.926752 time: 0.0388s
INFO:root:Epoch: 0250 val_loss: 0.735274 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 0.552284 train_acc: 0.926752 train_f1: 0.926752 time: 0.0459s
INFO:root:Epoch: 0260 val_loss: 0.736231 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 0.551235 train_acc: 0.923567 train_f1: 0.923567 time: 0.0342s
INFO:root:Epoch: 0270 val_loss: 0.735985 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 0.548614 train_acc: 0.926752 train_f1: 0.926752 time: 0.0341s
INFO:root:Epoch: 0280 val_loss: 0.739081 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 0.546185 train_acc: 0.926752 train_f1: 0.926752 time: 0.0359s
INFO:root:Epoch: 0290 val_loss: 0.742085 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 0.545308 train_acc: 0.926752 train_f1: 0.926752 time: 0.0490s
INFO:root:Epoch: 0300 val_loss: 0.744040 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 0.548997 train_acc: 0.926752 train_f1: 0.926752 time: 0.0376s
INFO:root:Epoch: 0310 val_loss: 0.743081 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 0.548294 train_acc: 0.923567 train_f1: 0.923567 time: 0.0386s
INFO:root:Epoch: 0320 val_loss: 0.743397 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 0.543495 train_acc: 0.926752 train_f1: 0.926752 time: 0.0395s
INFO:root:Epoch: 0330 val_loss: 0.742445 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 0.544067 train_acc: 0.926752 train_f1: 0.926752 time: 0.0373s
INFO:root:Epoch: 0340 val_loss: 0.741184 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 0.544274 train_acc: 0.926752 train_f1: 0.926752 time: 0.0388s
INFO:root:Epoch: 0350 val_loss: 0.740292 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 0.542412 train_acc: 0.926752 train_f1: 0.926752 time: 0.0335s
INFO:root:Epoch: 0360 val_loss: 0.740652 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 0.550256 train_acc: 0.923567 train_f1: 0.923567 time: 0.0380s
INFO:root:Epoch: 0370 val_loss: 0.739849 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 0.543639 train_acc: 0.926752 train_f1: 0.926752 time: 0.0341s
INFO:root:Epoch: 0380 val_loss: 0.740078 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 0.543560 train_acc: 0.926752 train_f1: 0.926752 time: 0.0384s
INFO:root:Epoch: 0390 val_loss: 0.739274 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 0.539283 train_acc: 0.926752 train_f1: 0.926752 time: 0.0337s
INFO:root:Epoch: 0400 val_loss: 0.738224 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 0.538403 train_acc: 0.926752 train_f1: 0.926752 time: 0.0420s
INFO:root:Epoch: 0410 val_loss: 0.737378 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 0.540420 train_acc: 0.926752 train_f1: 0.926752 time: 0.0373s
INFO:root:Epoch: 0420 val_loss: 0.735462 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 0.538629 train_acc: 0.926752 train_f1: 0.926752 time: 0.0370s
INFO:root:Epoch: 0430 val_loss: 0.734350 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 0.539036 train_acc: 0.926752 train_f1: 0.926752 time: 0.0416s
INFO:root:Epoch: 0440 val_loss: 0.733570 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 0.540400 train_acc: 0.926752 train_f1: 0.926752 time: 0.0400s
INFO:root:Epoch: 0450 val_loss: 0.733337 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 0.536157 train_acc: 0.926752 train_f1: 0.926752 time: 0.0395s
INFO:root:Epoch: 0460 val_loss: 0.733669 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 0.541349 train_acc: 0.926752 train_f1: 0.926752 time: 0.0380s
INFO:root:Epoch: 0470 val_loss: 0.734600 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 0.541092 train_acc: 0.923567 train_f1: 0.923567 time: 0.0415s
INFO:root:Epoch: 0480 val_loss: 0.734370 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 0.538663 train_acc: 0.926752 train_f1: 0.926752 time: 0.0340s
INFO:root:Epoch: 0490 val_loss: 0.735122 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 0.536035 train_acc: 0.926752 train_f1: 0.926752 time: 0.0385s
INFO:root:Epoch: 0500 val_loss: 0.737194 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 0.535461 train_acc: 0.926752 train_f1: 0.926752 time: 0.0442s
INFO:root:Epoch: 0510 val_loss: 0.737767 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 0.536173 train_acc: 0.926752 train_f1: 0.926752 time: 0.0365s
INFO:root:Epoch: 0520 val_loss: 0.737543 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 0.538314 train_acc: 0.926752 train_f1: 0.926752 time: 0.0394s
INFO:root:Epoch: 0530 val_loss: 0.738061 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 0.537491 train_acc: 0.926752 train_f1: 0.926752 time: 0.0344s
INFO:root:Epoch: 0540 val_loss: 0.738736 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 0.536408 train_acc: 0.926752 train_f1: 0.926752 time: 0.0347s
INFO:root:Epoch: 0550 val_loss: 0.739856 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 0.534969 train_acc: 0.926752 train_f1: 0.926752 time: 0.0372s
INFO:root:Epoch: 0560 val_loss: 0.739141 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 23.9335s
INFO:root:Val set results: val_loss: 0.793603 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Test set results: test_loss: 0.743418 test_acc: 0.814815 test_f1: 0.814815
