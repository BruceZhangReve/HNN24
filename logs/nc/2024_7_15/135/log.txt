INFO:root:Using: cuda:7
INFO:root:Using seed 42.
INFO:root:Dataset: wisconsin
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (3): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
          (MLP_f): LMLP(
            (linear1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=64, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (linear2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=64, out_features=64, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
          (MLP_fi): LMLP(
            (linear1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=64, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (linear2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 68497.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.427204 train_acc: 0.436306 train_f1: 0.436306 time: 0.0442s
INFO:root:Epoch: 0010 val_loss: 1.258363 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.309984 train_acc: 0.538217 train_f1: 0.538217 time: 0.0487s
INFO:root:Epoch: 0020 val_loss: 1.133088 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.290128 train_acc: 0.538217 train_f1: 0.538217 time: 0.0456s
INFO:root:Epoch: 0030 val_loss: 1.140335 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.268350 train_acc: 0.538217 train_f1: 0.538217 time: 0.0460s
INFO:root:Epoch: 0040 val_loss: 1.110014 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.269143 train_acc: 0.538217 train_f1: 0.538217 time: 0.0442s
INFO:root:Epoch: 0050 val_loss: 1.138284 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.236206 train_acc: 0.538217 train_f1: 0.538217 time: 0.0466s
INFO:root:Epoch: 0060 val_loss: 1.128884 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.230728 train_acc: 0.538217 train_f1: 0.538217 time: 0.0477s
INFO:root:Epoch: 0070 val_loss: 1.130859 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.231871 train_acc: 0.538217 train_f1: 0.538217 time: 0.0446s
INFO:root:Epoch: 0080 val_loss: 1.126331 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.224844 train_acc: 0.538217 train_f1: 0.538217 time: 0.0423s
INFO:root:Epoch: 0090 val_loss: 1.119371 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.219000 train_acc: 0.538217 train_f1: 0.538217 time: 0.0465s
INFO:root:Epoch: 0100 val_loss: 1.122304 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.225532 train_acc: 0.538217 train_f1: 0.538217 time: 0.0425s
INFO:root:Epoch: 0110 val_loss: 1.115578 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.201957 train_acc: 0.538217 train_f1: 0.538217 time: 0.0448s
INFO:root:Epoch: 0120 val_loss: 1.114382 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.193991 train_acc: 0.538217 train_f1: 0.538217 time: 0.0420s
INFO:root:Epoch: 0130 val_loss: 1.104659 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.166079 train_acc: 0.550955 train_f1: 0.550955 time: 0.0441s
INFO:root:Epoch: 0140 val_loss: 1.086473 val_acc: 0.574074 val_f1: 0.574074
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.108486 train_acc: 0.563694 train_f1: 0.563694 time: 0.0431s
INFO:root:Epoch: 0150 val_loss: 1.020654 val_acc: 0.629630 val_f1: 0.629630
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.959653 train_acc: 0.621019 train_f1: 0.621019 time: 0.0459s
INFO:root:Epoch: 0160 val_loss: 0.900924 val_acc: 0.629630 val_f1: 0.629630
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.824311 train_acc: 0.687898 train_f1: 0.687898 time: 0.0427s
INFO:root:Epoch: 0170 val_loss: 0.754151 val_acc: 0.722222 val_f1: 0.722222
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.718978 train_acc: 0.770701 train_f1: 0.770701 time: 0.0424s
INFO:root:Epoch: 0180 val_loss: 0.653252 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.666958 train_acc: 0.840764 train_f1: 0.840764 time: 0.0444s
INFO:root:Epoch: 0190 val_loss: 0.620562 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 0.615372 train_acc: 0.872611 train_f1: 0.872611 time: 0.0486s
INFO:root:Epoch: 0200 val_loss: 0.569833 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 0.633950 train_acc: 0.878981 train_f1: 0.878981 time: 0.0502s
INFO:root:Epoch: 0210 val_loss: 0.581623 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 0.603417 train_acc: 0.885350 train_f1: 0.885350 time: 0.0476s
INFO:root:Epoch: 0220 val_loss: 0.595233 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 0.602673 train_acc: 0.878981 train_f1: 0.878981 time: 0.0459s
INFO:root:Epoch: 0230 val_loss: 0.580218 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 0.605250 train_acc: 0.901274 train_f1: 0.901274 time: 0.0426s
INFO:root:Epoch: 0240 val_loss: 0.578967 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 0.588212 train_acc: 0.898089 train_f1: 0.898089 time: 0.0426s
INFO:root:Epoch: 0250 val_loss: 0.582700 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 0.593775 train_acc: 0.901274 train_f1: 0.901274 time: 0.0467s
INFO:root:Epoch: 0260 val_loss: 0.592464 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 0.583637 train_acc: 0.901274 train_f1: 0.901274 time: 0.0459s
INFO:root:Epoch: 0270 val_loss: 0.592361 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 0.586998 train_acc: 0.904459 train_f1: 0.904459 time: 0.0460s
INFO:root:Epoch: 0280 val_loss: 0.594161 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 0.582324 train_acc: 0.904459 train_f1: 0.904459 time: 0.0472s
INFO:root:Epoch: 0290 val_loss: 0.594228 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 0.579596 train_acc: 0.914013 train_f1: 0.914013 time: 0.0422s
INFO:root:Epoch: 0300 val_loss: 0.593757 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 0.574946 train_acc: 0.907643 train_f1: 0.907643 time: 0.0423s
INFO:root:Epoch: 0310 val_loss: 0.591561 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 0.576939 train_acc: 0.917197 train_f1: 0.917197 time: 0.0456s
INFO:root:Epoch: 0320 val_loss: 0.589924 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 0.567551 train_acc: 0.920382 train_f1: 0.920382 time: 0.0462s
INFO:root:Epoch: 0330 val_loss: 0.588417 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 0.570475 train_acc: 0.923567 train_f1: 0.923567 time: 0.0437s
INFO:root:Epoch: 0340 val_loss: 0.587817 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 0.578208 train_acc: 0.917197 train_f1: 0.917197 time: 0.0444s
INFO:root:Epoch: 0350 val_loss: 0.587540 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 0.561091 train_acc: 0.917197 train_f1: 0.917197 time: 0.0470s
INFO:root:Epoch: 0360 val_loss: 0.586998 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 0.557952 train_acc: 0.923567 train_f1: 0.923567 time: 0.0441s
INFO:root:Epoch: 0370 val_loss: 0.586945 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 0.575116 train_acc: 0.910828 train_f1: 0.910828 time: 0.0489s
INFO:root:Epoch: 0380 val_loss: 0.587474 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 0.575928 train_acc: 0.920382 train_f1: 0.920382 time: 0.0449s
INFO:root:Epoch: 0390 val_loss: 0.586465 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 0.563930 train_acc: 0.917197 train_f1: 0.917197 time: 0.0425s
INFO:root:Epoch: 0400 val_loss: 0.587018 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 0.559081 train_acc: 0.920382 train_f1: 0.920382 time: 0.0455s
INFO:root:Epoch: 0410 val_loss: 0.587366 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 0.572796 train_acc: 0.914013 train_f1: 0.914013 time: 0.0463s
INFO:root:Epoch: 0420 val_loss: 0.588246 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 0.577663 train_acc: 0.907643 train_f1: 0.907643 time: 0.0420s
INFO:root:Epoch: 0430 val_loss: 0.588978 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 0.556692 train_acc: 0.917197 train_f1: 0.917197 time: 0.0461s
INFO:root:Epoch: 0440 val_loss: 0.590547 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 0.555393 train_acc: 0.920382 train_f1: 0.920382 time: 0.0473s
INFO:root:Epoch: 0450 val_loss: 0.591811 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 0.589455 train_acc: 0.907643 train_f1: 0.907643 time: 0.0461s
INFO:root:Epoch: 0460 val_loss: 0.592687 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 0.552929 train_acc: 0.923567 train_f1: 0.923567 time: 0.0438s
INFO:root:Epoch: 0470 val_loss: 0.593440 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 0.575225 train_acc: 0.920382 train_f1: 0.920382 time: 0.0463s
INFO:root:Epoch: 0480 val_loss: 0.593829 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 0.567096 train_acc: 0.917197 train_f1: 0.917197 time: 0.0422s
INFO:root:Epoch: 0490 val_loss: 0.593826 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 0.559824 train_acc: 0.914013 train_f1: 0.914013 time: 0.0439s
INFO:root:Epoch: 0500 val_loss: 0.593949 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 0.563671 train_acc: 0.926752 train_f1: 0.926752 time: 0.0437s
INFO:root:Epoch: 0510 val_loss: 0.594097 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 0.563669 train_acc: 0.901274 train_f1: 0.901274 time: 0.0445s
INFO:root:Epoch: 0520 val_loss: 0.593872 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 0.552436 train_acc: 0.920382 train_f1: 0.920382 time: 0.0467s
INFO:root:Epoch: 0530 val_loss: 0.593683 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 0.570098 train_acc: 0.920382 train_f1: 0.920382 time: 0.0471s
INFO:root:Epoch: 0540 val_loss: 0.594033 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 0.568731 train_acc: 0.920382 train_f1: 0.920382 time: 0.0429s
INFO:root:Epoch: 0550 val_loss: 0.594269 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 0.580628 train_acc: 0.910828 train_f1: 0.910828 time: 0.0445s
INFO:root:Epoch: 0560 val_loss: 0.593852 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 0.552497 train_acc: 0.923567 train_f1: 0.923567 time: 0.0427s
INFO:root:Epoch: 0570 val_loss: 0.593903 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 0.557692 train_acc: 0.917197 train_f1: 0.917197 time: 0.0480s
INFO:root:Epoch: 0580 val_loss: 0.594535 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 0.570663 train_acc: 0.917197 train_f1: 0.917197 time: 0.0477s
INFO:root:Epoch: 0590 val_loss: 0.595136 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.591895 train_acc: 0.898089 train_f1: 0.898089 time: 0.0459s
INFO:root:Epoch: 0600 val_loss: 0.595626 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0610 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.563195 train_acc: 0.914013 train_f1: 0.914013 time: 0.0430s
INFO:root:Epoch: 0610 val_loss: 0.595795 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0620 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.572398 train_acc: 0.917197 train_f1: 0.917197 time: 0.0473s
INFO:root:Epoch: 0620 val_loss: 0.595711 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0630 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.557573 train_acc: 0.917197 train_f1: 0.917197 time: 0.0471s
INFO:root:Epoch: 0630 val_loss: 0.595908 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0640 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.556730 train_acc: 0.923567 train_f1: 0.923567 time: 0.0425s
INFO:root:Epoch: 0640 val_loss: 0.595839 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0650 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.563656 train_acc: 0.923567 train_f1: 0.923567 time: 0.0429s
INFO:root:Epoch: 0650 val_loss: 0.595749 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0660 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.562723 train_acc: 0.920382 train_f1: 0.920382 time: 0.0434s
INFO:root:Epoch: 0660 val_loss: 0.595468 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0670 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.569637 train_acc: 0.923567 train_f1: 0.923567 time: 0.0461s
INFO:root:Epoch: 0670 val_loss: 0.595017 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0680 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.566237 train_acc: 0.920382 train_f1: 0.920382 time: 0.0481s
INFO:root:Epoch: 0680 val_loss: 0.594815 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0690 lr: [1.5625e-05, 1.5625e-05] train_loss: 0.565680 train_acc: 0.917197 train_f1: 0.917197 time: 0.0425s
INFO:root:Epoch: 0690 val_loss: 0.594613 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0700 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.581256 train_acc: 0.923567 train_f1: 0.923567 time: 0.0435s
INFO:root:Epoch: 0700 val_loss: 0.594596 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0710 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.557544 train_acc: 0.920382 train_f1: 0.920382 time: 0.0467s
INFO:root:Epoch: 0710 val_loss: 0.594619 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Epoch: 0720 lr: [7.8125e-06, 7.8125e-06] train_loss: 0.571911 train_acc: 0.923567 train_f1: 0.923567 time: 0.0460s
INFO:root:Epoch: 0720 val_loss: 0.594662 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 35.6238s
INFO:root:Val set results: val_loss: 0.595233 val_acc: 0.907407 val_f1: 0.907407
INFO:root:Test set results: test_loss: 0.855253 test_acc: 0.833333 test_f1: 0.833333
