INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (manifold): Lorentz manifold
  (encoder): HKPNet(
    (manifold): Lorentz manifold
    (linear_before): LorentzLinear(
      (manifold): Lorentz manifold
      (weight): Linear(in_features=1704, out_features=32, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (manifold): Lorentz manifold
          (linears): ModuleList(
            (0): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (1): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (2): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
            (3): LorentzLinear(
              (manifold): Lorentz manifold
              (weight): Linear(in_features=32, out_features=32, bias=True)
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): LorentzDecoder(
    (manifold): Lorentz manifold
  )
)
INFO:root:Total number of parameters: 59085.0
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.633889 train_acc: 0.418033 train_f1: 0.418033 time: 0.0319s
INFO:root:Epoch: 0010 val_loss: 1.559600 val_acc: 0.409091 val_f1: 0.409091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.470981 train_acc: 0.422131 train_f1: 0.422131 time: 0.0298s
INFO:root:Epoch: 0020 val_loss: 1.505429 val_acc: 0.386364 val_f1: 0.386364
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.390502 train_acc: 0.422131 train_f1: 0.422131 time: 0.0291s
INFO:root:Epoch: 0030 val_loss: 1.501424 val_acc: 0.386364 val_f1: 0.386364
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.318034 train_acc: 0.467213 train_f1: 0.467213 time: 0.0275s
INFO:root:Epoch: 0040 val_loss: 1.456289 val_acc: 0.386364 val_f1: 0.386364
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.261880 train_acc: 0.528689 train_f1: 0.528689 time: 0.0252s
INFO:root:Epoch: 0050 val_loss: 1.414308 val_acc: 0.409091 val_f1: 0.409091
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.197237 train_acc: 0.590164 train_f1: 0.590164 time: 0.0293s
INFO:root:Epoch: 0060 val_loss: 1.386857 val_acc: 0.431818 val_f1: 0.431818
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.161590 train_acc: 0.766393 train_f1: 0.766393 time: 0.0293s
INFO:root:Epoch: 0070 val_loss: 1.364561 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.150846 train_acc: 0.778689 train_f1: 0.778689 time: 0.0275s
INFO:root:Epoch: 0080 val_loss: 1.341506 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.139958 train_acc: 0.786885 train_f1: 0.786885 time: 0.0301s
INFO:root:Epoch: 0090 val_loss: 1.337768 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.123151 train_acc: 0.790984 train_f1: 0.790984 time: 0.0330s
INFO:root:Epoch: 0100 val_loss: 1.317609 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.121496 train_acc: 0.790984 train_f1: 0.790984 time: 0.0417s
INFO:root:Epoch: 0110 val_loss: 1.317743 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.122126 train_acc: 0.790984 train_f1: 0.790984 time: 0.0319s
INFO:root:Epoch: 0120 val_loss: 1.315483 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.116068 train_acc: 0.790984 train_f1: 0.790984 time: 0.0310s
INFO:root:Epoch: 0130 val_loss: 1.311651 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.114894 train_acc: 0.790984 train_f1: 0.790984 time: 0.0332s
INFO:root:Epoch: 0140 val_loss: 1.308868 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.115164 train_acc: 0.790984 train_f1: 0.790984 time: 0.0342s
INFO:root:Epoch: 0150 val_loss: 1.304557 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.114516 train_acc: 0.790984 train_f1: 0.790984 time: 0.0362s
INFO:root:Epoch: 0160 val_loss: 1.300582 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.112593 train_acc: 0.790984 train_f1: 0.790984 time: 0.0309s
INFO:root:Epoch: 0170 val_loss: 1.298417 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.111648 train_acc: 0.790984 train_f1: 0.790984 time: 0.0321s
INFO:root:Epoch: 0180 val_loss: 1.293412 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.107159 train_acc: 0.790984 train_f1: 0.790984 time: 0.0350s
INFO:root:Epoch: 0190 val_loss: 1.291226 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 1.109500 train_acc: 0.790984 train_f1: 0.790984 time: 0.0348s
INFO:root:Epoch: 0200 val_loss: 1.291742 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 1.104700 train_acc: 0.790984 train_f1: 0.790984 time: 0.0332s
INFO:root:Epoch: 0210 val_loss: 1.290132 val_acc: 0.795455 val_f1: 0.795455
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 1.108497 train_acc: 0.786885 train_f1: 0.786885 time: 0.0301s
INFO:root:Epoch: 0220 val_loss: 1.287920 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 1.102900 train_acc: 0.790984 train_f1: 0.790984 time: 0.0342s
INFO:root:Epoch: 0230 val_loss: 1.285465 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 1.104296 train_acc: 0.790984 train_f1: 0.790984 time: 0.0411s
INFO:root:Epoch: 0240 val_loss: 1.283750 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 1.103178 train_acc: 0.790984 train_f1: 0.790984 time: 0.0350s
INFO:root:Epoch: 0250 val_loss: 1.281962 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0260 lr: [0.00025, 0.00025] train_loss: 1.102315 train_acc: 0.790984 train_f1: 0.790984 time: 0.0340s
INFO:root:Epoch: 0260 val_loss: 1.279578 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0270 lr: [0.00025, 0.00025] train_loss: 1.100134 train_acc: 0.790984 train_f1: 0.790984 time: 0.0324s
INFO:root:Epoch: 0270 val_loss: 1.278543 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0280 lr: [0.00025, 0.00025] train_loss: 1.098912 train_acc: 0.790984 train_f1: 0.790984 time: 0.0322s
INFO:root:Epoch: 0280 val_loss: 1.277526 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0290 lr: [0.00025, 0.00025] train_loss: 1.106770 train_acc: 0.782787 train_f1: 0.782787 time: 0.0306s
INFO:root:Epoch: 0290 val_loss: 1.275753 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0300 lr: [0.000125, 0.000125] train_loss: 1.097844 train_acc: 0.790984 train_f1: 0.790984 time: 0.0337s
INFO:root:Epoch: 0300 val_loss: 1.273332 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0310 lr: [0.000125, 0.000125] train_loss: 1.098123 train_acc: 0.790984 train_f1: 0.790984 time: 0.0297s
INFO:root:Epoch: 0310 val_loss: 1.272325 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0320 lr: [0.000125, 0.000125] train_loss: 1.097714 train_acc: 0.790984 train_f1: 0.790984 time: 0.0340s
INFO:root:Epoch: 0320 val_loss: 1.273103 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0330 lr: [0.000125, 0.000125] train_loss: 1.097133 train_acc: 0.790984 train_f1: 0.790984 time: 0.0313s
INFO:root:Epoch: 0330 val_loss: 1.272709 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0340 lr: [0.000125, 0.000125] train_loss: 1.095792 train_acc: 0.790984 train_f1: 0.790984 time: 0.0359s
INFO:root:Epoch: 0340 val_loss: 1.272960 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0350 lr: [0.000125, 0.000125] train_loss: 1.098913 train_acc: 0.790984 train_f1: 0.790984 time: 0.0332s
INFO:root:Epoch: 0350 val_loss: 1.272259 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0360 lr: [0.000125, 0.000125] train_loss: 1.096095 train_acc: 0.790984 train_f1: 0.790984 time: 0.0379s
INFO:root:Epoch: 0360 val_loss: 1.271659 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0370 lr: [0.000125, 0.000125] train_loss: 1.097977 train_acc: 0.790984 train_f1: 0.790984 time: 0.0337s
INFO:root:Epoch: 0370 val_loss: 1.271050 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0380 lr: [0.000125, 0.000125] train_loss: 1.095422 train_acc: 0.790984 train_f1: 0.790984 time: 0.0331s
INFO:root:Epoch: 0380 val_loss: 1.270220 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0390 lr: [0.000125, 0.000125] train_loss: 1.094656 train_acc: 0.790984 train_f1: 0.790984 time: 0.0333s
INFO:root:Epoch: 0390 val_loss: 1.269325 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0400 lr: [6.25e-05, 6.25e-05] train_loss: 1.097165 train_acc: 0.786885 train_f1: 0.786885 time: 0.0335s
INFO:root:Epoch: 0400 val_loss: 1.268369 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0410 lr: [6.25e-05, 6.25e-05] train_loss: 1.094291 train_acc: 0.790984 train_f1: 0.790984 time: 0.0310s
INFO:root:Epoch: 0410 val_loss: 1.267681 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0420 lr: [6.25e-05, 6.25e-05] train_loss: 1.093677 train_acc: 0.790984 train_f1: 0.790984 time: 0.0294s
INFO:root:Epoch: 0420 val_loss: 1.267241 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0430 lr: [6.25e-05, 6.25e-05] train_loss: 1.095157 train_acc: 0.790984 train_f1: 0.790984 time: 0.0336s
INFO:root:Epoch: 0430 val_loss: 1.266591 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0440 lr: [6.25e-05, 6.25e-05] train_loss: 1.093292 train_acc: 0.790984 train_f1: 0.790984 time: 0.0347s
INFO:root:Epoch: 0440 val_loss: 1.266201 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0450 lr: [6.25e-05, 6.25e-05] train_loss: 1.095256 train_acc: 0.790984 train_f1: 0.790984 time: 0.0321s
INFO:root:Epoch: 0450 val_loss: 1.266007 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0460 lr: [6.25e-05, 6.25e-05] train_loss: 1.093331 train_acc: 0.790984 train_f1: 0.790984 time: 0.0313s
INFO:root:Epoch: 0460 val_loss: 1.265641 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0470 lr: [6.25e-05, 6.25e-05] train_loss: 1.092838 train_acc: 0.790984 train_f1: 0.790984 time: 0.0351s
INFO:root:Epoch: 0470 val_loss: 1.264874 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0480 lr: [6.25e-05, 6.25e-05] train_loss: 1.091684 train_acc: 0.790984 train_f1: 0.790984 time: 0.0341s
INFO:root:Epoch: 0480 val_loss: 1.264448 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0490 lr: [6.25e-05, 6.25e-05] train_loss: 1.091920 train_acc: 0.790984 train_f1: 0.790984 time: 0.0387s
INFO:root:Epoch: 0490 val_loss: 1.263925 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0500 lr: [3.125e-05, 3.125e-05] train_loss: 1.091550 train_acc: 0.790984 train_f1: 0.790984 time: 0.0336s
INFO:root:Epoch: 0500 val_loss: 1.263519 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0510 lr: [3.125e-05, 3.125e-05] train_loss: 1.093974 train_acc: 0.790984 train_f1: 0.790984 time: 0.0307s
INFO:root:Epoch: 0510 val_loss: 1.263238 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0520 lr: [3.125e-05, 3.125e-05] train_loss: 1.092272 train_acc: 0.790984 train_f1: 0.790984 time: 0.0320s
INFO:root:Epoch: 0520 val_loss: 1.262951 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0530 lr: [3.125e-05, 3.125e-05] train_loss: 1.094021 train_acc: 0.790984 train_f1: 0.790984 time: 0.0350s
INFO:root:Epoch: 0530 val_loss: 1.262728 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0540 lr: [3.125e-05, 3.125e-05] train_loss: 1.091600 train_acc: 0.790984 train_f1: 0.790984 time: 0.0360s
INFO:root:Epoch: 0540 val_loss: 1.262408 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0550 lr: [3.125e-05, 3.125e-05] train_loss: 1.092848 train_acc: 0.786885 train_f1: 0.786885 time: 0.0331s
INFO:root:Epoch: 0550 val_loss: 1.262157 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0560 lr: [3.125e-05, 3.125e-05] train_loss: 1.092233 train_acc: 0.790984 train_f1: 0.790984 time: 0.0331s
INFO:root:Epoch: 0560 val_loss: 1.261883 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0570 lr: [3.125e-05, 3.125e-05] train_loss: 1.090841 train_acc: 0.790984 train_f1: 0.790984 time: 0.0307s
INFO:root:Epoch: 0570 val_loss: 1.261816 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0580 lr: [3.125e-05, 3.125e-05] train_loss: 1.090622 train_acc: 0.790984 train_f1: 0.790984 time: 0.0326s
INFO:root:Epoch: 0580 val_loss: 1.261698 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0590 lr: [3.125e-05, 3.125e-05] train_loss: 1.093599 train_acc: 0.790984 train_f1: 0.790984 time: 0.0332s
INFO:root:Epoch: 0590 val_loss: 1.261621 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Epoch: 0600 lr: [1.5625e-05, 1.5625e-05] train_loss: 1.091731 train_acc: 0.790984 train_f1: 0.790984 time: 0.0296s
INFO:root:Epoch: 0600 val_loss: 1.261605 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 22.1306s
INFO:root:Val set results: val_loss: 1.317609 val_acc: 0.818182 val_f1: 0.818182
INFO:root:Test set results: test_loss: 0.936328 test_acc: 0.886364 test_f1: 0.886364
