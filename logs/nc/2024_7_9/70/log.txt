INFO:root:Using: cuda:1
INFO:root:Using seed 10086.
INFO:root:Dataset: texas
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(
      in_features=1703, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
      (dropout): Dropout(p=0.3, inplace=False)
      (E_linear): Linear(in_features=1703, out_features=32, bias=False)
    )
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (3): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (4): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (5): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (act): BAct(c=tensor([1.], device='cuda:1'), act=<function relu at 0x7fc97eb336d0>)
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (1): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (2): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (3): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (4): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
            (5): BLinear(
              in_features=32, out_features=32, c=tensor([1.], device='cuda:1'), use_bias=1, act=None, dropout_rate=0.3
              (dropout): Dropout(p=0.3, inplace=False)
              (E_linear): Linear(in_features=32, out_features=32, bias=False)
            )
          )
          (act): BAct(c=tensor([1.], device='cuda:1'), act=<function relu at 0x7fc97eb336d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 67781
INFO:root:Epoch: 0002 lr: [0.001, 0.001] train_loss: 1.589988 train_acc: 0.590164 train_f1: 0.590164 time: 0.1346s
INFO:root:Epoch: 0002 val_loss: 1.561510 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0004 lr: [0.001, 0.001] train_loss: 1.552206 train_acc: 0.590164 train_f1: 0.590164 time: 0.1341s
INFO:root:Epoch: 0004 val_loss: 1.515087 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0006 lr: [0.001, 0.001] train_loss: 1.516298 train_acc: 0.590164 train_f1: 0.590164 time: 0.1314s
INFO:root:Epoch: 0006 val_loss: 1.470236 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0008 lr: [0.001, 0.001] train_loss: 1.481217 train_acc: 0.590164 train_f1: 0.590164 time: 0.1320s
INFO:root:Epoch: 0008 val_loss: 1.427002 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.448313 train_acc: 0.590164 train_f1: 0.590164 time: 0.1402s
INFO:root:Epoch: 0010 val_loss: 1.385514 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0012 lr: [0.001, 0.001] train_loss: 1.417916 train_acc: 0.590164 train_f1: 0.590164 time: 0.1337s
INFO:root:Epoch: 0012 val_loss: 1.345902 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0014 lr: [0.001, 0.001] train_loss: 1.388542 train_acc: 0.590164 train_f1: 0.590164 time: 0.1322s
INFO:root:Epoch: 0014 val_loss: 1.308245 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0016 lr: [0.001, 0.001] train_loss: 1.361588 train_acc: 0.590164 train_f1: 0.590164 time: 0.1335s
INFO:root:Epoch: 0016 val_loss: 1.272583 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0018 lr: [0.001, 0.001] train_loss: 1.336650 train_acc: 0.590164 train_f1: 0.590164 time: 0.1334s
INFO:root:Epoch: 0018 val_loss: 1.239000 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.313765 train_acc: 0.590164 train_f1: 0.590164 time: 0.1411s
INFO:root:Epoch: 0020 val_loss: 1.207560 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0022 lr: [0.001, 0.001] train_loss: 1.293238 train_acc: 0.590164 train_f1: 0.590164 time: 0.1317s
INFO:root:Epoch: 0022 val_loss: 1.178331 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0024 lr: [0.001, 0.001] train_loss: 1.275323 train_acc: 0.590164 train_f1: 0.590164 time: 0.1489s
INFO:root:Epoch: 0024 val_loss: 1.151351 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0026 lr: [0.001, 0.001] train_loss: 1.259079 train_acc: 0.590164 train_f1: 0.590164 time: 0.1356s
INFO:root:Epoch: 0026 val_loss: 1.126741 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0028 lr: [0.001, 0.001] train_loss: 1.245105 train_acc: 0.590164 train_f1: 0.590164 time: 0.1370s
INFO:root:Epoch: 0028 val_loss: 1.104556 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.234026 train_acc: 0.590164 train_f1: 0.590164 time: 0.1414s
INFO:root:Epoch: 0030 val_loss: 1.084877 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0032 lr: [0.001, 0.001] train_loss: 1.224890 train_acc: 0.590164 train_f1: 0.590164 time: 0.1323s
INFO:root:Epoch: 0032 val_loss: 1.067747 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0034 lr: [0.001, 0.001] train_loss: 1.217885 train_acc: 0.590164 train_f1: 0.590164 time: 0.1322s
INFO:root:Epoch: 0034 val_loss: 1.053252 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0036 lr: [0.001, 0.001] train_loss: 1.212838 train_acc: 0.590164 train_f1: 0.590164 time: 0.1368s
INFO:root:Epoch: 0036 val_loss: 1.041171 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0038 lr: [0.001, 0.001] train_loss: 1.208844 train_acc: 0.590164 train_f1: 0.590164 time: 0.1463s
INFO:root:Epoch: 0038 val_loss: 1.031366 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.205837 train_acc: 0.590164 train_f1: 0.590164 time: 0.1393s
INFO:root:Epoch: 0040 val_loss: 1.023493 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0042 lr: [0.001, 0.001] train_loss: 1.203275 train_acc: 0.590164 train_f1: 0.590164 time: 0.1321s
INFO:root:Epoch: 0042 val_loss: 1.017199 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0044 lr: [0.001, 0.001] train_loss: 1.200012 train_acc: 0.590164 train_f1: 0.590164 time: 0.1354s
INFO:root:Epoch: 0044 val_loss: 1.012355 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0046 lr: [0.001, 0.001] train_loss: 1.196643 train_acc: 0.590164 train_f1: 0.590164 time: 0.1320s
INFO:root:Epoch: 0046 val_loss: 1.008890 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0048 lr: [0.001, 0.001] train_loss: 1.191381 train_acc: 0.590164 train_f1: 0.590164 time: 0.1401s
INFO:root:Epoch: 0048 val_loss: 1.006584 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.187502 train_acc: 0.590164 train_f1: 0.590164 time: 0.1408s
INFO:root:Epoch: 0050 val_loss: 1.005292 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0052 lr: [0.001, 0.001] train_loss: 1.183645 train_acc: 0.590164 train_f1: 0.590164 time: 0.1318s
INFO:root:Epoch: 0052 val_loss: 1.004612 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0054 lr: [0.001, 0.001] train_loss: 1.179462 train_acc: 0.590164 train_f1: 0.590164 time: 0.1348s
INFO:root:Epoch: 0054 val_loss: 1.004023 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0056 lr: [0.001, 0.001] train_loss: 1.176343 train_acc: 0.590164 train_f1: 0.590164 time: 0.1311s
INFO:root:Epoch: 0056 val_loss: 1.003156 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0058 lr: [0.001, 0.001] train_loss: 1.172061 train_acc: 0.590164 train_f1: 0.590164 time: 0.1453s
INFO:root:Epoch: 0058 val_loss: 1.001800 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.167382 train_acc: 0.590164 train_f1: 0.590164 time: 0.1412s
INFO:root:Epoch: 0060 val_loss: 0.999761 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0062 lr: [0.001, 0.001] train_loss: 1.162234 train_acc: 0.590164 train_f1: 0.590164 time: 0.1318s
INFO:root:Epoch: 0062 val_loss: 0.997138 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0064 lr: [0.001, 0.001] train_loss: 1.156991 train_acc: 0.590164 train_f1: 0.590164 time: 0.1308s
INFO:root:Epoch: 0064 val_loss: 0.994062 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0066 lr: [0.001, 0.001] train_loss: 1.151274 train_acc: 0.590164 train_f1: 0.590164 time: 0.1323s
INFO:root:Epoch: 0066 val_loss: 0.990769 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0068 lr: [0.001, 0.001] train_loss: 1.144527 train_acc: 0.590164 train_f1: 0.590164 time: 0.1390s
INFO:root:Epoch: 0068 val_loss: 0.987074 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.137957 train_acc: 0.590164 train_f1: 0.590164 time: 0.1395s
INFO:root:Epoch: 0070 val_loss: 0.983172 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0072 lr: [0.001, 0.001] train_loss: 1.133190 train_acc: 0.590164 train_f1: 0.590164 time: 0.1313s
INFO:root:Epoch: 0072 val_loss: 0.979205 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0074 lr: [0.001, 0.001] train_loss: 1.126654 train_acc: 0.590164 train_f1: 0.590164 time: 0.1325s
INFO:root:Epoch: 0074 val_loss: 0.975267 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0076 lr: [0.001, 0.001] train_loss: 1.120232 train_acc: 0.590164 train_f1: 0.590164 time: 0.1320s
INFO:root:Epoch: 0076 val_loss: 0.970715 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0078 lr: [0.001, 0.001] train_loss: 1.111171 train_acc: 0.590164 train_f1: 0.590164 time: 0.1477s
INFO:root:Epoch: 0078 val_loss: 0.965785 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.105415 train_acc: 0.590164 train_f1: 0.590164 time: 0.1335s
INFO:root:Epoch: 0080 val_loss: 0.960302 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0082 lr: [0.001, 0.001] train_loss: 1.097958 train_acc: 0.590164 train_f1: 0.590164 time: 0.1341s
INFO:root:Epoch: 0082 val_loss: 0.954510 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0084 lr: [0.001, 0.001] train_loss: 1.091023 train_acc: 0.590164 train_f1: 0.590164 time: 0.1316s
INFO:root:Epoch: 0084 val_loss: 0.948707 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0086 lr: [0.001, 0.001] train_loss: 1.083110 train_acc: 0.590164 train_f1: 0.590164 time: 0.1315s
INFO:root:Epoch: 0086 val_loss: 0.942979 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0088 lr: [0.001, 0.001] train_loss: 1.077223 train_acc: 0.590164 train_f1: 0.590164 time: 0.1395s
INFO:root:Epoch: 0088 val_loss: 0.937139 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.069831 train_acc: 0.590164 train_f1: 0.590164 time: 0.1328s
INFO:root:Epoch: 0090 val_loss: 0.931280 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0092 lr: [0.001, 0.001] train_loss: 1.063249 train_acc: 0.590164 train_f1: 0.590164 time: 0.1339s
INFO:root:Epoch: 0092 val_loss: 0.925379 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0094 lr: [0.001, 0.001] train_loss: 1.057209 train_acc: 0.590164 train_f1: 0.590164 time: 0.1319s
INFO:root:Epoch: 0094 val_loss: 0.919590 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0096 lr: [0.001, 0.001] train_loss: 1.047843 train_acc: 0.590164 train_f1: 0.590164 time: 0.1359s
INFO:root:Epoch: 0096 val_loss: 0.914484 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0098 lr: [0.001, 0.001] train_loss: 1.041919 train_acc: 0.590164 train_f1: 0.590164 time: 0.1405s
INFO:root:Epoch: 0098 val_loss: 0.909084 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 1.032932 train_acc: 0.590164 train_f1: 0.590164 time: 0.1318s
INFO:root:Epoch: 0100 val_loss: 0.903695 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0102 lr: [0.001, 0.001] train_loss: 1.026255 train_acc: 0.590164 train_f1: 0.590164 time: 0.1317s
INFO:root:Epoch: 0102 val_loss: 0.898400 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0104 lr: [0.001, 0.001] train_loss: 1.018783 train_acc: 0.590164 train_f1: 0.590164 time: 0.1329s
INFO:root:Epoch: 0104 val_loss: 0.893309 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0106 lr: [0.001, 0.001] train_loss: 1.012782 train_acc: 0.590164 train_f1: 0.590164 time: 0.1397s
INFO:root:Epoch: 0106 val_loss: 0.887804 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0108 lr: [0.001, 0.001] train_loss: 1.005671 train_acc: 0.590164 train_f1: 0.590164 time: 0.1427s
INFO:root:Epoch: 0108 val_loss: 0.883181 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.997053 train_acc: 0.590164 train_f1: 0.590164 time: 0.1391s
INFO:root:Epoch: 0110 val_loss: 0.877981 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0112 lr: [0.001, 0.001] train_loss: 0.989982 train_acc: 0.590164 train_f1: 0.590164 time: 0.1324s
INFO:root:Epoch: 0112 val_loss: 0.872252 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0114 lr: [0.001, 0.001] train_loss: 0.983626 train_acc: 0.590164 train_f1: 0.590164 time: 0.1327s
INFO:root:Epoch: 0114 val_loss: 0.866059 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0116 lr: [0.001, 0.001] train_loss: 0.976355 train_acc: 0.590164 train_f1: 0.590164 time: 0.1379s
INFO:root:Epoch: 0116 val_loss: 0.860144 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0118 lr: [0.001, 0.001] train_loss: 0.971024 train_acc: 0.590164 train_f1: 0.590164 time: 0.1414s
INFO:root:Epoch: 0118 val_loss: 0.854148 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.963413 train_acc: 0.590164 train_f1: 0.590164 time: 0.1342s
INFO:root:Epoch: 0120 val_loss: 0.848225 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0122 lr: [0.001, 0.001] train_loss: 0.956988 train_acc: 0.590164 train_f1: 0.590164 time: 0.1319s
INFO:root:Epoch: 0122 val_loss: 0.842755 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0124 lr: [0.001, 0.001] train_loss: 0.950231 train_acc: 0.590164 train_f1: 0.590164 time: 0.1313s
INFO:root:Epoch: 0124 val_loss: 0.837488 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0126 lr: [0.001, 0.001] train_loss: 0.945731 train_acc: 0.590164 train_f1: 0.590164 time: 0.1413s
INFO:root:Epoch: 0126 val_loss: 0.832626 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0128 lr: [0.001, 0.001] train_loss: 0.937936 train_acc: 0.590164 train_f1: 0.590164 time: 0.1361s
INFO:root:Epoch: 0128 val_loss: 0.827385 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.931582 train_acc: 0.590164 train_f1: 0.590164 time: 0.1344s
INFO:root:Epoch: 0130 val_loss: 0.822128 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0132 lr: [0.001, 0.001] train_loss: 0.929551 train_acc: 0.590164 train_f1: 0.590164 time: 0.1311s
INFO:root:Epoch: 0132 val_loss: 0.817193 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0134 lr: [0.001, 0.001] train_loss: 0.919667 train_acc: 0.590164 train_f1: 0.590164 time: 0.1329s
INFO:root:Epoch: 0134 val_loss: 0.812692 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0136 lr: [0.001, 0.001] train_loss: 0.919906 train_acc: 0.590164 train_f1: 0.590164 time: 0.1489s
INFO:root:Epoch: 0136 val_loss: 0.808719 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0138 lr: [0.001, 0.001] train_loss: 0.908178 train_acc: 0.590164 train_f1: 0.590164 time: 0.1442s
INFO:root:Epoch: 0138 val_loss: 0.803309 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.901588 train_acc: 0.590164 train_f1: 0.590164 time: 0.1307s
INFO:root:Epoch: 0140 val_loss: 0.797059 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0142 lr: [0.001, 0.001] train_loss: 0.896942 train_acc: 0.590164 train_f1: 0.590164 time: 0.1346s
INFO:root:Epoch: 0142 val_loss: 0.792481 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0144 lr: [0.001, 0.001] train_loss: 0.893073 train_acc: 0.590164 train_f1: 0.590164 time: 0.1318s
INFO:root:Epoch: 0144 val_loss: 0.787581 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0146 lr: [0.001, 0.001] train_loss: 0.886573 train_acc: 0.590164 train_f1: 0.590164 time: 0.1457s
INFO:root:Epoch: 0146 val_loss: 0.781794 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0148 lr: [0.001, 0.001] train_loss: 0.882142 train_acc: 0.590164 train_f1: 0.590164 time: 0.1351s
INFO:root:Epoch: 0148 val_loss: 0.778750 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 0.876033 train_acc: 0.590164 train_f1: 0.590164 time: 0.1342s
INFO:root:Epoch: 0150 val_loss: 0.773719 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0152 lr: [0.001, 0.001] train_loss: 0.871298 train_acc: 0.590164 train_f1: 0.590164 time: 0.1337s
INFO:root:Epoch: 0152 val_loss: 0.767670 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0154 lr: [0.001, 0.001] train_loss: 0.867628 train_acc: 0.590164 train_f1: 0.590164 time: 0.1356s
INFO:root:Epoch: 0154 val_loss: 0.763599 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0156 lr: [0.001, 0.001] train_loss: 0.862431 train_acc: 0.590164 train_f1: 0.590164 time: 0.1404s
INFO:root:Epoch: 0156 val_loss: 0.759196 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0158 lr: [0.001, 0.001] train_loss: 0.859305 train_acc: 0.590164 train_f1: 0.590164 time: 0.1328s
INFO:root:Epoch: 0158 val_loss: 0.755948 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 0.855421 train_acc: 0.590164 train_f1: 0.590164 time: 0.1339s
INFO:root:Epoch: 0160 val_loss: 0.769528 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0162 lr: [0.001, 0.001] train_loss: 0.857386 train_acc: 0.590164 train_f1: 0.590164 time: 0.1328s
INFO:root:Epoch: 0162 val_loss: 0.756335 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0164 lr: [0.001, 0.001] train_loss: 0.848676 train_acc: 0.590164 train_f1: 0.590164 time: 0.1350s
INFO:root:Epoch: 0164 val_loss: 0.733585 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0166 lr: [0.001, 0.001] train_loss: 0.845702 train_acc: 0.590164 train_f1: 0.590164 time: 0.1422s
INFO:root:Epoch: 0166 val_loss: 0.750463 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0168 lr: [0.001, 0.001] train_loss: 0.842033 train_acc: 0.590164 train_f1: 0.590164 time: 0.1349s
INFO:root:Epoch: 0168 val_loss: 0.731996 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 0.841484 train_acc: 0.590164 train_f1: 0.590164 time: 0.2006s
INFO:root:Epoch: 0170 val_loss: 0.744826 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0172 lr: [0.001, 0.001] train_loss: 0.835542 train_acc: 0.590164 train_f1: 0.590164 time: 0.1332s
INFO:root:Epoch: 0172 val_loss: 0.727552 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0174 lr: [0.001, 0.001] train_loss: 0.834276 train_acc: 0.590164 train_f1: 0.590164 time: 0.1438s
INFO:root:Epoch: 0174 val_loss: 0.733919 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0176 lr: [0.001, 0.001] train_loss: 0.832828 train_acc: 0.590164 train_f1: 0.590164 time: 0.1418s
INFO:root:Epoch: 0176 val_loss: 0.728347 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0178 lr: [0.001, 0.001] train_loss: 0.829131 train_acc: 0.590164 train_f1: 0.590164 time: 0.1369s
INFO:root:Epoch: 0178 val_loss: 0.720753 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 0.825946 train_acc: 0.590164 train_f1: 0.590164 time: 0.1338s
INFO:root:Epoch: 0180 val_loss: 0.728625 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0182 lr: [0.001, 0.001] train_loss: 0.821636 train_acc: 0.590164 train_f1: 0.590164 time: 0.1358s
INFO:root:Epoch: 0182 val_loss: 0.715573 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0184 lr: [0.001, 0.001] train_loss: 0.819395 train_acc: 0.590164 train_f1: 0.590164 time: 0.1358s
INFO:root:Epoch: 0184 val_loss: 0.719249 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0186 lr: [0.001, 0.001] train_loss: 0.818953 train_acc: 0.590164 train_f1: 0.590164 time: 0.1420s
INFO:root:Epoch: 0186 val_loss: 0.713562 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0188 lr: [0.001, 0.001] train_loss: 0.814607 train_acc: 0.590164 train_f1: 0.590164 time: 0.1314s
INFO:root:Epoch: 0188 val_loss: 0.709237 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 0.814540 train_acc: 0.590164 train_f1: 0.590164 time: 0.1331s
INFO:root:Epoch: 0190 val_loss: 0.712766 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0192 lr: [0.001, 0.001] train_loss: 0.808825 train_acc: 0.590164 train_f1: 0.590164 time: 0.1357s
INFO:root:Epoch: 0192 val_loss: 0.701086 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0194 lr: [0.001, 0.001] train_loss: 0.806194 train_acc: 0.590164 train_f1: 0.590164 time: 0.1418s
INFO:root:Epoch: 0194 val_loss: 0.706622 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0196 lr: [0.001, 0.001] train_loss: 0.807565 train_acc: 0.590164 train_f1: 0.590164 time: 0.1408s
INFO:root:Epoch: 0196 val_loss: 0.693714 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0198 lr: [0.001, 0.001] train_loss: 0.801612 train_acc: 0.590164 train_f1: 0.590164 time: 0.1329s
INFO:root:Epoch: 0198 val_loss: 0.702281 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0200 lr: [0.001, 0.001] train_loss: 0.798584 train_acc: 0.590164 train_f1: 0.590164 time: 0.1436s
INFO:root:Epoch: 0200 val_loss: 0.690478 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0202 lr: [0.001, 0.001] train_loss: 0.798435 train_acc: 0.590164 train_f1: 0.590164 time: 0.1324s
INFO:root:Epoch: 0202 val_loss: 0.694025 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0204 lr: [0.001, 0.001] train_loss: 0.795409 train_acc: 0.590164 train_f1: 0.590164 time: 0.1444s
INFO:root:Epoch: 0204 val_loss: 0.688980 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0206 lr: [0.001, 0.001] train_loss: 0.792339 train_acc: 0.590164 train_f1: 0.590164 time: 0.1328s
INFO:root:Epoch: 0206 val_loss: 0.685795 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0208 lr: [0.001, 0.001] train_loss: 0.789892 train_acc: 0.590164 train_f1: 0.590164 time: 0.1331s
INFO:root:Epoch: 0208 val_loss: 0.686347 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0210 lr: [0.001, 0.001] train_loss: 0.788380 train_acc: 0.590164 train_f1: 0.590164 time: 0.1323s
INFO:root:Epoch: 0210 val_loss: 0.678073 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0212 lr: [0.001, 0.001] train_loss: 0.784842 train_acc: 0.590164 train_f1: 0.590164 time: 0.1382s
INFO:root:Epoch: 0212 val_loss: 0.683669 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0214 lr: [0.001, 0.001] train_loss: 0.783914 train_acc: 0.590164 train_f1: 0.590164 time: 0.1406s
INFO:root:Epoch: 0214 val_loss: 0.676508 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0216 lr: [0.001, 0.001] train_loss: 0.781264 train_acc: 0.590164 train_f1: 0.590164 time: 0.1339s
INFO:root:Epoch: 0216 val_loss: 0.673605 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0218 lr: [0.001, 0.001] train_loss: 0.780749 train_acc: 0.590164 train_f1: 0.590164 time: 0.1408s
INFO:root:Epoch: 0218 val_loss: 0.680600 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0220 lr: [0.001, 0.001] train_loss: 0.777535 train_acc: 0.590164 train_f1: 0.590164 time: 0.1338s
INFO:root:Epoch: 0220 val_loss: 0.669140 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0222 lr: [0.001, 0.001] train_loss: 0.775916 train_acc: 0.590164 train_f1: 0.590164 time: 0.1399s
INFO:root:Epoch: 0222 val_loss: 0.670348 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0224 lr: [0.001, 0.001] train_loss: 0.774435 train_acc: 0.590164 train_f1: 0.590164 time: 0.1389s
INFO:root:Epoch: 0224 val_loss: 0.676631 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0226 lr: [0.001, 0.001] train_loss: 0.772264 train_acc: 0.590164 train_f1: 0.590164 time: 0.1355s
INFO:root:Epoch: 0226 val_loss: 0.664089 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0228 lr: [0.001, 0.001] train_loss: 0.770921 train_acc: 0.590164 train_f1: 0.590164 time: 0.1326s
INFO:root:Epoch: 0228 val_loss: 0.668408 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0230 lr: [0.001, 0.001] train_loss: 0.768992 train_acc: 0.590164 train_f1: 0.590164 time: 0.1324s
INFO:root:Epoch: 0230 val_loss: 0.663440 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0232 lr: [0.001, 0.001] train_loss: 0.766772 train_acc: 0.590164 train_f1: 0.590164 time: 0.1367s
INFO:root:Epoch: 0232 val_loss: 0.665931 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0234 lr: [0.001, 0.001] train_loss: 0.765642 train_acc: 0.590164 train_f1: 0.590164 time: 0.1396s
INFO:root:Epoch: 0234 val_loss: 0.661126 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0236 lr: [0.001, 0.001] train_loss: 0.763424 train_acc: 0.590164 train_f1: 0.590164 time: 0.1320s
INFO:root:Epoch: 0236 val_loss: 0.661147 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0238 lr: [0.001, 0.001] train_loss: 0.761694 train_acc: 0.590164 train_f1: 0.590164 time: 0.1327s
INFO:root:Epoch: 0238 val_loss: 0.661166 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0240 lr: [0.001, 0.001] train_loss: 0.759865 train_acc: 0.590164 train_f1: 0.590164 time: 0.1311s
INFO:root:Epoch: 0240 val_loss: 0.654940 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0242 lr: [0.001, 0.001] train_loss: 0.759468 train_acc: 0.590164 train_f1: 0.590164 time: 0.1427s
INFO:root:Epoch: 0242 val_loss: 0.658700 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0244 lr: [0.001, 0.001] train_loss: 0.757018 train_acc: 0.590164 train_f1: 0.590164 time: 0.1409s
INFO:root:Epoch: 0244 val_loss: 0.657307 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0246 lr: [0.001, 0.001] train_loss: 0.756202 train_acc: 0.590164 train_f1: 0.590164 time: 0.1348s
INFO:root:Epoch: 0246 val_loss: 0.654442 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0248 lr: [0.001, 0.001] train_loss: 0.753890 train_acc: 0.590164 train_f1: 0.590164 time: 0.1338s
INFO:root:Epoch: 0248 val_loss: 0.657820 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0250 lr: [0.001, 0.001] train_loss: 0.752639 train_acc: 0.590164 train_f1: 0.590164 time: 0.1328s
INFO:root:Epoch: 0250 val_loss: 0.652588 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0252 lr: [0.001, 0.001] train_loss: 0.751550 train_acc: 0.590164 train_f1: 0.590164 time: 0.1478s
INFO:root:Epoch: 0252 val_loss: 0.652903 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0254 lr: [0.001, 0.001] train_loss: 0.750906 train_acc: 0.590164 train_f1: 0.590164 time: 0.1382s
INFO:root:Epoch: 0254 val_loss: 0.656045 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0256 lr: [0.001, 0.001] train_loss: 0.748954 train_acc: 0.590164 train_f1: 0.590164 time: 0.1323s
INFO:root:Epoch: 0256 val_loss: 0.648222 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0258 lr: [0.001, 0.001] train_loss: 0.746784 train_acc: 0.590164 train_f1: 0.590164 time: 0.1337s
INFO:root:Epoch: 0258 val_loss: 0.642332 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0260 lr: [0.001, 0.001] train_loss: 0.745460 train_acc: 0.590164 train_f1: 0.590164 time: 0.1332s
INFO:root:Epoch: 0260 val_loss: 0.644706 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0262 lr: [0.001, 0.001] train_loss: 0.744297 train_acc: 0.590164 train_f1: 0.590164 time: 0.1402s
INFO:root:Epoch: 0262 val_loss: 0.645368 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0264 lr: [0.001, 0.001] train_loss: 0.742474 train_acc: 0.590164 train_f1: 0.590164 time: 0.1385s
INFO:root:Epoch: 0264 val_loss: 0.638191 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0266 lr: [0.001, 0.001] train_loss: 0.742605 train_acc: 0.590164 train_f1: 0.590164 time: 0.1334s
INFO:root:Epoch: 0266 val_loss: 0.639091 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0268 lr: [0.001, 0.001] train_loss: 0.739835 train_acc: 0.590164 train_f1: 0.590164 time: 0.1337s
INFO:root:Epoch: 0268 val_loss: 0.645202 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0270 lr: [0.001, 0.001] train_loss: 0.738595 train_acc: 0.590164 train_f1: 0.590164 time: 0.1329s
INFO:root:Epoch: 0270 val_loss: 0.640402 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0272 lr: [0.001, 0.001] train_loss: 0.739084 train_acc: 0.590164 train_f1: 0.590164 time: 0.1396s
INFO:root:Epoch: 0272 val_loss: 0.639575 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0274 lr: [0.001, 0.001] train_loss: 0.735636 train_acc: 0.590164 train_f1: 0.590164 time: 0.1320s
INFO:root:Epoch: 0274 val_loss: 0.642130 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0276 lr: [0.001, 0.001] train_loss: 0.734371 train_acc: 0.590164 train_f1: 0.590164 time: 0.1354s
INFO:root:Epoch: 0276 val_loss: 0.636850 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0278 lr: [0.001, 0.001] train_loss: 0.734733 train_acc: 0.590164 train_f1: 0.590164 time: 0.1317s
INFO:root:Epoch: 0278 val_loss: 0.635645 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0280 lr: [0.001, 0.001] train_loss: 0.732440 train_acc: 0.590164 train_f1: 0.590164 time: 0.1363s
INFO:root:Epoch: 0280 val_loss: 0.636942 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0282 lr: [0.001, 0.001] train_loss: 0.731123 train_acc: 0.590164 train_f1: 0.590164 time: 0.1414s
INFO:root:Epoch: 0282 val_loss: 0.634633 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0284 lr: [0.001, 0.001] train_loss: 0.734119 train_acc: 0.590164 train_f1: 0.590164 time: 0.1319s
INFO:root:Epoch: 0284 val_loss: 0.633673 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0286 lr: [0.001, 0.001] train_loss: 0.728219 train_acc: 0.590164 train_f1: 0.590164 time: 0.1387s
INFO:root:Epoch: 0286 val_loss: 0.636230 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0288 lr: [0.001, 0.001] train_loss: 0.727728 train_acc: 0.590164 train_f1: 0.590164 time: 0.1323s
INFO:root:Epoch: 0288 val_loss: 0.634654 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0290 lr: [0.001, 0.001] train_loss: 0.725823 train_acc: 0.590164 train_f1: 0.590164 time: 0.1420s
INFO:root:Epoch: 0290 val_loss: 0.630927 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0292 lr: [0.001, 0.001] train_loss: 0.724782 train_acc: 0.590164 train_f1: 0.590164 time: 0.1465s
INFO:root:Epoch: 0292 val_loss: 0.629501 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0294 lr: [0.001, 0.001] train_loss: 0.723817 train_acc: 0.590164 train_f1: 0.590164 time: 0.1327s
INFO:root:Epoch: 0294 val_loss: 0.632622 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0296 lr: [0.001, 0.001] train_loss: 0.722126 train_acc: 0.590164 train_f1: 0.590164 time: 0.1333s
INFO:root:Epoch: 0296 val_loss: 0.632272 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0298 lr: [0.001, 0.001] train_loss: 0.720929 train_acc: 0.590164 train_f1: 0.590164 time: 0.1327s
INFO:root:Epoch: 0298 val_loss: 0.627350 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0300 lr: [0.001, 0.001] train_loss: 0.721673 train_acc: 0.618852 train_f1: 0.618852 time: 0.1445s
INFO:root:Epoch: 0300 val_loss: 0.624020 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0302 lr: [0.001, 0.001] train_loss: 0.718851 train_acc: 0.590164 train_f1: 0.590164 time: 0.1361s
INFO:root:Epoch: 0302 val_loss: 0.627183 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0304 lr: [0.001, 0.001] train_loss: 0.718032 train_acc: 0.590164 train_f1: 0.590164 time: 0.1331s
INFO:root:Epoch: 0304 val_loss: 0.629224 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0306 lr: [0.001, 0.001] train_loss: 0.716345 train_acc: 0.590164 train_f1: 0.590164 time: 0.1380s
INFO:root:Epoch: 0306 val_loss: 0.621854 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0308 lr: [0.001, 0.001] train_loss: 0.716102 train_acc: 0.590164 train_f1: 0.590164 time: 0.1316s
INFO:root:Epoch: 0308 val_loss: 0.623034 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0310 lr: [0.001, 0.001] train_loss: 0.714543 train_acc: 0.590164 train_f1: 0.590164 time: 0.1380s
INFO:root:Epoch: 0310 val_loss: 0.626420 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0312 lr: [0.001, 0.001] train_loss: 0.712769 train_acc: 0.590164 train_f1: 0.590164 time: 0.1395s
INFO:root:Epoch: 0312 val_loss: 0.619158 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0314 lr: [0.001, 0.001] train_loss: 0.712605 train_acc: 0.590164 train_f1: 0.590164 time: 0.1339s
INFO:root:Epoch: 0314 val_loss: 0.622889 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0316 lr: [0.001, 0.001] train_loss: 0.711408 train_acc: 0.590164 train_f1: 0.590164 time: 0.1317s
INFO:root:Epoch: 0316 val_loss: 0.625550 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0318 lr: [0.001, 0.001] train_loss: 0.709682 train_acc: 0.590164 train_f1: 0.590164 time: 0.1321s
INFO:root:Epoch: 0318 val_loss: 0.620705 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0320 lr: [0.001, 0.001] train_loss: 0.710018 train_acc: 0.590164 train_f1: 0.590164 time: 0.1457s
INFO:root:Epoch: 0320 val_loss: 0.625879 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0322 lr: [0.001, 0.001] train_loss: 0.710682 train_acc: 0.590164 train_f1: 0.590164 time: 0.1414s
INFO:root:Epoch: 0322 val_loss: 0.622228 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0324 lr: [0.001, 0.001] train_loss: 0.706063 train_acc: 0.590164 train_f1: 0.590164 time: 0.1363s
INFO:root:Epoch: 0324 val_loss: 0.619587 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0326 lr: [0.001, 0.001] train_loss: 0.708342 train_acc: 0.590164 train_f1: 0.590164 time: 0.1348s
INFO:root:Epoch: 0326 val_loss: 0.618485 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0328 lr: [0.001, 0.001] train_loss: 0.703573 train_acc: 0.590164 train_f1: 0.590164 time: 0.1325s
INFO:root:Epoch: 0328 val_loss: 0.612138 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0330 lr: [0.001, 0.001] train_loss: 0.703424 train_acc: 0.590164 train_f1: 0.590164 time: 0.1422s
INFO:root:Epoch: 0330 val_loss: 0.611909 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Epoch: 0332 lr: [0.001, 0.001] train_loss: 0.701824 train_acc: 0.590164 train_f1: 0.590164 time: 0.1412s
INFO:root:Epoch: 0332 val_loss: 0.613659 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Epoch: 0334 lr: [0.001, 0.001] train_loss: 0.700126 train_acc: 0.590164 train_f1: 0.590164 time: 0.1346s
INFO:root:Epoch: 0334 val_loss: 0.609536 val_acc: 0.681818 val_f1: 0.681818
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 50.0458s
INFO:root:Val set results: val_loss: 0.629224 val_acc: 0.727273 val_f1: 0.727273
INFO:root:Test set results: test_loss: 0.664094 test_acc: 0.704545 test_f1: 0.704545
