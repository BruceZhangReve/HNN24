INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: wisconsin
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f152901f6d0>)
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f152901f6d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 143237
INFO:root:Epoch: 0005 lr: [0.0005, 0.0005] train_loss: 1.946709 train_acc: 0.576433 train_f1: 0.576433 time: 0.1928s
INFO:root:Epoch: 0005 val_loss: 1.949322 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0010 lr: [0.0005, 0.0005] train_loss: 1.878187 train_acc: 0.576433 train_f1: 0.576433 time: 0.1899s
INFO:root:Epoch: 0010 val_loss: 1.896880 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0015 lr: [0.0005, 0.0005] train_loss: 1.807185 train_acc: 0.576433 train_f1: 0.576433 time: 0.2007s
INFO:root:Epoch: 0015 val_loss: 1.842367 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0020 lr: [0.0005, 0.0005] train_loss: 1.732910 train_acc: 0.576433 train_f1: 0.576433 time: 0.1944s
INFO:root:Epoch: 0020 val_loss: 1.785138 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0025 lr: [0.0005, 0.0005] train_loss: 1.653765 train_acc: 0.576433 train_f1: 0.576433 time: 0.1929s
INFO:root:Epoch: 0025 val_loss: 1.723889 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0030 lr: [0.0005, 0.0005] train_loss: 1.567957 train_acc: 0.576433 train_f1: 0.576433 time: 0.1912s
INFO:root:Epoch: 0030 val_loss: 1.657140 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0035 lr: [0.0005, 0.0005] train_loss: 1.473104 train_acc: 0.576433 train_f1: 0.576433 time: 0.2098s
INFO:root:Epoch: 0035 val_loss: 1.583058 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0040 lr: [0.0005, 0.0005] train_loss: 1.364791 train_acc: 0.576433 train_f1: 0.576433 time: 0.1910s
INFO:root:Epoch: 0040 val_loss: 1.497923 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0045 lr: [0.0005, 0.0005] train_loss: 1.245117 train_acc: 0.576433 train_f1: 0.576433 time: 0.1939s
INFO:root:Epoch: 0045 val_loss: 1.418389 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0050 lr: [0.0005, 0.0005] train_loss: 1.246381 train_acc: 0.576433 train_f1: 0.576433 time: 0.2041s
INFO:root:Epoch: 0050 val_loss: 1.437129 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0055 lr: [0.0005, 0.0005] train_loss: 1.249345 train_acc: 0.576433 train_f1: 0.576433 time: 0.1973s
INFO:root:Epoch: 0055 val_loss: 1.436170 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0060 lr: [0.0005, 0.0005] train_loss: 1.237821 train_acc: 0.576433 train_f1: 0.576433 time: 0.1907s
INFO:root:Epoch: 0060 val_loss: 1.418056 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0065 lr: [0.0005, 0.0005] train_loss: 1.217099 train_acc: 0.576433 train_f1: 0.576433 time: 0.2007s
INFO:root:Epoch: 0065 val_loss: 1.389617 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0070 lr: [0.0005, 0.0005] train_loss: 1.206864 train_acc: 0.576433 train_f1: 0.576433 time: 0.1974s
INFO:root:Epoch: 0070 val_loss: 1.377570 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0075 lr: [0.0005, 0.0005] train_loss: 1.196290 train_acc: 0.576433 train_f1: 0.576433 time: 0.1945s
INFO:root:Epoch: 0075 val_loss: 1.365581 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0080 lr: [0.0005, 0.0005] train_loss: 1.189261 train_acc: 0.576433 train_f1: 0.576433 time: 0.1921s
INFO:root:Epoch: 0080 val_loss: 1.360600 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0085 lr: [0.0005, 0.0005] train_loss: 1.177741 train_acc: 0.576433 train_f1: 0.576433 time: 0.2023s
INFO:root:Epoch: 0085 val_loss: 1.347873 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0090 lr: [0.0005, 0.0005] train_loss: 1.167815 train_acc: 0.576433 train_f1: 0.576433 time: 0.1937s
INFO:root:Epoch: 0090 val_loss: 1.338055 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0095 lr: [0.0005, 0.0005] train_loss: 1.157702 train_acc: 0.576433 train_f1: 0.576433 time: 0.1947s
INFO:root:Epoch: 0095 val_loss: 1.326079 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.146717 train_acc: 0.576433 train_f1: 0.576433 time: 0.2056s
INFO:root:Epoch: 0100 val_loss: 1.314594 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0105 lr: [0.0005, 0.0005] train_loss: 1.134978 train_acc: 0.576433 train_f1: 0.576433 time: 0.1948s
INFO:root:Epoch: 0105 val_loss: 1.301319 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.122776 train_acc: 0.576433 train_f1: 0.576433 time: 0.1917s
INFO:root:Epoch: 0110 val_loss: 1.288965 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0115 lr: [0.0005, 0.0005] train_loss: 1.109400 train_acc: 0.576433 train_f1: 0.576433 time: 0.2046s
INFO:root:Epoch: 0115 val_loss: 1.275034 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.095668 train_acc: 0.576433 train_f1: 0.576433 time: 0.1931s
INFO:root:Epoch: 0120 val_loss: 1.260313 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0125 lr: [0.0005, 0.0005] train_loss: 1.081574 train_acc: 0.576433 train_f1: 0.576433 time: 0.1937s
INFO:root:Epoch: 0125 val_loss: 1.245443 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.067041 train_acc: 0.576433 train_f1: 0.576433 time: 0.1997s
INFO:root:Epoch: 0130 val_loss: 1.229361 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0135 lr: [0.0005, 0.0005] train_loss: 1.051880 train_acc: 0.576433 train_f1: 0.576433 time: 0.1989s
INFO:root:Epoch: 0135 val_loss: 1.211850 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.036200 train_acc: 0.576433 train_f1: 0.576433 time: 0.1972s
INFO:root:Epoch: 0140 val_loss: 1.194607 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0145 lr: [0.0005, 0.0005] train_loss: 1.023960 train_acc: 0.576433 train_f1: 0.576433 time: 0.1938s
INFO:root:Epoch: 0145 val_loss: 1.179722 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.012124 train_acc: 0.576433 train_f1: 0.576433 time: 0.2010s
INFO:root:Epoch: 0150 val_loss: 1.166331 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0155 lr: [0.0005, 0.0005] train_loss: 0.999687 train_acc: 0.576433 train_f1: 0.576433 time: 0.1951s
INFO:root:Epoch: 0155 val_loss: 1.152207 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.987447 train_acc: 0.576433 train_f1: 0.576433 time: 0.1937s
INFO:root:Epoch: 0160 val_loss: 1.138767 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0165 lr: [0.0005, 0.0005] train_loss: 0.975903 train_acc: 0.576433 train_f1: 0.576433 time: 0.2041s
INFO:root:Epoch: 0165 val_loss: 1.127327 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.965058 train_acc: 0.576433 train_f1: 0.576433 time: 0.1942s
INFO:root:Epoch: 0170 val_loss: 1.115893 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0175 lr: [0.0005, 0.0005] train_loss: 0.954912 train_acc: 0.576433 train_f1: 0.576433 time: 0.1939s
INFO:root:Epoch: 0175 val_loss: 1.105187 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.944202 train_acc: 0.576433 train_f1: 0.576433 time: 0.2025s
INFO:root:Epoch: 0180 val_loss: 1.093408 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0185 lr: [0.0005, 0.0005] train_loss: 0.933324 train_acc: 0.576433 train_f1: 0.576433 time: 0.1944s
INFO:root:Epoch: 0185 val_loss: 1.083388 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.924333 train_acc: 0.576433 train_f1: 0.576433 time: 0.1962s
INFO:root:Epoch: 0190 val_loss: 1.073731 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0195 lr: [0.0005, 0.0005] train_loss: 0.915149 train_acc: 0.576433 train_f1: 0.576433 time: 0.2090s
INFO:root:Epoch: 0195 val_loss: 1.065234 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 0.906968 train_acc: 0.576433 train_f1: 0.576433 time: 0.1950s
INFO:root:Epoch: 0200 val_loss: 1.057341 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0205 lr: [0.0005, 0.0005] train_loss: 0.899125 train_acc: 0.576433 train_f1: 0.576433 time: 0.1933s
INFO:root:Epoch: 0205 val_loss: 1.050187 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 0.891576 train_acc: 0.576433 train_f1: 0.576433 time: 0.2027s
INFO:root:Epoch: 0210 val_loss: 1.043189 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0215 lr: [0.0005, 0.0005] train_loss: 0.884486 train_acc: 0.576433 train_f1: 0.576433 time: 0.1921s
INFO:root:Epoch: 0215 val_loss: 1.037244 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 0.877660 train_acc: 0.576433 train_f1: 0.576433 time: 0.1918s
INFO:root:Epoch: 0220 val_loss: 1.032559 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0225 lr: [0.0005, 0.0005] train_loss: 0.872039 train_acc: 0.576433 train_f1: 0.576433 time: 0.1992s
INFO:root:Epoch: 0225 val_loss: 1.026197 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 0.865608 train_acc: 0.576433 train_f1: 0.576433 time: 0.1953s
INFO:root:Epoch: 0230 val_loss: 1.019061 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0235 lr: [0.0005, 0.0005] train_loss: 0.859583 train_acc: 0.576433 train_f1: 0.576433 time: 0.1922s
INFO:root:Epoch: 0235 val_loss: 1.013402 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 0.853532 train_acc: 0.576433 train_f1: 0.576433 time: 0.1964s
INFO:root:Epoch: 0240 val_loss: 1.007270 val_acc: 0.537037 val_f1: 0.537037
INFO:root:Epoch: 0245 lr: [0.0005, 0.0005] train_loss: 0.848692 train_acc: 0.729299 train_f1: 0.729299 time: 0.1938s
INFO:root:Epoch: 0245 val_loss: 1.003062 val_acc: 0.555556 val_f1: 0.555556
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.845028 train_acc: 0.729299 train_f1: 0.729299 time: 0.1927s
INFO:root:Epoch: 0250 val_loss: 0.996951 val_acc: 0.555556 val_f1: 0.555556
INFO:root:Epoch: 0255 lr: [0.0005, 0.0005] train_loss: 0.841371 train_acc: 0.732484 train_f1: 0.732484 time: 0.1961s
INFO:root:Epoch: 0255 val_loss: 0.993447 val_acc: 0.555556 val_f1: 0.555556
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.836296 train_acc: 0.732484 train_f1: 0.732484 time: 0.2023s
INFO:root:Epoch: 0260 val_loss: 0.988204 val_acc: 0.555556 val_f1: 0.555556
INFO:root:Epoch: 0265 lr: [0.0005, 0.0005] train_loss: 0.831703 train_acc: 0.732484 train_f1: 0.732484 time: 0.1923s
INFO:root:Epoch: 0265 val_loss: 0.984865 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.827834 train_acc: 0.732484 train_f1: 0.732484 time: 0.1919s
INFO:root:Epoch: 0270 val_loss: 0.975795 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0275 lr: [0.0005, 0.0005] train_loss: 0.824035 train_acc: 0.732484 train_f1: 0.732484 time: 0.2061s
INFO:root:Epoch: 0275 val_loss: 0.973505 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.821559 train_acc: 0.732484 train_f1: 0.732484 time: 0.1913s
INFO:root:Epoch: 0280 val_loss: 0.970515 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0285 lr: [0.0005, 0.0005] train_loss: 0.817283 train_acc: 0.732484 train_f1: 0.732484 time: 0.1923s
INFO:root:Epoch: 0285 val_loss: 0.966997 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.814146 train_acc: 0.732484 train_f1: 0.732484 time: 0.2064s
INFO:root:Epoch: 0290 val_loss: 0.965308 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0295 lr: [0.0005, 0.0005] train_loss: 0.812889 train_acc: 0.732484 train_f1: 0.732484 time: 0.1917s
INFO:root:Epoch: 0295 val_loss: 0.964680 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0300 lr: [0.0005, 0.0005] train_loss: 0.810458 train_acc: 0.732484 train_f1: 0.732484 time: 0.1917s
INFO:root:Epoch: 0300 val_loss: 0.963187 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0305 lr: [0.0005, 0.0005] train_loss: 0.808480 train_acc: 0.732484 train_f1: 0.732484 time: 0.2039s
INFO:root:Epoch: 0305 val_loss: 0.958157 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0310 lr: [0.0005, 0.0005] train_loss: 0.806670 train_acc: 0.732484 train_f1: 0.732484 time: 0.1994s
INFO:root:Epoch: 0310 val_loss: 0.959060 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0315 lr: [0.0005, 0.0005] train_loss: 0.803960 train_acc: 0.732484 train_f1: 0.732484 time: 0.1921s
INFO:root:Epoch: 0315 val_loss: 0.958851 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0320 lr: [0.0005, 0.0005] train_loss: 0.800681 train_acc: 0.732484 train_f1: 0.732484 time: 0.1922s
INFO:root:Epoch: 0320 val_loss: 0.955192 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0325 lr: [0.0005, 0.0005] train_loss: 0.799487 train_acc: 0.732484 train_f1: 0.732484 time: 0.2018s
INFO:root:Epoch: 0325 val_loss: 0.954785 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0330 lr: [0.0005, 0.0005] train_loss: 0.797697 train_acc: 0.732484 train_f1: 0.732484 time: 0.1933s
INFO:root:Epoch: 0330 val_loss: 0.951452 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0335 lr: [0.0005, 0.0005] train_loss: 0.796125 train_acc: 0.732484 train_f1: 0.732484 time: 0.1929s
INFO:root:Epoch: 0335 val_loss: 0.948758 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0340 lr: [0.0005, 0.0005] train_loss: 0.795600 train_acc: 0.732484 train_f1: 0.732484 time: 0.2018s
INFO:root:Epoch: 0340 val_loss: 0.947980 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0345 lr: [0.0005, 0.0005] train_loss: 0.793614 train_acc: 0.732484 train_f1: 0.732484 time: 0.1905s
INFO:root:Epoch: 0345 val_loss: 0.946018 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0350 lr: [0.0005, 0.0005] train_loss: 0.791619 train_acc: 0.732484 train_f1: 0.732484 time: 0.1909s
INFO:root:Epoch: 0350 val_loss: 0.944724 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0355 lr: [0.0005, 0.0005] train_loss: 0.790453 train_acc: 0.732484 train_f1: 0.732484 time: 0.1999s
INFO:root:Epoch: 0355 val_loss: 0.944058 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0360 lr: [0.0005, 0.0005] train_loss: 0.789767 train_acc: 0.732484 train_f1: 0.732484 time: 0.1944s
INFO:root:Epoch: 0360 val_loss: 0.943215 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0365 lr: [0.0005, 0.0005] train_loss: 0.788018 train_acc: 0.732484 train_f1: 0.732484 time: 0.1910s
INFO:root:Epoch: 0365 val_loss: 0.941284 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0370 lr: [0.0005, 0.0005] train_loss: 0.787583 train_acc: 0.732484 train_f1: 0.732484 time: 0.1909s
INFO:root:Epoch: 0370 val_loss: 0.940410 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0375 lr: [0.0005, 0.0005] train_loss: 0.785792 train_acc: 0.732484 train_f1: 0.732484 time: 0.2107s
INFO:root:Epoch: 0375 val_loss: 0.940456 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0380 lr: [0.0005, 0.0005] train_loss: 0.785216 train_acc: 0.732484 train_f1: 0.732484 time: 0.1925s
INFO:root:Epoch: 0380 val_loss: 0.939403 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0385 lr: [0.0005, 0.0005] train_loss: 0.782499 train_acc: 0.732484 train_f1: 0.732484 time: 0.1911s
INFO:root:Epoch: 0385 val_loss: 0.939012 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0390 lr: [0.0005, 0.0005] train_loss: 0.781995 train_acc: 0.732484 train_f1: 0.732484 time: 0.1989s
INFO:root:Epoch: 0390 val_loss: 0.936812 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0395 lr: [0.0005, 0.0005] train_loss: 0.779811 train_acc: 0.732484 train_f1: 0.732484 time: 0.1926s
INFO:root:Epoch: 0395 val_loss: 0.937629 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0400 lr: [0.0005, 0.0005] train_loss: 0.781108 train_acc: 0.732484 train_f1: 0.732484 time: 0.1909s
INFO:root:Epoch: 0400 val_loss: 0.937394 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0405 lr: [0.0005, 0.0005] train_loss: 0.781456 train_acc: 0.732484 train_f1: 0.732484 time: 0.1950s
INFO:root:Epoch: 0405 val_loss: 0.936164 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0410 lr: [0.0005, 0.0005] train_loss: 0.779035 train_acc: 0.732484 train_f1: 0.732484 time: 0.2032s
INFO:root:Epoch: 0410 val_loss: 0.935529 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0415 lr: [0.0005, 0.0005] train_loss: 0.776846 train_acc: 0.732484 train_f1: 0.732484 time: 0.1905s
INFO:root:Epoch: 0415 val_loss: 0.933554 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0420 lr: [0.0005, 0.0005] train_loss: 0.774936 train_acc: 0.732484 train_f1: 0.732484 time: 0.1931s
INFO:root:Epoch: 0420 val_loss: 0.934059 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0425 lr: [0.0005, 0.0005] train_loss: 0.776144 train_acc: 0.732484 train_f1: 0.732484 time: 0.2045s
INFO:root:Epoch: 0425 val_loss: 0.932292 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0430 lr: [0.0005, 0.0005] train_loss: 0.775045 train_acc: 0.732484 train_f1: 0.732484 time: 0.1922s
INFO:root:Epoch: 0430 val_loss: 0.928697 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0435 lr: [0.0005, 0.0005] train_loss: 0.777911 train_acc: 0.732484 train_f1: 0.732484 time: 0.1916s
INFO:root:Epoch: 0435 val_loss: 0.933071 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0440 lr: [0.0005, 0.0005] train_loss: 0.771743 train_acc: 0.732484 train_f1: 0.732484 time: 0.2025s
INFO:root:Epoch: 0440 val_loss: 0.930966 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0445 lr: [0.0005, 0.0005] train_loss: 0.771770 train_acc: 0.732484 train_f1: 0.732484 time: 0.1909s
INFO:root:Epoch: 0445 val_loss: 0.927622 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0450 lr: [0.0005, 0.0005] train_loss: 0.770938 train_acc: 0.732484 train_f1: 0.732484 time: 0.1912s
INFO:root:Epoch: 0450 val_loss: 0.930525 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0455 lr: [0.0005, 0.0005] train_loss: 0.771542 train_acc: 0.732484 train_f1: 0.732484 time: 0.2006s
INFO:root:Epoch: 0455 val_loss: 0.932569 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0460 lr: [0.0005, 0.0005] train_loss: 0.768909 train_acc: 0.732484 train_f1: 0.732484 time: 0.2011s
INFO:root:Epoch: 0460 val_loss: 0.929370 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0465 lr: [0.0005, 0.0005] train_loss: 0.769036 train_acc: 0.732484 train_f1: 0.732484 time: 0.1910s
INFO:root:Epoch: 0465 val_loss: 0.930489 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0470 lr: [0.0005, 0.0005] train_loss: 0.769542 train_acc: 0.732484 train_f1: 0.732484 time: 0.1918s
INFO:root:Epoch: 0470 val_loss: 0.927880 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0475 lr: [0.0005, 0.0005] train_loss: 0.769189 train_acc: 0.732484 train_f1: 0.732484 time: 0.2065s
INFO:root:Epoch: 0475 val_loss: 0.929411 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0480 lr: [0.0005, 0.0005] train_loss: 0.768202 train_acc: 0.732484 train_f1: 0.732484 time: 0.1924s
INFO:root:Epoch: 0480 val_loss: 0.927975 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0485 lr: [0.0005, 0.0005] train_loss: 0.766484 train_acc: 0.732484 train_f1: 0.732484 time: 0.1925s
INFO:root:Epoch: 0485 val_loss: 0.930575 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0490 lr: [0.0005, 0.0005] train_loss: 0.765751 train_acc: 0.732484 train_f1: 0.732484 time: 0.2052s
INFO:root:Epoch: 0490 val_loss: 0.925899 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0495 lr: [0.0005, 0.0005] train_loss: 0.766310 train_acc: 0.732484 train_f1: 0.732484 time: 0.1929s
INFO:root:Epoch: 0495 val_loss: 0.924530 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0500 lr: [0.0005, 0.0005] train_loss: 0.764450 train_acc: 0.732484 train_f1: 0.732484 time: 0.1913s
INFO:root:Epoch: 0500 val_loss: 0.919845 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0505 lr: [0.0005, 0.0005] train_loss: 0.764595 train_acc: 0.732484 train_f1: 0.732484 time: 0.2036s
INFO:root:Epoch: 0505 val_loss: 0.922419 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0510 lr: [0.0005, 0.0005] train_loss: 0.764492 train_acc: 0.732484 train_f1: 0.732484 time: 0.1922s
INFO:root:Epoch: 0510 val_loss: 0.925523 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Epoch: 0515 lr: [0.0005, 0.0005] train_loss: 0.762490 train_acc: 0.732484 train_f1: 0.732484 time: 0.1924s
INFO:root:Epoch: 0515 val_loss: 0.923754 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 104.9428s
INFO:root:Val set results: val_loss: 0.984865 val_acc: 0.592593 val_f1: 0.592593
INFO:root:Test set results: test_loss: 0.946872 test_acc: 0.666667 test_f1: 0.666667
