INFO:root:Using: cuda:7
INFO:root:Using seed 18.
INFO:root:Dataset: wisconsin
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f417e3436d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f417e3436d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f417e3436d0>)
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f417e3436d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f417e3436d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f417e3436d0>)
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 217733
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 1.750142 train_acc: 0.576433 train_f1: 0.576433 time: 0.3174s
INFO:root:Epoch: 0005 val_loss: 1.744998 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.510009 train_acc: 0.576433 train_f1: 0.576433 time: 0.3217s
INFO:root:Epoch: 0010 val_loss: 1.563212 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 1.320487 train_acc: 0.576433 train_f1: 0.576433 time: 0.3248s
INFO:root:Epoch: 0015 val_loss: 1.407151 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.142359 train_acc: 0.576433 train_f1: 0.576433 time: 0.3249s
INFO:root:Epoch: 0020 val_loss: 1.257796 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 1.093500 train_acc: 0.576433 train_f1: 0.576433 time: 0.3379s
INFO:root:Epoch: 0025 val_loss: 1.225275 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.056702 train_acc: 0.576433 train_f1: 0.576433 time: 0.3389s
INFO:root:Epoch: 0030 val_loss: 1.172400 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 1.010079 train_acc: 0.576433 train_f1: 0.576433 time: 0.3187s
INFO:root:Epoch: 0035 val_loss: 1.119213 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 0.957915 train_acc: 0.576433 train_f1: 0.576433 time: 0.3182s
INFO:root:Epoch: 0040 val_loss: 1.070436 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 0.913784 train_acc: 0.576433 train_f1: 0.576433 time: 0.3163s
INFO:root:Epoch: 0045 val_loss: 1.029699 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 0.873562 train_acc: 0.576433 train_f1: 0.576433 time: 0.3256s
INFO:root:Epoch: 0050 val_loss: 1.005641 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 0.840140 train_acc: 0.576433 train_f1: 0.576433 time: 0.3216s
INFO:root:Epoch: 0055 val_loss: 0.983565 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 0.815184 train_acc: 0.576433 train_f1: 0.576433 time: 0.3315s
INFO:root:Epoch: 0060 val_loss: 0.957608 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 0.794721 train_acc: 0.576433 train_f1: 0.576433 time: 0.3327s
INFO:root:Epoch: 0065 val_loss: 0.934428 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.776470 train_acc: 0.576433 train_f1: 0.576433 time: 0.3312s
INFO:root:Epoch: 0070 val_loss: 0.910279 val_acc: 0.518519 val_f1: 0.518519
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 0.760861 train_acc: 0.678344 train_f1: 0.678344 time: 0.3162s
INFO:root:Epoch: 0075 val_loss: 0.897031 val_acc: 0.555556 val_f1: 0.555556
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.743975 train_acc: 0.726115 train_f1: 0.726115 time: 0.3144s
INFO:root:Epoch: 0080 val_loss: 0.888711 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 0.737978 train_acc: 0.726115 train_f1: 0.726115 time: 0.3222s
INFO:root:Epoch: 0085 val_loss: 0.889583 val_acc: 0.629630 val_f1: 0.629630
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.730089 train_acc: 0.815287 train_f1: 0.815287 time: 0.3204s
INFO:root:Epoch: 0090 val_loss: 0.892356 val_acc: 0.703704 val_f1: 0.703704
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 0.722419 train_acc: 0.834395 train_f1: 0.834395 time: 0.3181s
INFO:root:Epoch: 0095 val_loss: 0.871936 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 0.717609 train_acc: 0.722930 train_f1: 0.722930 time: 0.3309s
INFO:root:Epoch: 0100 val_loss: 0.865049 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0105 lr: [0.0005, 0.0005] train_loss: 0.708206 train_acc: 0.722930 train_f1: 0.722930 time: 0.3309s
INFO:root:Epoch: 0105 val_loss: 0.861437 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 0.702248 train_acc: 0.722930 train_f1: 0.722930 time: 0.3331s
INFO:root:Epoch: 0110 val_loss: 0.862504 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0115 lr: [0.0005, 0.0005] train_loss: 0.699644 train_acc: 0.722930 train_f1: 0.722930 time: 0.3155s
INFO:root:Epoch: 0115 val_loss: 0.858671 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 0.698055 train_acc: 0.722930 train_f1: 0.722930 time: 0.3184s
INFO:root:Epoch: 0120 val_loss: 0.854667 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0125 lr: [0.0005, 0.0005] train_loss: 0.695788 train_acc: 0.722930 train_f1: 0.722930 time: 0.3200s
INFO:root:Epoch: 0125 val_loss: 0.854142 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 0.695615 train_acc: 0.722930 train_f1: 0.722930 time: 0.3220s
INFO:root:Epoch: 0130 val_loss: 0.851969 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0135 lr: [0.0005, 0.0005] train_loss: 0.693972 train_acc: 0.722930 train_f1: 0.722930 time: 0.3216s
INFO:root:Epoch: 0135 val_loss: 0.852248 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 0.692569 train_acc: 0.722930 train_f1: 0.722930 time: 0.3265s
INFO:root:Epoch: 0140 val_loss: 0.851201 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0145 lr: [0.0005, 0.0005] train_loss: 0.692875 train_acc: 0.722930 train_f1: 0.722930 time: 0.3283s
INFO:root:Epoch: 0145 val_loss: 0.850094 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.692012 train_acc: 0.722930 train_f1: 0.722930 time: 0.3395s
INFO:root:Epoch: 0150 val_loss: 0.847953 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0155 lr: [0.0005, 0.0005] train_loss: 0.691191 train_acc: 0.722930 train_f1: 0.722930 time: 0.3343s
INFO:root:Epoch: 0155 val_loss: 0.850026 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.687769 train_acc: 0.722930 train_f1: 0.722930 time: 0.3216s
INFO:root:Epoch: 0160 val_loss: 0.846883 val_acc: 0.629630 val_f1: 0.629630
INFO:root:Epoch: 0165 lr: [0.0005, 0.0005] train_loss: 0.686209 train_acc: 0.722930 train_f1: 0.722930 time: 0.3277s
INFO:root:Epoch: 0165 val_loss: 0.847499 val_acc: 0.629630 val_f1: 0.629630
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.684858 train_acc: 0.722930 train_f1: 0.722930 time: 0.3201s
INFO:root:Epoch: 0170 val_loss: 0.845187 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0175 lr: [0.0005, 0.0005] train_loss: 0.683901 train_acc: 0.722930 train_f1: 0.722930 time: 0.3175s
INFO:root:Epoch: 0175 val_loss: 0.845870 val_acc: 0.629630 val_f1: 0.629630
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.681895 train_acc: 0.722930 train_f1: 0.722930 time: 0.3291s
INFO:root:Epoch: 0180 val_loss: 0.845631 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0185 lr: [0.0005, 0.0005] train_loss: 0.682981 train_acc: 0.722930 train_f1: 0.722930 time: 0.3389s
INFO:root:Epoch: 0185 val_loss: 0.846055 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.681749 train_acc: 0.722930 train_f1: 0.722930 time: 0.3306s
INFO:root:Epoch: 0190 val_loss: 0.849877 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0195 lr: [0.0005, 0.0005] train_loss: 0.681131 train_acc: 0.722930 train_f1: 0.722930 time: 0.3327s
INFO:root:Epoch: 0195 val_loss: 0.846593 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0200 lr: [0.00025, 0.00025] train_loss: 0.676830 train_acc: 0.722930 train_f1: 0.722930 time: 0.3205s
INFO:root:Epoch: 0200 val_loss: 0.849601 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0205 lr: [0.00025, 0.00025] train_loss: 0.674711 train_acc: 0.722930 train_f1: 0.722930 time: 0.3163s
INFO:root:Epoch: 0205 val_loss: 0.849608 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0210 lr: [0.00025, 0.00025] train_loss: 0.673039 train_acc: 0.722930 train_f1: 0.722930 time: 0.3164s
INFO:root:Epoch: 0210 val_loss: 0.846372 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0215 lr: [0.00025, 0.00025] train_loss: 0.671647 train_acc: 0.722930 train_f1: 0.722930 time: 0.3201s
INFO:root:Epoch: 0215 val_loss: 0.845918 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0220 lr: [0.00025, 0.00025] train_loss: 0.669912 train_acc: 0.722930 train_f1: 0.722930 time: 0.3246s
INFO:root:Epoch: 0220 val_loss: 0.847186 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0225 lr: [0.00025, 0.00025] train_loss: 0.666394 train_acc: 0.722930 train_f1: 0.722930 time: 0.3342s
INFO:root:Epoch: 0225 val_loss: 0.859042 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0230 lr: [0.00025, 0.00025] train_loss: 0.663361 train_acc: 0.722930 train_f1: 0.722930 time: 0.3375s
INFO:root:Epoch: 0230 val_loss: 0.860992 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0235 lr: [0.00025, 0.00025] train_loss: 0.660554 train_acc: 0.722930 train_f1: 0.722930 time: 0.3190s
INFO:root:Epoch: 0235 val_loss: 0.850232 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0240 lr: [0.00025, 0.00025] train_loss: 0.658318 train_acc: 0.722930 train_f1: 0.722930 time: 0.3203s
INFO:root:Epoch: 0240 val_loss: 0.846973 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0245 lr: [0.00025, 0.00025] train_loss: 0.656806 train_acc: 0.722930 train_f1: 0.722930 time: 0.3206s
INFO:root:Epoch: 0245 val_loss: 0.844692 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0250 lr: [0.00025, 0.00025] train_loss: 0.655587 train_acc: 0.722930 train_f1: 0.722930 time: 0.3260s
INFO:root:Epoch: 0250 val_loss: 0.843472 val_acc: 0.648148 val_f1: 0.648148
INFO:root:Epoch: 0255 lr: [0.00025, 0.00025] train_loss: 0.653950 train_acc: 0.722930 train_f1: 0.722930 time: 0.3203s
INFO:root:Epoch: 0255 val_loss: 0.843241 val_acc: 0.648148 val_f1: 0.648148
