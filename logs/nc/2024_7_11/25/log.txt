INFO:root:Using: cuda:7
INFO:root:Using seed 8.
INFO:root:Dataset: wisconsin
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=True, act=None)
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f5bc17136d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f5bc17136d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_f): BMLP(
            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f5bc17136d0>)
            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
          (MLP_fi): BMLP(
            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
            (act): BAct(c=tensor([1.], device='cuda:7'), act=<function relu at 0x7f5bc17136d0>)
            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:7'), use_bias=1, act=None)
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 217733
INFO:root:Epoch: 0005 lr: [0.0005, 0.0005] train_loss: 1.848982 train_acc: 0.576433 train_f1: 0.576433 time: 0.3304s
INFO:root:Epoch: 0005 val_loss: 1.874302 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0010 lr: [0.0005, 0.0005] train_loss: 1.709638 train_acc: 0.576433 train_f1: 0.576433 time: 0.3198s
INFO:root:Epoch: 0010 val_loss: 1.792657 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0015 lr: [0.0005, 0.0005] train_loss: 1.618632 train_acc: 0.576433 train_f1: 0.576433 time: 0.3165s
INFO:root:Epoch: 0015 val_loss: 1.718181 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0020 lr: [0.0005, 0.0005] train_loss: 1.522211 train_acc: 0.576433 train_f1: 0.576433 time: 0.3267s
INFO:root:Epoch: 0020 val_loss: 1.627516 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0025 lr: [0.0005, 0.0005] train_loss: 1.407701 train_acc: 0.576433 train_f1: 0.576433 time: 0.3343s
INFO:root:Epoch: 0025 val_loss: 1.512812 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0030 lr: [0.0005, 0.0005] train_loss: 1.278679 train_acc: 0.576433 train_f1: 0.576433 time: 0.3395s
INFO:root:Epoch: 0030 val_loss: 1.389100 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0035 lr: [0.0005, 0.0005] train_loss: 1.172886 train_acc: 0.576433 train_f1: 0.576433 time: 0.3303s
INFO:root:Epoch: 0035 val_loss: 1.286644 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0040 lr: [0.0005, 0.0005] train_loss: 1.073634 train_acc: 0.576433 train_f1: 0.576433 time: 0.3189s
INFO:root:Epoch: 0040 val_loss: 1.207914 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0045 lr: [0.0005, 0.0005] train_loss: 1.035742 train_acc: 0.576433 train_f1: 0.576433 time: 0.3228s
INFO:root:Epoch: 0045 val_loss: 1.171236 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0050 lr: [0.0005, 0.0005] train_loss: 1.004351 train_acc: 0.576433 train_f1: 0.576433 time: 0.3222s
INFO:root:Epoch: 0050 val_loss: 1.135279 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0055 lr: [0.0005, 0.0005] train_loss: 0.969699 train_acc: 0.576433 train_f1: 0.576433 time: 0.3291s
INFO:root:Epoch: 0055 val_loss: 1.088067 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0060 lr: [0.0005, 0.0005] train_loss: 0.935606 train_acc: 0.576433 train_f1: 0.576433 time: 0.3294s
INFO:root:Epoch: 0060 val_loss: 1.044095 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0065 lr: [0.0005, 0.0005] train_loss: 0.902547 train_acc: 0.576433 train_f1: 0.576433 time: 0.3376s
INFO:root:Epoch: 0065 val_loss: 1.000321 val_acc: 0.481481 val_f1: 0.481481
INFO:root:Epoch: 0070 lr: [0.0005, 0.0005] train_loss: 0.871380 train_acc: 0.726115 train_f1: 0.726115 time: 0.3259s
INFO:root:Epoch: 0070 val_loss: 0.958822 val_acc: 0.685185 val_f1: 0.685185
INFO:root:Epoch: 0075 lr: [0.0005, 0.0005] train_loss: 0.840665 train_acc: 0.729299 train_f1: 0.729299 time: 0.3168s
INFO:root:Epoch: 0075 val_loss: 0.920737 val_acc: 0.759259 val_f1: 0.759259
INFO:root:Epoch: 0080 lr: [0.0005, 0.0005] train_loss: 0.816578 train_acc: 0.882166 train_f1: 0.882166 time: 0.3154s
INFO:root:Epoch: 0080 val_loss: 0.885749 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0085 lr: [0.0005, 0.0005] train_loss: 0.795678 train_acc: 0.885350 train_f1: 0.885350 time: 0.3167s
INFO:root:Epoch: 0085 val_loss: 0.858960 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0090 lr: [0.0005, 0.0005] train_loss: 0.777353 train_acc: 0.885350 train_f1: 0.885350 time: 0.3183s
INFO:root:Epoch: 0090 val_loss: 0.837248 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0095 lr: [0.0005, 0.0005] train_loss: 0.758943 train_acc: 0.885350 train_f1: 0.885350 time: 0.3197s
INFO:root:Epoch: 0095 val_loss: 0.811591 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 0.737344 train_acc: 0.885350 train_f1: 0.885350 time: 0.3363s
INFO:root:Epoch: 0100 val_loss: 0.784741 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0105 lr: [0.0005, 0.0005] train_loss: 0.718143 train_acc: 0.885350 train_f1: 0.885350 time: 0.3310s
INFO:root:Epoch: 0105 val_loss: 0.767297 val_acc: 0.814815 val_f1: 0.814815
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 0.710870 train_acc: 0.885350 train_f1: 0.885350 time: 0.3293s
INFO:root:Epoch: 0110 val_loss: 0.768821 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0115 lr: [0.0005, 0.0005] train_loss: 0.697133 train_acc: 0.885350 train_f1: 0.885350 time: 0.3199s
INFO:root:Epoch: 0115 val_loss: 0.762064 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 0.694305 train_acc: 0.885350 train_f1: 0.885350 time: 0.3173s
INFO:root:Epoch: 0120 val_loss: 0.747348 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0125 lr: [0.0005, 0.0005] train_loss: 0.687311 train_acc: 0.885350 train_f1: 0.885350 time: 0.3208s
INFO:root:Epoch: 0125 val_loss: 0.748704 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 0.683045 train_acc: 0.885350 train_f1: 0.885350 time: 0.3203s
INFO:root:Epoch: 0130 val_loss: 0.739770 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0135 lr: [0.0005, 0.0005] train_loss: 0.679276 train_acc: 0.885350 train_f1: 0.885350 time: 0.3290s
INFO:root:Epoch: 0135 val_loss: 0.736668 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 0.678551 train_acc: 0.885350 train_f1: 0.885350 time: 0.3323s
INFO:root:Epoch: 0140 val_loss: 0.735605 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0145 lr: [0.0005, 0.0005] train_loss: 0.676958 train_acc: 0.885350 train_f1: 0.885350 time: 0.3248s
INFO:root:Epoch: 0145 val_loss: 0.735066 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 0.675949 train_acc: 0.885350 train_f1: 0.885350 time: 0.3266s
INFO:root:Epoch: 0150 val_loss: 0.734548 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0155 lr: [0.0005, 0.0005] train_loss: 0.673751 train_acc: 0.885350 train_f1: 0.885350 time: 0.3242s
INFO:root:Epoch: 0155 val_loss: 0.739114 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 0.673085 train_acc: 0.885350 train_f1: 0.885350 time: 0.3242s
INFO:root:Epoch: 0160 val_loss: 0.743733 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0165 lr: [0.0005, 0.0005] train_loss: 0.672621 train_acc: 0.885350 train_f1: 0.885350 time: 0.3254s
INFO:root:Epoch: 0165 val_loss: 0.737847 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 0.672229 train_acc: 0.885350 train_f1: 0.885350 time: 0.3309s
INFO:root:Epoch: 0170 val_loss: 0.728480 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0175 lr: [0.0005, 0.0005] train_loss: 0.671709 train_acc: 0.885350 train_f1: 0.885350 time: 0.3558s
INFO:root:Epoch: 0175 val_loss: 0.733880 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 0.670093 train_acc: 0.885350 train_f1: 0.885350 time: 0.3471s
INFO:root:Epoch: 0180 val_loss: 0.732146 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0185 lr: [0.0005, 0.0005] train_loss: 0.668860 train_acc: 0.885350 train_f1: 0.885350 time: 0.3282s
INFO:root:Epoch: 0185 val_loss: 0.730140 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 0.669969 train_acc: 0.885350 train_f1: 0.885350 time: 0.3286s
INFO:root:Epoch: 0190 val_loss: 0.737044 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0195 lr: [0.0005, 0.0005] train_loss: 0.668483 train_acc: 0.885350 train_f1: 0.885350 time: 0.3294s
INFO:root:Epoch: 0195 val_loss: 0.731212 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 0.665980 train_acc: 0.885350 train_f1: 0.885350 time: 0.3403s
INFO:root:Epoch: 0200 val_loss: 0.730010 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0205 lr: [0.0005, 0.0005] train_loss: 0.665411 train_acc: 0.885350 train_f1: 0.885350 time: 0.3463s
INFO:root:Epoch: 0205 val_loss: 0.734051 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 0.665108 train_acc: 0.885350 train_f1: 0.885350 time: 0.3407s
INFO:root:Epoch: 0210 val_loss: 0.729460 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0215 lr: [0.0005, 0.0005] train_loss: 0.664134 train_acc: 0.885350 train_f1: 0.885350 time: 0.3275s
INFO:root:Epoch: 0215 val_loss: 0.729037 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 0.665096 train_acc: 0.885350 train_f1: 0.885350 time: 0.3282s
INFO:root:Epoch: 0220 val_loss: 0.726723 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0225 lr: [0.0005, 0.0005] train_loss: 0.664486 train_acc: 0.885350 train_f1: 0.885350 time: 0.3320s
INFO:root:Epoch: 0225 val_loss: 0.724978 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 0.662793 train_acc: 0.885350 train_f1: 0.885350 time: 0.3405s
INFO:root:Epoch: 0230 val_loss: 0.726907 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0235 lr: [0.0005, 0.0005] train_loss: 0.661246 train_acc: 0.885350 train_f1: 0.885350 time: 0.3528s
INFO:root:Epoch: 0235 val_loss: 0.730058 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 0.660766 train_acc: 0.885350 train_f1: 0.885350 time: 0.3363s
INFO:root:Epoch: 0240 val_loss: 0.728064 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0245 lr: [0.0005, 0.0005] train_loss: 0.661497 train_acc: 0.885350 train_f1: 0.885350 time: 0.3324s
INFO:root:Epoch: 0245 val_loss: 0.725552 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 0.660794 train_acc: 0.885350 train_f1: 0.885350 time: 0.3346s
INFO:root:Epoch: 0250 val_loss: 0.722700 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0255 lr: [0.0005, 0.0005] train_loss: 0.658699 train_acc: 0.885350 train_f1: 0.885350 time: 0.3357s
INFO:root:Epoch: 0255 val_loss: 0.722335 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 0.658402 train_acc: 0.885350 train_f1: 0.885350 time: 0.3431s
INFO:root:Epoch: 0260 val_loss: 0.723599 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0265 lr: [0.0005, 0.0005] train_loss: 0.656453 train_acc: 0.885350 train_f1: 0.885350 time: 0.3531s
INFO:root:Epoch: 0265 val_loss: 0.723531 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 0.656323 train_acc: 0.885350 train_f1: 0.885350 time: 0.3340s
INFO:root:Epoch: 0270 val_loss: 0.722507 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0275 lr: [0.0005, 0.0005] train_loss: 0.656557 train_acc: 0.885350 train_f1: 0.885350 time: 0.3315s
INFO:root:Epoch: 0275 val_loss: 0.728726 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 0.655671 train_acc: 0.885350 train_f1: 0.885350 time: 0.3431s
INFO:root:Epoch: 0280 val_loss: 0.720028 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0285 lr: [0.0005, 0.0005] train_loss: 0.653952 train_acc: 0.885350 train_f1: 0.885350 time: 0.3145s
INFO:root:Epoch: 0285 val_loss: 0.719397 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 0.654031 train_acc: 0.885350 train_f1: 0.885350 time: 0.3211s
INFO:root:Epoch: 0290 val_loss: 0.733352 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0295 lr: [0.0005, 0.0005] train_loss: 0.653205 train_acc: 0.885350 train_f1: 0.885350 time: 0.3317s
INFO:root:Epoch: 0295 val_loss: 0.716354 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0300 lr: [0.0005, 0.0005] train_loss: 0.652132 train_acc: 0.885350 train_f1: 0.885350 time: 0.3409s
INFO:root:Epoch: 0300 val_loss: 0.722131 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0305 lr: [0.0005, 0.0005] train_loss: 0.651570 train_acc: 0.885350 train_f1: 0.885350 time: 0.3269s
INFO:root:Epoch: 0305 val_loss: 0.726505 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0310 lr: [0.0005, 0.0005] train_loss: 0.651527 train_acc: 0.885350 train_f1: 0.885350 time: 0.3178s
INFO:root:Epoch: 0310 val_loss: 0.719510 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0315 lr: [0.0005, 0.0005] train_loss: 0.650358 train_acc: 0.885350 train_f1: 0.885350 time: 0.3137s
INFO:root:Epoch: 0315 val_loss: 0.730032 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0320 lr: [0.0005, 0.0005] train_loss: 0.649643 train_acc: 0.885350 train_f1: 0.885350 time: 0.3139s
INFO:root:Epoch: 0320 val_loss: 0.721006 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0325 lr: [0.0005, 0.0005] train_loss: 0.649759 train_acc: 0.885350 train_f1: 0.885350 time: 0.3131s
INFO:root:Epoch: 0325 val_loss: 0.719671 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0330 lr: [0.0005, 0.0005] train_loss: 0.649085 train_acc: 0.885350 train_f1: 0.885350 time: 0.3222s
INFO:root:Epoch: 0330 val_loss: 0.722642 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0335 lr: [0.0005, 0.0005] train_loss: 0.646751 train_acc: 0.885350 train_f1: 0.885350 time: 0.3199s
INFO:root:Epoch: 0335 val_loss: 0.719566 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0340 lr: [0.0005, 0.0005] train_loss: 0.645941 train_acc: 0.885350 train_f1: 0.885350 time: 0.3271s
INFO:root:Epoch: 0340 val_loss: 0.720986 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0345 lr: [0.0005, 0.0005] train_loss: 0.645184 train_acc: 0.885350 train_f1: 0.885350 time: 0.3273s
INFO:root:Epoch: 0345 val_loss: 0.714828 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0350 lr: [0.0005, 0.0005] train_loss: 0.644619 train_acc: 0.885350 train_f1: 0.885350 time: 0.3197s
INFO:root:Epoch: 0350 val_loss: 0.721893 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0355 lr: [0.0005, 0.0005] train_loss: 0.643194 train_acc: 0.885350 train_f1: 0.885350 time: 0.3152s
INFO:root:Epoch: 0355 val_loss: 0.721940 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0360 lr: [0.0005, 0.0005] train_loss: 0.641558 train_acc: 0.885350 train_f1: 0.885350 time: 0.3205s
INFO:root:Epoch: 0360 val_loss: 0.719706 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0365 lr: [0.0005, 0.0005] train_loss: 0.640967 train_acc: 0.885350 train_f1: 0.885350 time: 0.3171s
INFO:root:Epoch: 0365 val_loss: 0.721591 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0370 lr: [0.0005, 0.0005] train_loss: 0.639703 train_acc: 0.885350 train_f1: 0.885350 time: 0.3129s
INFO:root:Epoch: 0370 val_loss: 0.716342 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0375 lr: [0.0005, 0.0005] train_loss: 0.639542 train_acc: 0.885350 train_f1: 0.885350 time: 0.3195s
INFO:root:Epoch: 0375 val_loss: 0.716086 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0380 lr: [0.0005, 0.0005] train_loss: 0.638405 train_acc: 0.885350 train_f1: 0.885350 time: 0.3263s
INFO:root:Epoch: 0380 val_loss: 0.716605 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0385 lr: [0.0005, 0.0005] train_loss: 0.637292 train_acc: 0.885350 train_f1: 0.885350 time: 0.3360s
INFO:root:Epoch: 0385 val_loss: 0.721762 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0390 lr: [0.0005, 0.0005] train_loss: 0.636397 train_acc: 0.885350 train_f1: 0.885350 time: 0.3261s
INFO:root:Epoch: 0390 val_loss: 0.714257 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0395 lr: [0.0005, 0.0005] train_loss: 0.635014 train_acc: 0.885350 train_f1: 0.885350 time: 0.3143s
INFO:root:Epoch: 0395 val_loss: 0.714652 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0400 lr: [0.0005, 0.0005] train_loss: 0.633626 train_acc: 0.885350 train_f1: 0.885350 time: 0.3146s
INFO:root:Epoch: 0400 val_loss: 0.713449 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0405 lr: [0.0005, 0.0005] train_loss: 0.632165 train_acc: 0.885350 train_f1: 0.885350 time: 0.3192s
INFO:root:Epoch: 0405 val_loss: 0.712886 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0410 lr: [0.0005, 0.0005] train_loss: 0.631422 train_acc: 0.885350 train_f1: 0.885350 time: 0.3141s
INFO:root:Epoch: 0410 val_loss: 0.718913 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0415 lr: [0.0005, 0.0005] train_loss: 0.629184 train_acc: 0.885350 train_f1: 0.885350 time: 0.3887s
INFO:root:Epoch: 0415 val_loss: 0.706219 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0420 lr: [0.0005, 0.0005] train_loss: 0.627852 train_acc: 0.885350 train_f1: 0.885350 time: 0.3220s
INFO:root:Epoch: 0420 val_loss: 0.716043 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0425 lr: [0.0005, 0.0005] train_loss: 0.626398 train_acc: 0.885350 train_f1: 0.885350 time: 0.3266s
INFO:root:Epoch: 0425 val_loss: 0.707266 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0430 lr: [0.0005, 0.0005] train_loss: 0.625609 train_acc: 0.885350 train_f1: 0.885350 time: 0.3232s
INFO:root:Epoch: 0430 val_loss: 0.716644 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0435 lr: [0.0005, 0.0005] train_loss: 0.622321 train_acc: 0.885350 train_f1: 0.885350 time: 0.3203s
INFO:root:Epoch: 0435 val_loss: 0.708747 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0440 lr: [0.0005, 0.0005] train_loss: 0.622268 train_acc: 0.885350 train_f1: 0.885350 time: 0.3126s
INFO:root:Epoch: 0440 val_loss: 0.709553 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Epoch: 0445 lr: [0.0005, 0.0005] train_loss: 0.622862 train_acc: 0.885350 train_f1: 0.885350 time: 0.3178s
INFO:root:Epoch: 0445 val_loss: 0.705037 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0450 lr: [0.0005, 0.0005] train_loss: 0.622903 train_acc: 0.885350 train_f1: 0.885350 time: 0.3151s
INFO:root:Epoch: 0450 val_loss: 0.705199 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0455 lr: [0.0005, 0.0005] train_loss: 0.621275 train_acc: 0.885350 train_f1: 0.885350 time: 0.3145s
INFO:root:Epoch: 0455 val_loss: 0.704463 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0460 lr: [0.0005, 0.0005] train_loss: 0.620118 train_acc: 0.885350 train_f1: 0.885350 time: 0.3284s
INFO:root:Epoch: 0460 val_loss: 0.714429 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0465 lr: [0.0005, 0.0005] train_loss: 0.620450 train_acc: 0.885350 train_f1: 0.885350 time: 0.3292s
INFO:root:Epoch: 0465 val_loss: 0.709455 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0470 lr: [0.0005, 0.0005] train_loss: 0.618434 train_acc: 0.885350 train_f1: 0.885350 time: 0.3359s
INFO:root:Epoch: 0470 val_loss: 0.706536 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0475 lr: [0.0005, 0.0005] train_loss: 0.618110 train_acc: 0.885350 train_f1: 0.885350 time: 0.3225s
INFO:root:Epoch: 0475 val_loss: 0.705412 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0480 lr: [0.0005, 0.0005] train_loss: 0.619008 train_acc: 0.885350 train_f1: 0.885350 time: 0.3138s
INFO:root:Epoch: 0480 val_loss: 0.704504 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0485 lr: [0.0005, 0.0005] train_loss: 0.619629 train_acc: 0.885350 train_f1: 0.885350 time: 0.3128s
INFO:root:Epoch: 0485 val_loss: 0.702160 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0490 lr: [0.0005, 0.0005] train_loss: 0.620003 train_acc: 0.885350 train_f1: 0.885350 time: 0.3157s
INFO:root:Epoch: 0490 val_loss: 0.704547 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0495 lr: [0.0005, 0.0005] train_loss: 0.619332 train_acc: 0.885350 train_f1: 0.885350 time: 0.3191s
INFO:root:Epoch: 0495 val_loss: 0.706067 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0500 lr: [0.0005, 0.0005] train_loss: 0.620047 train_acc: 0.885350 train_f1: 0.885350 time: 0.3225s
INFO:root:Epoch: 0500 val_loss: 0.704256 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0505 lr: [0.0005, 0.0005] train_loss: 0.619729 train_acc: 0.885350 train_f1: 0.885350 time: 0.3330s
INFO:root:Epoch: 0505 val_loss: 0.703024 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0510 lr: [0.0005, 0.0005] train_loss: 0.619966 train_acc: 0.885350 train_f1: 0.885350 time: 0.3195s
INFO:root:Epoch: 0510 val_loss: 0.705127 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0515 lr: [0.0005, 0.0005] train_loss: 0.618702 train_acc: 0.885350 train_f1: 0.885350 time: 0.3140s
INFO:root:Epoch: 0515 val_loss: 0.707922 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0520 lr: [0.0005, 0.0005] train_loss: 0.618100 train_acc: 0.885350 train_f1: 0.885350 time: 0.3192s
INFO:root:Epoch: 0520 val_loss: 0.706724 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0525 lr: [0.0005, 0.0005] train_loss: 0.618411 train_acc: 0.885350 train_f1: 0.885350 time: 0.3150s
INFO:root:Epoch: 0525 val_loss: 0.704205 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0530 lr: [0.0005, 0.0005] train_loss: 0.617694 train_acc: 0.885350 train_f1: 0.885350 time: 0.3144s
INFO:root:Epoch: 0530 val_loss: 0.703196 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0535 lr: [0.0005, 0.0005] train_loss: 0.616317 train_acc: 0.885350 train_f1: 0.885350 time: 0.3202s
INFO:root:Epoch: 0535 val_loss: 0.704641 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0540 lr: [0.0005, 0.0005] train_loss: 0.616627 train_acc: 0.885350 train_f1: 0.885350 time: 0.3294s
INFO:root:Epoch: 0540 val_loss: 0.702473 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0545 lr: [0.0005, 0.0005] train_loss: 0.616032 train_acc: 0.885350 train_f1: 0.885350 time: 0.3309s
INFO:root:Epoch: 0545 val_loss: 0.703514 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0550 lr: [0.0005, 0.0005] train_loss: 0.616653 train_acc: 0.885350 train_f1: 0.885350 time: 0.3189s
INFO:root:Epoch: 0550 val_loss: 0.705332 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0555 lr: [0.0005, 0.0005] train_loss: 0.618328 train_acc: 0.885350 train_f1: 0.885350 time: 0.3190s
INFO:root:Epoch: 0555 val_loss: 0.712253 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0560 lr: [0.0005, 0.0005] train_loss: 0.617949 train_acc: 0.885350 train_f1: 0.885350 time: 0.3144s
INFO:root:Epoch: 0560 val_loss: 0.702259 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0565 lr: [0.0005, 0.0005] train_loss: 0.619907 train_acc: 0.885350 train_f1: 0.885350 time: 0.3184s
INFO:root:Epoch: 0565 val_loss: 0.704256 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Epoch: 0570 lr: [0.0005, 0.0005] train_loss: 0.620445 train_acc: 0.885350 train_f1: 0.885350 time: 0.3146s
INFO:root:Epoch: 0570 val_loss: 0.702639 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0575 lr: [0.0005, 0.0005] train_loss: 0.617631 train_acc: 0.885350 train_f1: 0.885350 time: 0.3261s
INFO:root:Epoch: 0575 val_loss: 0.704790 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0580 lr: [0.0005, 0.0005] train_loss: 0.618679 train_acc: 0.885350 train_f1: 0.885350 time: 0.3317s
INFO:root:Epoch: 0580 val_loss: 0.701479 val_acc: 0.870370 val_f1: 0.870370
INFO:root:Epoch: 0585 lr: [0.0005, 0.0005] train_loss: 0.618428 train_acc: 0.885350 train_f1: 0.885350 time: 0.3181s
INFO:root:Epoch: 0585 val_loss: 0.701123 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0590 lr: [0.0005, 0.0005] train_loss: 0.616734 train_acc: 0.885350 train_f1: 0.885350 time: 0.3135s
INFO:root:Epoch: 0590 val_loss: 0.705655 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0595 lr: [0.0005, 0.0005] train_loss: 0.616672 train_acc: 0.885350 train_f1: 0.885350 time: 0.3152s
INFO:root:Epoch: 0595 val_loss: 0.710254 val_acc: 0.851852 val_f1: 0.851852
INFO:root:Epoch: 0600 lr: [0.0005, 0.0005] train_loss: 0.616602 train_acc: 0.885350 train_f1: 0.885350 time: 0.3137s
INFO:root:Epoch: 0600 val_loss: 0.702296 val_acc: 0.833333 val_f1: 0.833333
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 202.1009s
INFO:root:Val set results: val_loss: 0.784741 val_acc: 0.888889 val_f1: 0.888889
INFO:root:Test set results: test_loss: 0.883414 test_acc: 0.796296 test_f1: 0.796296
