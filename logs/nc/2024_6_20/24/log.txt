INFO:root:Using: cuda:0
INFO:root:Using seed 8.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 57989
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 7.951102 train_acc: 0.586066 train_f1: 0.586066 time: 0.0517s
INFO:root:Epoch: 0005 val_loss: 7.927472 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 7.889648 train_acc: 0.586066 train_f1: 0.586066 time: 0.0520s
INFO:root:Epoch: 0010 val_loss: 7.854396 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 7.827145 train_acc: 0.586066 train_f1: 0.586066 time: 0.0551s
INFO:root:Epoch: 0015 val_loss: 7.779875 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 7.762688 train_acc: 0.586066 train_f1: 0.586066 time: 0.0539s
INFO:root:Epoch: 0020 val_loss: 7.702777 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 7.695088 train_acc: 0.586066 train_f1: 0.586066 time: 0.0518s
INFO:root:Epoch: 0025 val_loss: 7.621594 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 7.622689 train_acc: 0.586066 train_f1: 0.586066 time: 0.0554s
INFO:root:Epoch: 0030 val_loss: 7.534203 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 7.543053 train_acc: 0.586066 train_f1: 0.586066 time: 0.0510s
INFO:root:Epoch: 0035 val_loss: 7.437444 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 7.452300 train_acc: 0.586066 train_f1: 0.586066 time: 0.0510s
INFO:root:Epoch: 0040 val_loss: 7.326189 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 7.343524 train_acc: 0.586066 train_f1: 0.586066 time: 0.0548s
INFO:root:Epoch: 0045 val_loss: 7.191065 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 7.202298 train_acc: 0.586066 train_f1: 0.586066 time: 0.0515s
INFO:root:Epoch: 0050 val_loss: 7.011653 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 6.989086 train_acc: 0.586066 train_f1: 0.586066 time: 0.0503s
INFO:root:Epoch: 0055 val_loss: 6.727229 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 6.492688 train_acc: 0.586066 train_f1: 0.586066 time: 0.0517s
INFO:root:Epoch: 0060 val_loss: 5.885572 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 6.032400 train_acc: 0.586066 train_f1: 0.586066 time: 0.0513s
INFO:root:Epoch: 0065 val_loss: 5.956019 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 6.622503 train_acc: 0.586066 train_f1: 0.586066 time: 0.0505s
INFO:root:Epoch: 0070 val_loss: 6.412134 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 6.760573 train_acc: 0.586066 train_f1: 0.586066 time: 0.0509s
INFO:root:Epoch: 0075 val_loss: 6.547444 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 6.815736 train_acc: 0.586066 train_f1: 0.586066 time: 0.0523s
INFO:root:Epoch: 0080 val_loss: 6.602787 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 6.837758 train_acc: 0.586066 train_f1: 0.586066 time: 0.0510s
INFO:root:Epoch: 0085 val_loss: 6.624238 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 6.843557 train_acc: 0.586066 train_f1: 0.586066 time: 0.0504s
INFO:root:Epoch: 0090 val_loss: 6.628699 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 6.840703 train_acc: 0.586066 train_f1: 0.586066 time: 0.0496s
INFO:root:Epoch: 0095 val_loss: 6.624000 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 6.833062 train_acc: 0.586066 train_f1: 0.586066 time: 0.0514s
INFO:root:Epoch: 0100 val_loss: 6.614210 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0105 lr: [0.001, 0.001] train_loss: 6.822747 train_acc: 0.586066 train_f1: 0.586066 time: 0.0513s
INFO:root:Epoch: 0105 val_loss: 6.601578 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 6.810963 train_acc: 0.586066 train_f1: 0.586066 time: 0.0506s
INFO:root:Epoch: 0110 val_loss: 6.587391 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0115 lr: [0.001, 0.001] train_loss: 6.798406 train_acc: 0.586066 train_f1: 0.586066 time: 0.0507s
INFO:root:Epoch: 0115 val_loss: 6.572395 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 6.785484 train_acc: 0.586066 train_f1: 0.586066 time: 0.0516s
INFO:root:Epoch: 0120 val_loss: 6.557029 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0125 lr: [0.001, 0.001] train_loss: 6.772435 train_acc: 0.586066 train_f1: 0.586066 time: 0.0512s
INFO:root:Epoch: 0125 val_loss: 6.541547 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 6.759396 train_acc: 0.586066 train_f1: 0.586066 time: 0.0510s
INFO:root:Epoch: 0130 val_loss: 6.526097 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0135 lr: [0.001, 0.001] train_loss: 6.746447 train_acc: 0.586066 train_f1: 0.586066 time: 0.0514s
INFO:root:Epoch: 0135 val_loss: 6.510760 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 6.733628 train_acc: 0.586066 train_f1: 0.586066 time: 0.0504s
INFO:root:Epoch: 0140 val_loss: 6.495583 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0145 lr: [0.001, 0.001] train_loss: 6.720961 train_acc: 0.586066 train_f1: 0.586066 time: 0.0508s
INFO:root:Epoch: 0145 val_loss: 6.480588 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 6.708456 train_acc: 0.586066 train_f1: 0.586066 time: 0.0531s
INFO:root:Epoch: 0150 val_loss: 6.465782 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0155 lr: [0.001, 0.001] train_loss: 6.696114 train_acc: 0.586066 train_f1: 0.586066 time: 0.0505s
INFO:root:Epoch: 0155 val_loss: 6.451167 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 6.683933 train_acc: 0.586066 train_f1: 0.586066 time: 0.0511s
INFO:root:Epoch: 0160 val_loss: 6.436741 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0165 lr: [0.001, 0.001] train_loss: 6.671909 train_acc: 0.586066 train_f1: 0.586066 time: 0.0505s
INFO:root:Epoch: 0165 val_loss: 6.422498 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 6.660036 train_acc: 0.586066 train_f1: 0.586066 time: 0.0514s
INFO:root:Epoch: 0170 val_loss: 6.408431 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0175 lr: [0.001, 0.001] train_loss: 6.648309 train_acc: 0.586066 train_f1: 0.586066 time: 0.0506s
INFO:root:Epoch: 0175 val_loss: 6.394533 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 6.636722 train_acc: 0.586066 train_f1: 0.586066 time: 0.0506s
INFO:root:Epoch: 0180 val_loss: 6.380797 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0185 lr: [0.001, 0.001] train_loss: 6.625267 train_acc: 0.586066 train_f1: 0.586066 time: 0.0513s
INFO:root:Epoch: 0185 val_loss: 6.367217 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 6.613940 train_acc: 0.586066 train_f1: 0.586066 time: 0.0509s
INFO:root:Epoch: 0190 val_loss: 6.353784 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0195 lr: [0.001, 0.001] train_loss: 6.602735 train_acc: 0.586066 train_f1: 0.586066 time: 0.0514s
INFO:root:Epoch: 0195 val_loss: 6.340494 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0200 lr: [0.001, 0.001] train_loss: 6.591647 train_acc: 0.586066 train_f1: 0.586066 time: 0.0506s
INFO:root:Epoch: 0200 val_loss: 6.327339 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0205 lr: [0.001, 0.001] train_loss: 6.580671 train_acc: 0.586066 train_f1: 0.586066 time: 0.0543s
INFO:root:Epoch: 0205 val_loss: 6.314314 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0210 lr: [0.001, 0.001] train_loss: 6.569802 train_acc: 0.586066 train_f1: 0.586066 time: 0.0512s
INFO:root:Epoch: 0210 val_loss: 6.301413 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0215 lr: [0.001, 0.001] train_loss: 6.559035 train_acc: 0.586066 train_f1: 0.586066 time: 0.0506s
INFO:root:Epoch: 0215 val_loss: 6.288631 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0220 lr: [0.001, 0.001] train_loss: 6.548366 train_acc: 0.586066 train_f1: 0.586066 time: 0.0516s
INFO:root:Epoch: 0220 val_loss: 6.275963 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0225 lr: [0.001, 0.001] train_loss: 6.537792 train_acc: 0.586066 train_f1: 0.586066 time: 0.0516s
INFO:root:Epoch: 0225 val_loss: 6.263405 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0230 lr: [0.001, 0.001] train_loss: 6.527308 train_acc: 0.586066 train_f1: 0.586066 time: 0.0506s
INFO:root:Epoch: 0230 val_loss: 6.250952 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0235 lr: [0.001, 0.001] train_loss: 6.516910 train_acc: 0.586066 train_f1: 0.586066 time: 0.0508s
INFO:root:Epoch: 0235 val_loss: 6.238599 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0240 lr: [0.001, 0.001] train_loss: 6.506596 train_acc: 0.586066 train_f1: 0.586066 time: 0.0502s
INFO:root:Epoch: 0240 val_loss: 6.226343 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0245 lr: [0.001, 0.001] train_loss: 6.496361 train_acc: 0.586066 train_f1: 0.586066 time: 0.0510s
INFO:root:Epoch: 0245 val_loss: 6.214180 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0250 lr: [0.001, 0.001] train_loss: 6.486204 train_acc: 0.586066 train_f1: 0.586066 time: 0.0508s
INFO:root:Epoch: 0250 val_loss: 6.202106 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 17.6224s
INFO:root:Val set results: val_loss: 7.985503 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Test set results: test_loss: 7.984778 test_acc: 0.681818 test_f1: 0.681818
