INFO:root:Using: cuda:0
INFO:root:Using seed 8.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 57989
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 1.951102 train_acc: 0.586066 train_f1: 0.586066 time: 0.0420s
INFO:root:Epoch: 0005 val_loss: 1.927472 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.889648 train_acc: 0.586066 train_f1: 0.586066 time: 0.0425s
INFO:root:Epoch: 0010 val_loss: 1.854396 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 1.827145 train_acc: 0.586066 train_f1: 0.586066 time: 0.0429s
INFO:root:Epoch: 0015 val_loss: 1.779875 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.762688 train_acc: 0.586066 train_f1: 0.586066 time: 0.0425s
INFO:root:Epoch: 0020 val_loss: 1.702777 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 1.695088 train_acc: 0.586066 train_f1: 0.586066 time: 0.0421s
INFO:root:Epoch: 0025 val_loss: 1.621594 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.622689 train_acc: 0.586066 train_f1: 0.586066 time: 0.0416s
INFO:root:Epoch: 0030 val_loss: 1.534203 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 1.543053 train_acc: 0.586066 train_f1: 0.586066 time: 0.0419s
INFO:root:Epoch: 0035 val_loss: 1.437444 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.452300 train_acc: 0.586066 train_f1: 0.586066 time: 0.0487s
INFO:root:Epoch: 0040 val_loss: 1.326189 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 1.343524 train_acc: 0.586066 train_f1: 0.586066 time: 0.0433s
INFO:root:Epoch: 0045 val_loss: 1.191065 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.235094 train_acc: 0.586066 train_f1: 0.586066 time: 0.0425s
INFO:root:Epoch: 0050 val_loss: 1.094077 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 1.252998 train_acc: 0.586066 train_f1: 0.586066 time: 0.0423s
INFO:root:Epoch: 0055 val_loss: 1.105180 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.252800 train_acc: 0.586066 train_f1: 0.586066 time: 0.0462s
INFO:root:Epoch: 0060 val_loss: 1.101775 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 1.238478 train_acc: 0.586066 train_f1: 0.586066 time: 0.0445s
INFO:root:Epoch: 0065 val_loss: 1.087758 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.217494 train_acc: 0.586066 train_f1: 0.586066 time: 0.0424s
INFO:root:Epoch: 0070 val_loss: 1.075502 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 1.218808 train_acc: 0.586066 train_f1: 0.586066 time: 0.0427s
INFO:root:Epoch: 0075 val_loss: 1.080238 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.217025 train_acc: 0.586066 train_f1: 0.586066 time: 0.0418s
INFO:root:Epoch: 0080 val_loss: 1.079886 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 1.213301 train_acc: 0.586066 train_f1: 0.586066 time: 0.0418s
INFO:root:Epoch: 0085 val_loss: 1.076340 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.208209 train_acc: 0.586066 train_f1: 0.586066 time: 0.0424s
INFO:root:Epoch: 0090 val_loss: 1.070565 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 1.202016 train_acc: 0.586066 train_f1: 0.586066 time: 0.0417s
INFO:root:Epoch: 0095 val_loss: 1.063000 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 1.198257 train_acc: 0.586066 train_f1: 0.586066 time: 0.0536s
INFO:root:Epoch: 0100 val_loss: 1.059916 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0105 lr: [0.001, 0.001] train_loss: 1.193890 train_acc: 0.586066 train_f1: 0.586066 time: 0.0528s
INFO:root:Epoch: 0105 val_loss: 1.058440 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 1.189579 train_acc: 0.586066 train_f1: 0.586066 time: 0.0535s
INFO:root:Epoch: 0110 val_loss: 1.054912 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0115 lr: [0.001, 0.001] train_loss: 1.184608 train_acc: 0.586066 train_f1: 0.586066 time: 0.0525s
INFO:root:Epoch: 0115 val_loss: 1.052707 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 1.180796 train_acc: 0.586066 train_f1: 0.586066 time: 0.0548s
INFO:root:Epoch: 0120 val_loss: 1.049985 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0125 lr: [0.001, 0.001] train_loss: 1.176648 train_acc: 0.586066 train_f1: 0.586066 time: 0.0555s
INFO:root:Epoch: 0125 val_loss: 1.046103 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 1.172862 train_acc: 0.586066 train_f1: 0.586066 time: 0.0533s
INFO:root:Epoch: 0130 val_loss: 1.043107 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0135 lr: [0.001, 0.001] train_loss: 1.167666 train_acc: 0.586066 train_f1: 0.586066 time: 0.0548s
INFO:root:Epoch: 0135 val_loss: 1.039071 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 1.162793 train_acc: 0.586066 train_f1: 0.586066 time: 0.0559s
INFO:root:Epoch: 0140 val_loss: 1.035843 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0145 lr: [0.001, 0.001] train_loss: 1.160636 train_acc: 0.586066 train_f1: 0.586066 time: 0.0529s
INFO:root:Epoch: 0145 val_loss: 1.035037 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 1.153375 train_acc: 0.586066 train_f1: 0.586066 time: 0.0556s
INFO:root:Epoch: 0150 val_loss: 1.028312 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0155 lr: [0.001, 0.001] train_loss: 1.149283 train_acc: 0.586066 train_f1: 0.586066 time: 0.0526s
INFO:root:Epoch: 0155 val_loss: 1.022956 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 1.143544 train_acc: 0.586066 train_f1: 0.586066 time: 0.0526s
INFO:root:Epoch: 0160 val_loss: 1.020620 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0165 lr: [0.001, 0.001] train_loss: 1.137051 train_acc: 0.586066 train_f1: 0.586066 time: 0.0526s
INFO:root:Epoch: 0165 val_loss: 1.013759 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 1.130977 train_acc: 0.586066 train_f1: 0.586066 time: 0.0535s
INFO:root:Epoch: 0170 val_loss: 1.010293 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0175 lr: [0.001, 0.001] train_loss: 1.124069 train_acc: 0.586066 train_f1: 0.586066 time: 0.0521s
INFO:root:Epoch: 0175 val_loss: 1.003646 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 1.117504 train_acc: 0.586066 train_f1: 0.586066 time: 0.0533s
INFO:root:Epoch: 0180 val_loss: 0.998159 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0185 lr: [0.001, 0.001] train_loss: 1.112252 train_acc: 0.586066 train_f1: 0.586066 time: 0.0535s
INFO:root:Epoch: 0185 val_loss: 0.993193 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 1.103485 train_acc: 0.586066 train_f1: 0.586066 time: 0.0530s
INFO:root:Epoch: 0190 val_loss: 0.986437 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0195 lr: [0.001, 0.001] train_loss: 1.093583 train_acc: 0.586066 train_f1: 0.586066 time: 0.0529s
INFO:root:Epoch: 0195 val_loss: 0.981079 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0200 lr: [0.001, 0.001] train_loss: 1.084264 train_acc: 0.586066 train_f1: 0.586066 time: 0.0528s
INFO:root:Epoch: 0200 val_loss: 0.985339 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0205 lr: [0.001, 0.001] train_loss: 1.092720 train_acc: 0.586066 train_f1: 0.586066 time: 0.0536s
INFO:root:Epoch: 0205 val_loss: 0.975008 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0210 lr: [0.001, 0.001] train_loss: 1.085083 train_acc: 0.586066 train_f1: 0.586066 time: 0.0525s
INFO:root:Epoch: 0210 val_loss: 0.971201 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0215 lr: [0.001, 0.001] train_loss: 1.085735 train_acc: 0.586066 train_f1: 0.586066 time: 0.0533s
INFO:root:Epoch: 0215 val_loss: 0.973029 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0220 lr: [0.001, 0.001] train_loss: 1.078528 train_acc: 0.586066 train_f1: 0.586066 time: 0.0529s
INFO:root:Epoch: 0220 val_loss: 0.957330 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0225 lr: [0.001, 0.001] train_loss: 1.073393 train_acc: 0.586066 train_f1: 0.586066 time: 0.0549s
INFO:root:Epoch: 0225 val_loss: 0.953832 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0230 lr: [0.001, 0.001] train_loss: 1.084762 train_acc: 0.586066 train_f1: 0.586066 time: 0.0529s
INFO:root:Epoch: 0230 val_loss: 0.950333 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0235 lr: [0.001, 0.001] train_loss: 1.074061 train_acc: 0.586066 train_f1: 0.586066 time: 0.0535s
INFO:root:Epoch: 0235 val_loss: 0.954477 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0240 lr: [0.001, 0.001] train_loss: 1.076086 train_acc: 0.586066 train_f1: 0.586066 time: 0.0550s
INFO:root:Epoch: 0240 val_loss: 0.955018 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0245 lr: [0.001, 0.001] train_loss: 1.076780 train_acc: 0.586066 train_f1: 0.586066 time: 0.0537s
INFO:root:Epoch: 0245 val_loss: 0.952901 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0250 lr: [0.001, 0.001] train_loss: 1.072627 train_acc: 0.586066 train_f1: 0.586066 time: 0.0539s
INFO:root:Epoch: 0250 val_loss: 0.950326 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 18.2211s
INFO:root:Val set results: val_loss: 1.985503 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Test set results: test_loss: 1.984778 test_acc: 0.681818 test_f1: 0.681818
