INFO:root:Using: cuda:0
INFO:root:Using seed 8.
INFO:root:Dataset: film
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=932, out_features=64, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (6): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (7): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 68645
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 1.9693 train_acc: 0.2776 train_f1: 0.2776 time: 0.8724s
INFO:root:Epoch: 0005 val_loss: 1.9617 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.9307 train_acc: 0.2776 train_f1: 0.2776 time: 0.8726s
INFO:root:Epoch: 0010 val_loss: 1.9232 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 1.8916 train_acc: 0.2776 train_f1: 0.2776 time: 0.8753s
INFO:root:Epoch: 0015 val_loss: 1.8840 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.8513 train_acc: 0.2776 train_f1: 0.2776 time: 0.8776s
INFO:root:Epoch: 0020 val_loss: 1.8435 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 1.8091 train_acc: 0.2776 train_f1: 0.2776 time: 0.8718s
INFO:root:Epoch: 0025 val_loss: 1.8008 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.7639 train_acc: 0.2776 train_f1: 0.2776 time: 0.8724s
INFO:root:Epoch: 0030 val_loss: 1.7549 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 1.7139 train_acc: 0.2776 train_f1: 0.2776 time: 0.8713s
INFO:root:Epoch: 0035 val_loss: 1.7038 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.6567 train_acc: 0.2776 train_f1: 0.2776 time: 0.8716s
INFO:root:Epoch: 0040 val_loss: 1.6446 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 1.5872 train_acc: 0.2776 train_f1: 0.2776 time: 0.8703s
INFO:root:Epoch: 0045 val_loss: 1.5716 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.5479 train_acc: 0.2776 train_f1: 0.2776 time: 0.8784s
INFO:root:Epoch: 0050 val_loss: 1.5542 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 1.5656 train_acc: 0.2987 train_f1: 0.2987 time: 0.8741s
INFO:root:Epoch: 0055 val_loss: 1.5664 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.5599 train_acc: 0.2987 train_f1: 0.2987 time: 0.8756s
INFO:root:Epoch: 0060 val_loss: 1.5556 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 1.5501 train_acc: 0.2987 train_f1: 0.2987 time: 0.8758s
INFO:root:Epoch: 0065 val_loss: 1.5463 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.5497 train_acc: 0.2987 train_f1: 0.2987 time: 0.8744s
INFO:root:Epoch: 0070 val_loss: 1.5470 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 1.5401 train_acc: 0.2987 train_f1: 0.2987 time: 0.8773s
INFO:root:Epoch: 0075 val_loss: 1.5425 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.5385 train_acc: 0.2776 train_f1: 0.2776 time: 0.8759s
INFO:root:Epoch: 0080 val_loss: 1.5420 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 1.5393 train_acc: 0.2776 train_f1: 0.2776 time: 0.8744s
INFO:root:Epoch: 0085 val_loss: 1.5417 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.5372 train_acc: 0.2987 train_f1: 0.2987 time: 0.8739s
INFO:root:Epoch: 0090 val_loss: 1.5395 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 1.5371 train_acc: 0.2987 train_f1: 0.2987 time: 0.8751s
INFO:root:Epoch: 0095 val_loss: 1.5390 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 1.5358 train_acc: 0.2987 train_f1: 0.2987 time: 0.8740s
INFO:root:Epoch: 0100 val_loss: 1.5380 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 123.7592s
INFO:root:Val set results: val_loss: 1.5663 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Test set results: test_loss: 1.5734 test_acc: 0.3046 test_f1: 0.3046
