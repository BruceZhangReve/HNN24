INFO:root:Using: cuda:0
INFO:root:Using seed 7.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 57989
INFO:root:Epoch: 0010 lr: [0.0001, 0.0001] train_loss: 1.988782 train_acc: 0.586066 train_f1: 0.586066 time: 0.0524s
INFO:root:Epoch: 0010 val_loss: 1.985225 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.0001, 0.0001] train_loss: 1.976327 train_acc: 0.586066 train_f1: 0.586066 time: 0.0520s
INFO:root:Epoch: 0020 val_loss: 1.970460 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.0001, 0.0001] train_loss: 1.963876 train_acc: 0.586066 train_f1: 0.586066 time: 0.0534s
INFO:root:Epoch: 0030 val_loss: 1.955697 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.0001, 0.0001] train_loss: 1.951420 train_acc: 0.586066 train_f1: 0.586066 time: 0.0447s
INFO:root:Epoch: 0040 val_loss: 1.940926 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.0001, 0.0001] train_loss: 1.938951 train_acc: 0.586066 train_f1: 0.586066 time: 0.0452s
INFO:root:Epoch: 0050 val_loss: 1.926137 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.0001, 0.0001] train_loss: 1.926456 train_acc: 0.586066 train_f1: 0.586066 time: 0.0447s
INFO:root:Epoch: 0060 val_loss: 1.911316 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.0001, 0.0001] train_loss: 1.913927 train_acc: 0.586066 train_f1: 0.586066 time: 0.0448s
INFO:root:Epoch: 0070 val_loss: 1.896451 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.0001, 0.0001] train_loss: 1.901351 train_acc: 0.586066 train_f1: 0.586066 time: 0.0485s
INFO:root:Epoch: 0080 val_loss: 1.881528 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.0001, 0.0001] train_loss: 1.888717 train_acc: 0.586066 train_f1: 0.586066 time: 0.0468s
INFO:root:Epoch: 0090 val_loss: 1.866534 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.0001, 0.0001] train_loss: 1.876015 train_acc: 0.586066 train_f1: 0.586066 time: 0.0453s
INFO:root:Epoch: 0100 val_loss: 1.851457 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.0001, 0.0001] train_loss: 1.863232 train_acc: 0.586066 train_f1: 0.586066 time: 0.0625s
INFO:root:Epoch: 0110 val_loss: 1.836281 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.0001, 0.0001] train_loss: 1.850356 train_acc: 0.586066 train_f1: 0.586066 time: 0.0516s
INFO:root:Epoch: 0120 val_loss: 1.820992 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.0001, 0.0001] train_loss: 1.837375 train_acc: 0.586066 train_f1: 0.586066 time: 0.0510s
INFO:root:Epoch: 0130 val_loss: 1.805576 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.0001, 0.0001] train_loss: 1.824276 train_acc: 0.586066 train_f1: 0.586066 time: 0.0523s
INFO:root:Epoch: 0140 val_loss: 1.790017 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.0001, 0.0001] train_loss: 1.811045 train_acc: 0.586066 train_f1: 0.586066 time: 0.0514s
INFO:root:Epoch: 0150 val_loss: 1.774299 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.0001, 0.0001] train_loss: 1.797669 train_acc: 0.586066 train_f1: 0.586066 time: 0.0511s
INFO:root:Epoch: 0160 val_loss: 1.758406 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0170 lr: [0.0001, 0.0001] train_loss: 1.784132 train_acc: 0.586066 train_f1: 0.586066 time: 0.0519s
INFO:root:Epoch: 0170 val_loss: 1.742319 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0180 lr: [0.0001, 0.0001] train_loss: 1.770418 train_acc: 0.586066 train_f1: 0.586066 time: 0.0534s
INFO:root:Epoch: 0180 val_loss: 1.726019 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0190 lr: [0.0001, 0.0001] train_loss: 1.756510 train_acc: 0.586066 train_f1: 0.586066 time: 0.0515s
INFO:root:Epoch: 0190 val_loss: 1.709486 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0200 lr: [0.0001, 0.0001] train_loss: 1.742391 train_acc: 0.586066 train_f1: 0.586066 time: 0.0517s
INFO:root:Epoch: 0200 val_loss: 1.692697 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0210 lr: [0.0001, 0.0001] train_loss: 1.728040 train_acc: 0.586066 train_f1: 0.586066 time: 0.0516s
INFO:root:Epoch: 0210 val_loss: 1.675630 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0220 lr: [0.0001, 0.0001] train_loss: 1.713435 train_acc: 0.586066 train_f1: 0.586066 time: 0.0515s
INFO:root:Epoch: 0220 val_loss: 1.658258 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0230 lr: [0.0001, 0.0001] train_loss: 1.698554 train_acc: 0.586066 train_f1: 0.586066 time: 0.0507s
INFO:root:Epoch: 0230 val_loss: 1.640553 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0240 lr: [0.0001, 0.0001] train_loss: 1.683370 train_acc: 0.586066 train_f1: 0.586066 time: 0.0548s
INFO:root:Epoch: 0240 val_loss: 1.622485 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0250 lr: [0.0001, 0.0001] train_loss: 1.667855 train_acc: 0.586066 train_f1: 0.586066 time: 0.0541s
INFO:root:Epoch: 0250 val_loss: 1.604019 val_acc: 0.659091 val_f1: 0.659091
