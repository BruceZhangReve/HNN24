INFO:root:Using: cuda:0
INFO:root:Using seed 8.
INFO:root:Dataset: film
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=932, out_features=64, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (6): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (7): BLayer(
              (linear): BLinear(in_features=64, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 68645
INFO:root:Epoch: 0005 lr: [0.0005, 0.0005] train_loss: 1.9846 train_acc: 0.2776 train_f1: 0.2776 time: 0.8753s
INFO:root:Epoch: 0005 val_loss: 1.9809 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0010 lr: [0.0005, 0.0005] train_loss: 1.9654 train_acc: 0.2776 train_f1: 0.2776 time: 0.8751s
INFO:root:Epoch: 0010 val_loss: 1.9617 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0015 lr: [0.0005, 0.0005] train_loss: 1.9462 train_acc: 0.2776 train_f1: 0.2776 time: 0.8704s
INFO:root:Epoch: 0015 val_loss: 1.9425 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0020 lr: [0.0005, 0.0005] train_loss: 1.9268 train_acc: 0.2776 train_f1: 0.2776 time: 0.8710s
INFO:root:Epoch: 0020 val_loss: 1.9231 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0025 lr: [0.0005, 0.0005] train_loss: 1.9073 train_acc: 0.2776 train_f1: 0.2776 time: 0.8712s
INFO:root:Epoch: 0025 val_loss: 1.9036 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0030 lr: [0.0005, 0.0005] train_loss: 1.8874 train_acc: 0.2776 train_f1: 0.2776 time: 0.8700s
INFO:root:Epoch: 0030 val_loss: 1.8837 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0035 lr: [0.0005, 0.0005] train_loss: 1.8672 train_acc: 0.2776 train_f1: 0.2776 time: 0.8750s
INFO:root:Epoch: 0035 val_loss: 1.8635 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0040 lr: [0.0005, 0.0005] train_loss: 1.8465 train_acc: 0.2776 train_f1: 0.2776 time: 0.8743s
INFO:root:Epoch: 0040 val_loss: 1.8427 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0045 lr: [0.0005, 0.0005] train_loss: 1.8251 train_acc: 0.2776 train_f1: 0.2776 time: 0.8745s
INFO:root:Epoch: 0045 val_loss: 1.8212 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0050 lr: [0.0005, 0.0005] train_loss: 1.8029 train_acc: 0.2776 train_f1: 0.2776 time: 0.8746s
INFO:root:Epoch: 0050 val_loss: 1.7988 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0055 lr: [0.0005, 0.0005] train_loss: 1.7796 train_acc: 0.2776 train_f1: 0.2776 time: 0.8745s
INFO:root:Epoch: 0055 val_loss: 1.7753 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0060 lr: [0.0005, 0.0005] train_loss: 1.7551 train_acc: 0.2776 train_f1: 0.2776 time: 0.8748s
INFO:root:Epoch: 0060 val_loss: 1.7505 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0065 lr: [0.0005, 0.0005] train_loss: 1.7289 train_acc: 0.2776 train_f1: 0.2776 time: 0.8749s
INFO:root:Epoch: 0065 val_loss: 1.7239 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0070 lr: [0.0005, 0.0005] train_loss: 1.7006 train_acc: 0.2776 train_f1: 0.2776 time: 0.8744s
INFO:root:Epoch: 0070 val_loss: 1.6952 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0075 lr: [0.0005, 0.0005] train_loss: 1.6696 train_acc: 0.2776 train_f1: 0.2776 time: 0.8737s
INFO:root:Epoch: 0075 val_loss: 1.6635 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0080 lr: [0.0005, 0.0005] train_loss: 1.6349 train_acc: 0.2776 train_f1: 0.2776 time: 0.8750s
INFO:root:Epoch: 0080 val_loss: 1.6279 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0085 lr: [0.0005, 0.0005] train_loss: 1.5951 train_acc: 0.2776 train_f1: 0.2776 time: 0.8744s
INFO:root:Epoch: 0085 val_loss: 1.5868 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0090 lr: [0.0005, 0.0005] train_loss: 1.5578 train_acc: 0.2776 train_f1: 0.2776 time: 0.8742s
INFO:root:Epoch: 0090 val_loss: 1.5528 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0095 lr: [0.0005, 0.0005] train_loss: 1.5459 train_acc: 0.2776 train_f1: 0.2776 time: 0.8779s
INFO:root:Epoch: 0095 val_loss: 1.5488 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0100 lr: [0.0005, 0.0005] train_loss: 1.5529 train_acc: 0.2987 train_f1: 0.2987 time: 0.8778s
INFO:root:Epoch: 0100 val_loss: 1.5541 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0105 lr: [0.0005, 0.0005] train_loss: 1.5496 train_acc: 0.2987 train_f1: 0.2987 time: 0.8771s
INFO:root:Epoch: 0105 val_loss: 1.5485 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0110 lr: [0.0005, 0.0005] train_loss: 1.5424 train_acc: 0.2987 train_f1: 0.2987 time: 0.8772s
INFO:root:Epoch: 0110 val_loss: 1.5417 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0115 lr: [0.0005, 0.0005] train_loss: 1.5433 train_acc: 0.2987 train_f1: 0.2987 time: 0.8773s
INFO:root:Epoch: 0115 val_loss: 1.5422 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0120 lr: [0.0005, 0.0005] train_loss: 1.5396 train_acc: 0.2987 train_f1: 0.2987 time: 0.8764s
INFO:root:Epoch: 0120 val_loss: 1.5413 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0125 lr: [0.0005, 0.0005] train_loss: 1.5375 train_acc: 0.2987 train_f1: 0.2987 time: 0.8772s
INFO:root:Epoch: 0125 val_loss: 1.5390 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0130 lr: [0.0005, 0.0005] train_loss: 1.5368 train_acc: 0.2987 train_f1: 0.2987 time: 0.8777s
INFO:root:Epoch: 0130 val_loss: 1.5399 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0135 lr: [0.0005, 0.0005] train_loss: 1.5367 train_acc: 0.2776 train_f1: 0.2776 time: 0.8758s
INFO:root:Epoch: 0135 val_loss: 1.5394 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0140 lr: [0.0005, 0.0005] train_loss: 1.5360 train_acc: 0.2987 train_f1: 0.2987 time: 0.8763s
INFO:root:Epoch: 0140 val_loss: 1.5384 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0145 lr: [0.0005, 0.0005] train_loss: 1.5358 train_acc: 0.2987 train_f1: 0.2987 time: 0.8775s
INFO:root:Epoch: 0145 val_loss: 1.5382 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0150 lr: [0.0005, 0.0005] train_loss: 1.5355 train_acc: 0.2776 train_f1: 0.2776 time: 0.8764s
INFO:root:Epoch: 0150 val_loss: 1.5378 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0155 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8769s
INFO:root:Epoch: 0155 val_loss: 1.5379 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0160 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2562 train_f1: 0.2562 time: 0.8768s
INFO:root:Epoch: 0160 val_loss: 1.5377 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0165 lr: [0.0005, 0.0005] train_loss: 1.5355 train_acc: 0.2987 train_f1: 0.2987 time: 0.8770s
INFO:root:Epoch: 0165 val_loss: 1.5380 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0170 lr: [0.0005, 0.0005] train_loss: 1.5352 train_acc: 0.2776 train_f1: 0.2776 time: 0.8768s
INFO:root:Epoch: 0170 val_loss: 1.5382 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0175 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8764s
INFO:root:Epoch: 0175 val_loss: 1.5381 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0180 lr: [0.0005, 0.0005] train_loss: 1.5357 train_acc: 0.2776 train_f1: 0.2776 time: 0.8767s
INFO:root:Epoch: 0180 val_loss: 1.5381 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0185 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8772s
INFO:root:Epoch: 0185 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0190 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2776 train_f1: 0.2776 time: 0.8764s
INFO:root:Epoch: 0190 val_loss: 1.5377 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0195 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8776s
INFO:root:Epoch: 0195 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0200 lr: [0.0005, 0.0005] train_loss: 1.5353 train_acc: 0.2987 train_f1: 0.2987 time: 0.8770s
INFO:root:Epoch: 0200 val_loss: 1.5379 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0205 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2562 train_f1: 0.2562 time: 0.8762s
INFO:root:Epoch: 0205 val_loss: 1.5380 val_acc: 0.2380 val_f1: 0.2380
INFO:root:Epoch: 0210 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2776 train_f1: 0.2776 time: 0.8775s
INFO:root:Epoch: 0210 val_loss: 1.5382 val_acc: 0.2380 val_f1: 0.2380
INFO:root:Epoch: 0215 lr: [0.0005, 0.0005] train_loss: 1.5353 train_acc: 0.2987 train_f1: 0.2987 time: 0.8781s
INFO:root:Epoch: 0215 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0220 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8764s
INFO:root:Epoch: 0220 val_loss: 1.5379 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0225 lr: [0.0005, 0.0005] train_loss: 1.5352 train_acc: 0.2776 train_f1: 0.2776 time: 0.8762s
INFO:root:Epoch: 0225 val_loss: 1.5377 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0230 lr: [0.0005, 0.0005] train_loss: 1.5355 train_acc: 0.2987 train_f1: 0.2987 time: 0.8767s
INFO:root:Epoch: 0230 val_loss: 1.5380 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0235 lr: [0.0005, 0.0005] train_loss: 1.5353 train_acc: 0.2776 train_f1: 0.2776 time: 0.8761s
INFO:root:Epoch: 0235 val_loss: 1.5380 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0240 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8774s
INFO:root:Epoch: 0240 val_loss: 1.5382 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0245 lr: [0.0005, 0.0005] train_loss: 1.5355 train_acc: 0.2776 train_f1: 0.2776 time: 0.8761s
INFO:root:Epoch: 0245 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0250 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2562 train_f1: 0.2562 time: 0.8767s
INFO:root:Epoch: 0250 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0255 lr: [0.0005, 0.0005] train_loss: 1.5357 train_acc: 0.2987 train_f1: 0.2987 time: 0.8771s
INFO:root:Epoch: 0255 val_loss: 1.5382 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0260 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8768s
INFO:root:Epoch: 0260 val_loss: 1.5379 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0265 lr: [0.0005, 0.0005] train_loss: 1.5352 train_acc: 0.2987 train_f1: 0.2987 time: 0.8771s
INFO:root:Epoch: 0265 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0270 lr: [0.0005, 0.0005] train_loss: 1.5351 train_acc: 0.2562 train_f1: 0.2562 time: 0.8773s
INFO:root:Epoch: 0270 val_loss: 1.5382 val_acc: 0.2380 val_f1: 0.2380
INFO:root:Epoch: 0275 lr: [0.0005, 0.0005] train_loss: 1.5354 train_acc: 0.2987 train_f1: 0.2987 time: 0.8773s
INFO:root:Epoch: 0275 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0280 lr: [0.0005, 0.0005] train_loss: 1.5352 train_acc: 0.2987 train_f1: 0.2987 time: 0.8772s
INFO:root:Epoch: 0280 val_loss: 1.5378 val_acc: 0.2769 val_f1: 0.2769
INFO:root:Epoch: 0285 lr: [0.0005, 0.0005] train_loss: 1.5353 train_acc: 0.2987 train_f1: 0.2987 time: 0.8762s
INFO:root:Epoch: 0285 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Epoch: 0290 lr: [0.0005, 0.0005] train_loss: 1.5353 train_acc: 0.2776 train_f1: 0.2776 time: 0.8779s
INFO:root:Epoch: 0290 val_loss: 1.5379 val_acc: 0.2380 val_f1: 0.2380
INFO:root:Epoch: 0295 lr: [0.0005, 0.0005] train_loss: 1.5355 train_acc: 0.2987 train_f1: 0.2987 time: 0.8773s
INFO:root:Epoch: 0295 val_loss: 1.5378 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 353.2455s
INFO:root:Val set results: val_loss: 1.5537 val_acc: 0.3163 val_f1: 0.3163
INFO:root:Test set results: test_loss: 1.5605 test_acc: 0.3046 test_f1: 0.3046
