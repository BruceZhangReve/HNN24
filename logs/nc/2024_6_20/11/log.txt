INFO:root:Using: cuda:0
INFO:root:Using seed 7.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (6): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (7): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (8): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (9): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 60229
INFO:root:Epoch: 0010 lr: [1e-05, 1e-05] train_loss: 1.9988 train_acc: 0.5861 train_f1: 0.5861 time: 0.0620s
INFO:root:Epoch: 0010 val_loss: 1.9985 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0020 lr: [1e-05, 1e-05] train_loss: 1.9976 train_acc: 0.5861 train_f1: 0.5861 time: 0.0626s
INFO:root:Epoch: 0020 val_loss: 1.9969 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0030 lr: [1e-05, 1e-05] train_loss: 1.9963 train_acc: 0.5861 train_f1: 0.5861 time: 0.0623s
INFO:root:Epoch: 0030 val_loss: 1.9954 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0040 lr: [1e-05, 1e-05] train_loss: 1.9950 train_acc: 0.5861 train_f1: 0.5861 time: 0.0629s
INFO:root:Epoch: 0040 val_loss: 1.9939 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0050 lr: [1e-05, 1e-05] train_loss: 1.9937 train_acc: 0.5861 train_f1: 0.5861 time: 0.0641s
INFO:root:Epoch: 0050 val_loss: 1.9923 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0060 lr: [1e-05, 1e-05] train_loss: 1.9924 train_acc: 0.5861 train_f1: 0.5861 time: 0.0629s
INFO:root:Epoch: 0060 val_loss: 1.9908 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0070 lr: [1e-05, 1e-05] train_loss: 1.9911 train_acc: 0.5861 train_f1: 0.5861 time: 0.0633s
INFO:root:Epoch: 0070 val_loss: 1.9893 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0080 lr: [1e-05, 1e-05] train_loss: 1.9898 train_acc: 0.5861 train_f1: 0.5861 time: 0.0624s
INFO:root:Epoch: 0080 val_loss: 1.9877 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0090 lr: [1e-05, 1e-05] train_loss: 1.9885 train_acc: 0.5861 train_f1: 0.5861 time: 0.0628s
INFO:root:Epoch: 0090 val_loss: 1.9862 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0100 lr: [1e-05, 1e-05] train_loss: 1.9872 train_acc: 0.5861 train_f1: 0.5861 time: 0.0625s
INFO:root:Epoch: 0100 val_loss: 1.9847 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0110 lr: [1e-05, 1e-05] train_loss: 1.9860 train_acc: 0.5861 train_f1: 0.5861 time: 0.0619s
INFO:root:Epoch: 0110 val_loss: 1.9831 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0120 lr: [1e-05, 1e-05] train_loss: 1.9847 train_acc: 0.5861 train_f1: 0.5861 time: 0.0623s
INFO:root:Epoch: 0120 val_loss: 1.9816 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0130 lr: [1e-05, 1e-05] train_loss: 1.9834 train_acc: 0.5861 train_f1: 0.5861 time: 0.0639s
INFO:root:Epoch: 0130 val_loss: 1.9801 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0140 lr: [1e-05, 1e-05] train_loss: 1.9821 train_acc: 0.5861 train_f1: 0.5861 time: 0.0626s
INFO:root:Epoch: 0140 val_loss: 1.9785 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0150 lr: [1e-05, 1e-05] train_loss: 1.9808 train_acc: 0.5861 train_f1: 0.5861 time: 0.0636s
INFO:root:Epoch: 0150 val_loss: 1.9770 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0160 lr: [1e-05, 1e-05] train_loss: 1.9795 train_acc: 0.5861 train_f1: 0.5861 time: 0.0630s
INFO:root:Epoch: 0160 val_loss: 1.9755 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0170 lr: [1e-05, 1e-05] train_loss: 1.9782 train_acc: 0.5861 train_f1: 0.5861 time: 0.0622s
INFO:root:Epoch: 0170 val_loss: 1.9739 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0180 lr: [1e-05, 1e-05] train_loss: 1.9769 train_acc: 0.5861 train_f1: 0.5861 time: 0.0647s
INFO:root:Epoch: 0180 val_loss: 1.9724 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0190 lr: [1e-05, 1e-05] train_loss: 1.9756 train_acc: 0.5861 train_f1: 0.5861 time: 0.0640s
INFO:root:Epoch: 0190 val_loss: 1.9709 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0200 lr: [1e-05, 1e-05] train_loss: 1.9743 train_acc: 0.5861 train_f1: 0.5861 time: 0.0639s
INFO:root:Epoch: 0200 val_loss: 1.9693 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0210 lr: [1e-05, 1e-05] train_loss: 1.9731 train_acc: 0.5861 train_f1: 0.5861 time: 0.0645s
INFO:root:Epoch: 0210 val_loss: 1.9678 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0220 lr: [1e-05, 1e-05] train_loss: 1.9718 train_acc: 0.5861 train_f1: 0.5861 time: 0.0637s
INFO:root:Epoch: 0220 val_loss: 1.9662 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Epoch: 0230 lr: [1e-05, 1e-05] train_loss: 1.9705 train_acc: 0.5861 train_f1: 0.5861 time: 0.0622s
INFO:root:Epoch: 0230 val_loss: 1.9647 val_acc: 0.6591 val_f1: 0.6591
