INFO:root:Using: cuda:0
INFO:root:Using seed 8.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 57989
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 0.751102 train_acc: 0.586066 train_f1: 0.586066 time: 0.0426s
INFO:root:Epoch: 0005 val_loss: 0.727472 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 0.689648 train_acc: 0.586066 train_f1: 0.586066 time: 0.0424s
INFO:root:Epoch: 0010 val_loss: 0.654396 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 0.627145 train_acc: 0.586066 train_f1: 0.586066 time: 0.0546s
INFO:root:Epoch: 0015 val_loss: 0.579875 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 0.562688 train_acc: 0.586066 train_f1: 0.586066 time: 0.0425s
INFO:root:Epoch: 0020 val_loss: 0.502777 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 0.496752 train_acc: 0.586066 train_f1: 0.586066 time: 0.0423s
INFO:root:Epoch: 0025 val_loss: 0.436289 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 0.496462 train_acc: 0.586066 train_f1: 0.586066 time: 0.0427s
INFO:root:Epoch: 0030 val_loss: 0.437451 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 0.491662 train_acc: 0.586066 train_f1: 0.586066 time: 0.0436s
INFO:root:Epoch: 0035 val_loss: 0.431924 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 0.483170 train_acc: 0.586066 train_f1: 0.586066 time: 0.0461s
INFO:root:Epoch: 0040 val_loss: 0.426742 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 0.480932 train_acc: 0.586066 train_f1: 0.586066 time: 0.0422s
INFO:root:Epoch: 0045 val_loss: 0.426456 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 0.477437 train_acc: 0.586066 train_f1: 0.586066 time: 0.0425s
INFO:root:Epoch: 0050 val_loss: 0.424272 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 0.473028 train_acc: 0.586066 train_f1: 0.586066 time: 0.0431s
INFO:root:Epoch: 0055 val_loss: 0.420766 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 0.467932 train_acc: 0.586066 train_f1: 0.586066 time: 0.0435s
INFO:root:Epoch: 0060 val_loss: 0.416340 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 0.462643 train_acc: 0.586066 train_f1: 0.586066 time: 0.0427s
INFO:root:Epoch: 0065 val_loss: 0.412504 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 0.457972 train_acc: 0.586066 train_f1: 0.586066 time: 0.0421s
INFO:root:Epoch: 0070 val_loss: 0.410046 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 0.453763 train_acc: 0.586066 train_f1: 0.586066 time: 0.0430s
INFO:root:Epoch: 0075 val_loss: 0.406013 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 0.450233 train_acc: 0.586066 train_f1: 0.586066 time: 0.0432s
INFO:root:Epoch: 0080 val_loss: 0.402669 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 0.446575 train_acc: 0.586066 train_f1: 0.586066 time: 0.0421s
INFO:root:Epoch: 0085 val_loss: 0.400239 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 0.442357 train_acc: 0.586066 train_f1: 0.586066 time: 0.0424s
INFO:root:Epoch: 0090 val_loss: 0.395839 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 0.437688 train_acc: 0.586066 train_f1: 0.586066 time: 0.0422s
INFO:root:Epoch: 0095 val_loss: 0.391777 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 0.433455 train_acc: 0.586066 train_f1: 0.586066 time: 0.0422s
INFO:root:Epoch: 0100 val_loss: 0.388079 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0105 lr: [0.001, 0.001] train_loss: 0.431899 train_acc: 0.586066 train_f1: 0.586066 time: 0.0422s
INFO:root:Epoch: 0105 val_loss: 0.386076 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 0.430554 train_acc: 0.586066 train_f1: 0.586066 time: 0.0426s
INFO:root:Epoch: 0110 val_loss: 0.383948 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0115 lr: [0.001, 0.001] train_loss: 0.429682 train_acc: 0.586066 train_f1: 0.586066 time: 0.0448s
INFO:root:Epoch: 0115 val_loss: 0.381580 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 0.428747 train_acc: 0.586066 train_f1: 0.586066 time: 0.0433s
INFO:root:Epoch: 0120 val_loss: 0.379849 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0125 lr: [0.001, 0.001] train_loss: 0.428665 train_acc: 0.586066 train_f1: 0.586066 time: 0.0430s
INFO:root:Epoch: 0125 val_loss: 0.379103 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 0.428612 train_acc: 0.586066 train_f1: 0.586066 time: 0.0424s
INFO:root:Epoch: 0130 val_loss: 0.378645 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0135 lr: [0.001, 0.001] train_loss: 0.429158 train_acc: 0.586066 train_f1: 0.586066 time: 0.0433s
INFO:root:Epoch: 0135 val_loss: 0.378973 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 0.428882 train_acc: 0.586066 train_f1: 0.586066 time: 0.0437s
INFO:root:Epoch: 0140 val_loss: 0.378250 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0145 lr: [0.001, 0.001] train_loss: 0.428929 train_acc: 0.586066 train_f1: 0.586066 time: 0.0424s
INFO:root:Epoch: 0145 val_loss: 0.378125 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 0.428605 train_acc: 0.586066 train_f1: 0.586066 time: 0.0425s
INFO:root:Epoch: 0150 val_loss: 0.379090 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0155 lr: [0.001, 0.001] train_loss: 0.428582 train_acc: 0.586066 train_f1: 0.586066 time: 0.0432s
INFO:root:Epoch: 0155 val_loss: 0.380390 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 0.429398 train_acc: 0.586066 train_f1: 0.586066 time: 0.0432s
INFO:root:Epoch: 0160 val_loss: 0.379907 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0165 lr: [0.001, 0.001] train_loss: 0.429803 train_acc: 0.586066 train_f1: 0.586066 time: 0.0422s
INFO:root:Epoch: 0165 val_loss: 0.380949 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 0.428683 train_acc: 0.586066 train_f1: 0.586066 time: 0.0443s
INFO:root:Epoch: 0170 val_loss: 0.380176 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0175 lr: [0.001, 0.001] train_loss: 0.428687 train_acc: 0.586066 train_f1: 0.586066 time: 0.0423s
INFO:root:Epoch: 0175 val_loss: 0.380323 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 0.428955 train_acc: 0.586066 train_f1: 0.586066 time: 0.0423s
INFO:root:Epoch: 0180 val_loss: 0.380624 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0185 lr: [0.001, 0.001] train_loss: 0.428650 train_acc: 0.586066 train_f1: 0.586066 time: 0.0432s
INFO:root:Epoch: 0185 val_loss: 0.380195 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 0.429087 train_acc: 0.586066 train_f1: 0.586066 time: 0.0428s
INFO:root:Epoch: 0190 val_loss: 0.380503 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0195 lr: [0.001, 0.001] train_loss: 0.429393 train_acc: 0.586066 train_f1: 0.586066 time: 0.0434s
INFO:root:Epoch: 0195 val_loss: 0.380418 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0200 lr: [0.001, 0.001] train_loss: 0.429344 train_acc: 0.586066 train_f1: 0.586066 time: 0.0434s
INFO:root:Epoch: 0200 val_loss: 0.380187 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0205 lr: [0.001, 0.001] train_loss: 0.428689 train_acc: 0.586066 train_f1: 0.586066 time: 0.0435s
INFO:root:Epoch: 0205 val_loss: 0.380367 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0210 lr: [0.001, 0.001] train_loss: 0.428576 train_acc: 0.586066 train_f1: 0.586066 time: 0.0431s
INFO:root:Epoch: 0210 val_loss: 0.380174 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0215 lr: [0.001, 0.001] train_loss: 0.428730 train_acc: 0.586066 train_f1: 0.586066 time: 0.0445s
INFO:root:Epoch: 0215 val_loss: 0.380335 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0220 lr: [0.001, 0.001] train_loss: 0.428657 train_acc: 0.586066 train_f1: 0.586066 time: 0.0434s
INFO:root:Epoch: 0220 val_loss: 0.380227 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0225 lr: [0.001, 0.001] train_loss: 0.428683 train_acc: 0.586066 train_f1: 0.586066 time: 0.0426s
INFO:root:Epoch: 0225 val_loss: 0.379971 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0230 lr: [0.001, 0.001] train_loss: 0.428552 train_acc: 0.586066 train_f1: 0.586066 time: 0.0425s
INFO:root:Epoch: 0230 val_loss: 0.379942 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0235 lr: [0.001, 0.001] train_loss: 0.428785 train_acc: 0.586066 train_f1: 0.586066 time: 0.0432s
INFO:root:Epoch: 0235 val_loss: 0.379860 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0240 lr: [0.001, 0.001] train_loss: 0.428511 train_acc: 0.586066 train_f1: 0.586066 time: 0.0430s
INFO:root:Epoch: 0240 val_loss: 0.380139 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0245 lr: [0.001, 0.001] train_loss: 0.428634 train_acc: 0.586066 train_f1: 0.586066 time: 0.0426s
INFO:root:Epoch: 0245 val_loss: 0.379850 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0250 lr: [0.001, 0.001] train_loss: 0.428755 train_acc: 0.586066 train_f1: 0.586066 time: 0.0432s
INFO:root:Epoch: 0250 val_loss: 0.379776 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 15.6146s
INFO:root:Val set results: val_loss: 0.785503 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Test set results: test_loss: 0.784778 test_acc: 0.681818 test_f1: 0.681818
