INFO:root:Using: cuda:0
INFO:root:Using seed 8.
INFO:root:Dataset: cornell
INFO:root:Num classes: 5
INFO:root:NCModel(
  (encoder): BKNet(
    (linear_before): BLinear(in_features=1703, out_features=32, c=tensor([1.], device='cuda:0'))
    (layers): Sequential(
      (0): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=32, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
      (1): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
      (2): KPGraphConvolution(
        (net): KernelPointAggregation(
          (linears): ModuleList(
            (0): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (1): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (2): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (3): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (4): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
            (5): BLayer(
              (linear): BLinear(in_features=16, out_features=16, c=1)
              (act): BAct(c_in=tensor([1.], device='cuda:0'), c_out=tensor([1.], device='cuda:0'))
            )
          )
        )
      )
    )
  )
  (decoder): PoincareDecoder()
)
INFO:root:Total number of parameters: 61445
INFO:root:Epoch: 0005 lr: [0.001, 0.001] train_loss: 1.948874 train_acc: 0.586066 train_f1: 0.586066 time: 0.1155s
INFO:root:Epoch: 0005 val_loss: 1.924044 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0010 lr: [0.001, 0.001] train_loss: 1.884671 train_acc: 0.586066 train_f1: 0.586066 time: 0.1126s
INFO:root:Epoch: 0010 val_loss: 1.847577 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0015 lr: [0.001, 0.001] train_loss: 1.819404 train_acc: 0.586066 train_f1: 0.586066 time: 0.1126s
INFO:root:Epoch: 0015 val_loss: 1.769620 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0020 lr: [0.001, 0.001] train_loss: 1.752067 train_acc: 0.586066 train_f1: 0.586066 time: 0.1124s
INFO:root:Epoch: 0020 val_loss: 1.688918 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0025 lr: [0.001, 0.001] train_loss: 1.681328 train_acc: 0.586066 train_f1: 0.586066 time: 0.1118s
INFO:root:Epoch: 0025 val_loss: 1.603788 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0030 lr: [0.001, 0.001] train_loss: 1.605322 train_acc: 0.586066 train_f1: 0.586066 time: 0.1168s
INFO:root:Epoch: 0030 val_loss: 1.511843 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0035 lr: [0.001, 0.001] train_loss: 1.521266 train_acc: 0.586066 train_f1: 0.586066 time: 0.1164s
INFO:root:Epoch: 0035 val_loss: 1.409462 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0040 lr: [0.001, 0.001] train_loss: 1.424613 train_acc: 0.586066 train_f1: 0.586066 time: 0.1136s
INFO:root:Epoch: 0040 val_loss: 1.290597 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0045 lr: [0.001, 0.001] train_loss: 1.306948 train_acc: 0.586066 train_f1: 0.586066 time: 0.1109s
INFO:root:Epoch: 0045 val_loss: 1.143712 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0050 lr: [0.001, 0.001] train_loss: 1.236816 train_acc: 0.586066 train_f1: 0.586066 time: 0.1157s
INFO:root:Epoch: 0050 val_loss: 1.091964 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0055 lr: [0.001, 0.001] train_loss: 1.252603 train_acc: 0.586066 train_f1: 0.586066 time: 0.1118s
INFO:root:Epoch: 0055 val_loss: 1.101376 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0060 lr: [0.001, 0.001] train_loss: 1.249450 train_acc: 0.586066 train_f1: 0.586066 time: 0.1125s
INFO:root:Epoch: 0060 val_loss: 1.095704 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0065 lr: [0.001, 0.001] train_loss: 1.232547 train_acc: 0.586066 train_f1: 0.586066 time: 0.1131s
INFO:root:Epoch: 0065 val_loss: 1.079875 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0070 lr: [0.001, 0.001] train_loss: 1.212774 train_acc: 0.586066 train_f1: 0.586066 time: 0.1125s
INFO:root:Epoch: 0070 val_loss: 1.070018 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0075 lr: [0.001, 0.001] train_loss: 1.214055 train_acc: 0.586066 train_f1: 0.586066 time: 0.1126s
INFO:root:Epoch: 0075 val_loss: 1.075101 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0080 lr: [0.001, 0.001] train_loss: 1.212123 train_acc: 0.586066 train_f1: 0.586066 time: 0.1114s
INFO:root:Epoch: 0080 val_loss: 1.074957 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0085 lr: [0.001, 0.001] train_loss: 1.208207 train_acc: 0.586066 train_f1: 0.586066 time: 0.1122s
INFO:root:Epoch: 0085 val_loss: 1.071594 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0090 lr: [0.001, 0.001] train_loss: 1.202921 train_acc: 0.586066 train_f1: 0.586066 time: 0.1122s
INFO:root:Epoch: 0090 val_loss: 1.066045 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0095 lr: [0.001, 0.001] train_loss: 1.196560 train_acc: 0.586066 train_f1: 0.586066 time: 0.1119s
INFO:root:Epoch: 0095 val_loss: 1.058805 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0100 lr: [0.001, 0.001] train_loss: 1.191222 train_acc: 0.586066 train_f1: 0.586066 time: 0.1120s
INFO:root:Epoch: 0100 val_loss: 1.054156 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0105 lr: [0.001, 0.001] train_loss: 1.186360 train_acc: 0.586066 train_f1: 0.586066 time: 0.1116s
INFO:root:Epoch: 0105 val_loss: 1.051947 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0110 lr: [0.001, 0.001] train_loss: 1.181372 train_acc: 0.586066 train_f1: 0.586066 time: 0.1126s
INFO:root:Epoch: 0110 val_loss: 1.048828 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0115 lr: [0.001, 0.001] train_loss: 1.179107 train_acc: 0.586066 train_f1: 0.586066 time: 0.1115s
INFO:root:Epoch: 0115 val_loss: 1.049568 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0120 lr: [0.001, 0.001] train_loss: 1.174918 train_acc: 0.586066 train_f1: 0.586066 time: 0.1131s
INFO:root:Epoch: 0120 val_loss: 1.043745 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0125 lr: [0.001, 0.001] train_loss: 1.169595 train_acc: 0.586066 train_f1: 0.586066 time: 0.1150s
INFO:root:Epoch: 0125 val_loss: 1.041182 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0130 lr: [0.001, 0.001] train_loss: 1.166428 train_acc: 0.586066 train_f1: 0.586066 time: 0.1131s
INFO:root:Epoch: 0130 val_loss: 1.037829 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0135 lr: [0.001, 0.001] train_loss: 1.160825 train_acc: 0.586066 train_f1: 0.586066 time: 0.1121s
INFO:root:Epoch: 0135 val_loss: 1.033791 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0140 lr: [0.001, 0.001] train_loss: 1.156236 train_acc: 0.586066 train_f1: 0.586066 time: 0.1142s
INFO:root:Epoch: 0140 val_loss: 1.030379 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0145 lr: [0.001, 0.001] train_loss: 1.151554 train_acc: 0.586066 train_f1: 0.586066 time: 0.1133s
INFO:root:Epoch: 0145 val_loss: 1.026606 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0150 lr: [0.001, 0.001] train_loss: 1.146722 train_acc: 0.586066 train_f1: 0.586066 time: 0.1119s
INFO:root:Epoch: 0150 val_loss: 1.024054 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0155 lr: [0.001, 0.001] train_loss: 1.140231 train_acc: 0.586066 train_f1: 0.586066 time: 0.1106s
INFO:root:Epoch: 0155 val_loss: 1.020006 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0160 lr: [0.001, 0.001] train_loss: 1.136501 train_acc: 0.586066 train_f1: 0.586066 time: 0.1113s
INFO:root:Epoch: 0160 val_loss: 1.016164 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0165 lr: [0.001, 0.001] train_loss: 1.131558 train_acc: 0.586066 train_f1: 0.586066 time: 0.1133s
INFO:root:Epoch: 0165 val_loss: 1.009967 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0170 lr: [0.001, 0.001] train_loss: 1.124427 train_acc: 0.586066 train_f1: 0.586066 time: 0.1106s
INFO:root:Epoch: 0170 val_loss: 1.005810 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0175 lr: [0.001, 0.001] train_loss: 1.119179 train_acc: 0.586066 train_f1: 0.586066 time: 0.1135s
INFO:root:Epoch: 0175 val_loss: 1.003489 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0180 lr: [0.001, 0.001] train_loss: 1.110689 train_acc: 0.586066 train_f1: 0.586066 time: 0.1131s
INFO:root:Epoch: 0180 val_loss: 0.996097 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0185 lr: [0.001, 0.001] train_loss: 1.101584 train_acc: 0.586066 train_f1: 0.586066 time: 0.1110s
INFO:root:Epoch: 0185 val_loss: 0.989736 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0190 lr: [0.001, 0.001] train_loss: 1.094092 train_acc: 0.586066 train_f1: 0.586066 time: 0.1113s
INFO:root:Epoch: 0190 val_loss: 0.985435 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0195 lr: [0.001, 0.001] train_loss: 1.087575 train_acc: 0.586066 train_f1: 0.586066 time: 0.1138s
INFO:root:Epoch: 0195 val_loss: 0.979368 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0200 lr: [0.001, 0.001] train_loss: 1.085266 train_acc: 0.586066 train_f1: 0.586066 time: 0.1120s
INFO:root:Epoch: 0200 val_loss: 0.982272 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0205 lr: [0.001, 0.001] train_loss: 1.085461 train_acc: 0.586066 train_f1: 0.586066 time: 0.1150s
INFO:root:Epoch: 0205 val_loss: 0.990409 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0210 lr: [0.001, 0.001] train_loss: 1.088773 train_acc: 0.586066 train_f1: 0.586066 time: 0.1130s
INFO:root:Epoch: 0210 val_loss: 0.972516 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0215 lr: [0.001, 0.001] train_loss: 1.082984 train_acc: 0.586066 train_f1: 0.586066 time: 0.1125s
INFO:root:Epoch: 0215 val_loss: 0.965667 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0220 lr: [0.001, 0.001] train_loss: 1.078092 train_acc: 0.586066 train_f1: 0.586066 time: 0.1138s
INFO:root:Epoch: 0220 val_loss: 0.961169 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0225 lr: [0.001, 0.001] train_loss: 1.081241 train_acc: 0.586066 train_f1: 0.586066 time: 0.1116s
INFO:root:Epoch: 0225 val_loss: 0.956052 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0230 lr: [0.001, 0.001] train_loss: 1.079896 train_acc: 0.586066 train_f1: 0.586066 time: 0.1115s
INFO:root:Epoch: 0230 val_loss: 0.958632 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0235 lr: [0.001, 0.001] train_loss: 1.077632 train_acc: 0.586066 train_f1: 0.586066 time: 0.1109s
INFO:root:Epoch: 0235 val_loss: 0.955268 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0240 lr: [0.001, 0.001] train_loss: 1.077874 train_acc: 0.586066 train_f1: 0.586066 time: 0.1126s
INFO:root:Epoch: 0240 val_loss: 0.949956 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0245 lr: [0.001, 0.001] train_loss: 1.074648 train_acc: 0.586066 train_f1: 0.586066 time: 0.1119s
INFO:root:Epoch: 0245 val_loss: 0.950446 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Epoch: 0250 lr: [0.001, 0.001] train_loss: 1.072289 train_acc: 0.586066 train_f1: 0.586066 time: 0.1119s
INFO:root:Epoch: 0250 val_loss: 0.950956 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 37.8995s
INFO:root:Val set results: val_loss: 1.984811 val_acc: 0.659091 val_f1: 0.659091
INFO:root:Test set results: test_loss: 1.984060 test_acc: 0.681818 test_f1: 0.681818
