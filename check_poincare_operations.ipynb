{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n",
      "Using seed 1234.\n",
      "Dataset: wisconsin\n",
      "Num classes: 5\n",
      "dict_keys(['adj_train', 'features', 'labels', 'idx_train', 'idx_val', 'idx_test', 'adj_train_norm'])\n",
      "(251, 251)\n",
      "torch.Size([251, 1703])\n",
      "AggKlein == False\n",
      "corr == 0\n",
      "NCModel(\n",
      "  (encoder): BKNet(\n",
      "    (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=True, act=None)\n",
      "    (layers): Sequential(\n",
      "      (0): KPGraphConvolution(\n",
      "        (net): KernelPointAggregation(\n",
      "          (linears): ModuleList(\n",
      "            (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "            (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "            (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "            (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "          )\n",
      "          (MLP_f): BMLP(\n",
      "            (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "            (act): BAct(c=tensor([1.], device='cuda:0'), act=<function relu at 0x7f8560393370>)\n",
      "            (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "          )\n",
      "          (MLP_fi): BMLP(\n",
      "            (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "            (act): BAct(c=tensor([1.], device='cuda:0'), act=<function relu at 0x7f8560393370>)\n",
      "            (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): PoincareDecoder()\n",
      ")\n",
      "Total number of parameters: 163589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lige/HKN/utils/data_utils.py:347: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G, sorted(G.nodes()))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "import sys\n",
    "sys.path.append('/data/lige/HKN')# Please change accordingly!\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from geoopt import ManifoldParameter as geoopt_ManifoldParameter\n",
    "from manifolds.base import ManifoldParameter as base_ManifoldParameter\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "from optim import RiemannianAdam, RiemannianSGD\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from config import parser\n",
    "from models.base_models import NCModel, LPModel, GCModel\n",
    "from utils.data_utils import load_data, get_nei, GCDataset, split_batch\n",
    "from utils.train_utils import get_dir_name, format_metrics\n",
    "from utils.eval_utils import acc_f1\n",
    "\n",
    "from geoopt import ManifoldParameter as geoopt_ManifoldParameter\n",
    "from manifolds.base import ManifoldParameter as base_ManifoldParameter\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "config_args = {\n",
    "    'training_config': {\n",
    "        'lr': (1e-3, 'learning rate'),\n",
    "        'dropout': (0.25, 'dropout probability'),\n",
    "        'cuda': (0, 'which cuda device to use (-1 for cpu training)'),\n",
    "        'epochs': (1000, 'maximum number of epochs to train for'),\n",
    "        'weight_decay': (1e-3, 'l2 regularization strength'),\n",
    "        'optimizer': ('radam', 'which optimizer to use, can be any of [rsgd, radam]'),\n",
    "        'momentum': (0.999, 'momentum in optimizer'),\n",
    "        'patience': (15, 'patience for early stopping'),\n",
    "        'seed': (1234, 'seed for training'),\n",
    "        'log_freq': (5, 'how often to compute print train/val metrics (in epochs)'),\n",
    "        'eval_freq': (1, 'how often to compute val metrics (in epochs)'),\n",
    "        'save': (0, '1 to save model and logs and 0 otherwise'),\n",
    "        'save_dir': (None, 'path to save training logs and model weights (defaults to logs/task/date/run/)'),\n",
    "        'sweep_c': (0, ''),\n",
    "        'lr_reduce_freq': (None, 'reduce lr every lr-reduce-freq or None to keep lr constant'),\n",
    "        'gamma': (0.5, 'gamma for lr scheduler'),\n",
    "        'print_epoch': (True, ''),\n",
    "        'grad_clip': (None, 'max norm for gradient clipping, or None for no gradient clipping'),\n",
    "        'min_epochs': (300, 'do not early stop before min-epochs')\n",
    "    },\n",
    "    'model_config': {\n",
    "        'use_geoopt': (False, \"which manifold class to use, if false then use basd.manifold\"),\n",
    "        'AggKlein':(False, \"if false, then use hyperboloid centorid for aggregation\"),\n",
    "        'corr': (0,'0: d(x_i ominus x, x_k), 1: d(x_ik,x_k)'),\n",
    "        'task': ('nc', 'which tasks to train on, can be any of [lp, nc]'),\n",
    "        'model': ('BKNet', 'which encoder to use, can be any of [Shallow, MLP, HNN, GCN, GAT, HyperGCN, HyboNet,BKNet,BMLP]'),\n",
    "        'dim': (64, 'embedding dimension'),\n",
    "        'manifold': ('PoincareBall', 'which manifold to use, can be any of [Euclidean, Hyperboloid, PoincareBall, Lorentz]'),\n",
    "        'c': (1.0, 'hyperbolic radius, set to None for trainable curvature'),\n",
    "        'r': (2., 'fermi-dirac decoder parameter for lp'),\n",
    "        't': (1., 'fermi-dirac decoder parameter for lp'),\n",
    "        'margin': (2., 'margin of MarginLoss'),\n",
    "        'pretrained_embeddings': (None, 'path to pretrained embeddings (.npy file) for Shallow node classification'),\n",
    "        'pos_weight': (0, 'whether to upweight positive class in node classification tasks'),\n",
    "        'num_layers': (2, 'number of hidden layers in encoder'),\n",
    "        'bias': (1, 'whether to use bias (1) or not (0)'),\n",
    "        'act': ('relu', 'which activation function to use (or None for no activation)'),\n",
    "        'n_heads': (4, 'number of attention heads for graph attention networks, must be a divisor dim'),\n",
    "        'alpha': (0.2, 'alpha for leakyrelu in graph attention networks'),\n",
    "        'double_precision': ('1', 'whether to use double precision'),\n",
    "        'use_att': (0, 'whether to use hyperbolic attention or not'),\n",
    "        'local_agg': (0, 'whether to local tangent space aggregation or not'),\n",
    "        'kernel_size': (4, 'number of kernels'),\n",
    "        'KP_extent': (0.66, 'influence radius of each kernel point'),\n",
    "        'radius': (1, 'radius used for kernel point init'),\n",
    "        'deformable': (False, 'deformable kernel'),\n",
    "        'linear_before': (64, 'dim of linear before gcn')#64\n",
    "    },\n",
    "    'data_config': {\n",
    "        'dataset': ('wisconsin', 'which dataset to use(cornell,wisconsin,squirrel,cora)'),\n",
    "        'batch_size': (32, 'batch size for gc'),\n",
    "        'val_prop': (0.05, 'proportion of validation edges for link prediction'),\n",
    "        'test_prop': (0.1, 'proportion of test edges for link prediction'),\n",
    "        'use_feats': (1, 'whether to use node features or not'),\n",
    "        'normalize_feats': (1, 'whether to normalize input node features'),\n",
    "        'normalize_adj': (1, 'whether to row-normalize the adjacency matrix'),\n",
    "        'split_seed': (1234, 'seed for data splits (train/test/val)'),\n",
    "        'split_graph': (False, 'whether to split the graph')\n",
    "    }\n",
    "}\n",
    "\n",
    "# 将所有参数转换为 SimpleNamespace\n",
    "args = SimpleNamespace(\n",
    "    **{k: v[0] for config in config_args.values() for k, v in config.items()}\n",
    ")\n",
    "\n",
    "#choose which manifold class to follow \n",
    "if args.use_geoopt == False:\n",
    "    ManifoldParameter = base_ManifoldParameter\n",
    "else:\n",
    "    ManifoldParameter = geoopt_ManifoldParameter\n",
    "np.random.seed(args.seed)#args.seed\n",
    "torch.manual_seed(args.seed)#args.seed\n",
    "if int(args.cuda):#args.double_precision\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "if int(args.cuda) >= 0:#args.cuda\n",
    "    torch.cuda.manual_seed(args.seed)#args.seed\n",
    "args.device = 'cuda:' + str(args.cuda) if int(args.cuda) >= 0 else 'cpu' #args.device actually,<-args.cuda\n",
    "args.patience = args.epochs if not args.patience else args.patience #args.patience<-args.epochs|args.patience\n",
    "\n",
    "print(f'Using: {args.device}')\n",
    "print(\"Using seed {}.\".format(args.seed))\n",
    "print(f\"Dataset: {args.dataset}\")\n",
    "\n",
    "# Load data\n",
    "data = load_data(args, os.path.join('data', args.dataset))\n",
    "if args.task == 'gc':\n",
    "    args.n_nodes, args.feat_dim = data['features'][0].shape\n",
    "else:\n",
    "    args.n_nodes, args.feat_dim = data['features'].shape\n",
    "if args.task == 'nc':\n",
    "    Model = NCModel\n",
    "    args.n_classes = int(data['labels'].max() + 1)\n",
    "    args.data = data\n",
    "    print(f'Num classes: {args.n_classes}')\n",
    "elif args.task == 'gc':\n",
    "    Model = GCModel\n",
    "    args.n_classes = int(data['labels'].max() + 1)\n",
    "    print(f'Num classes: {args.n_classes}')\n",
    "else:\n",
    "    args.nb_false_edges = len(data['train_edges_false'])\n",
    "    args.nb_edges = len(data['train_edges'])\n",
    "    if args.task == 'lp':\n",
    "        Model = LPModel\n",
    "        args.n_classes = 2\n",
    "\n",
    "if not args.lr_reduce_freq:\n",
    "    args.lr_reduce_freq = args.epochs\n",
    "\n",
    "\n",
    "###A simple check on data\n",
    "print(data.keys())\n",
    "print(data['adj_train'].todense().shape)\n",
    "print(data['features'].shape)\n",
    "###A simple check on data\n",
    "\n",
    "# Model and optimizer\n",
    "model = Model(args)\n",
    "print(str(model))\n",
    "no_decay = ['bias', 'scale']\n",
    "optimizer_grouped_parameters = [{\n",
    "    'params': [\n",
    "        p for n, p in model.named_parameters()\n",
    "        if p.requires_grad and not any(\n",
    "            nd in n\n",
    "            for nd in no_decay) and not isinstance(p, ManifoldParameter)\n",
    "    ],\n",
    "    'weight_decay':\n",
    "    args.weight_decay\n",
    "}, {\n",
    "    'params': [\n",
    "        p for n, p in model.named_parameters() if p.requires_grad and any(\n",
    "            nd in n\n",
    "            for nd in no_decay) or isinstance(p, ManifoldParameter)\n",
    "    ],\n",
    "    'weight_decay':\n",
    "    0.0\n",
    "}]\n",
    "if args.optimizer == 'radam':\n",
    "    optimizer = RiemannianAdam(params=optimizer_grouped_parameters,\n",
    "                                lr=args.lr,\n",
    "                                stabilize=10)\n",
    "elif args.optimizer == 'rsgd':\n",
    "    optimizer = RiemannianSGD(params=optimizer_grouped_parameters,\n",
    "                                lr=args.lr,\n",
    "                                stabilize=10)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                step_size=int(\n",
    "                                                args.lr_reduce_freq),\n",
    "                                                gamma=float(args.gamma))\n",
    "tot_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "model = model.to(args.device)\n",
    "for x, val in data.items():\n",
    "    if torch.is_tensor(data[x]):\n",
    "        data[x] = data[x].to(args.device)\n",
    "print(f\"Total number of parameters: {tot_params}\")\n",
    "\n",
    "# Train model for nc:\n",
    "t_total = time.time()\n",
    "counter = 0\n",
    "best_val_metrics = model.init_metric_dict()\n",
    "best_test_metrics = None\n",
    "best_emb = None\n",
    "if args.n_classes > 2:\n",
    "    f1_average = 'micro'\n",
    "else:\n",
    "    f1_average = 'binary'\n",
    "\n",
    "if args.model == 'HKPNet':\n",
    "    nei, nei_mask = get_nei(data['adj_train'])\n",
    "    nei = nei.to(args.device)\n",
    "    nei_mask = nei_mask.to(args.device)\n",
    "elif args.model == 'BKNet':\n",
    "    nei, nei_mask = get_nei(data['adj_train'])\n",
    "    nei = nei.to(args.device)\n",
    "    nei_mask = nei_mask.to(args.device) #nei/nei_mask on cuda now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BKNet(\n",
       "  (linear_before): BLinear(in_features=1703, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=True, act=None)\n",
       "  (layers): Sequential(\n",
       "    (0): KPGraphConvolution(\n",
       "      (net): KernelPointAggregation(\n",
       "        (linears): ModuleList(\n",
       "          (0): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "          (1): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "          (2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "          (3): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "        )\n",
       "        (MLP_f): BMLP(\n",
       "          (linear1): BLinear(in_features=64, out_features=128, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "          (act): BAct(c=tensor([1.], device='cuda:0'), act=<function relu at 0x7f8560393370>)\n",
       "          (linear2): BLinear(in_features=128, out_features=128, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "        )\n",
       "        (MLP_fi): BMLP(\n",
       "          (linear1): BLinear(in_features=128, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "          (act): BAct(c=tensor([1.], device='cuda:0'), act=<function relu at 0x7f8560393370>)\n",
       "          (linear2): BLinear(in_features=64, out_features=64, c=tensor([1.], device='cuda:0'), use_bias=1, act=None)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([251, 122, 1703])\n"
     ]
    }
   ],
   "source": [
    "import layers.B_layers as Blayers\n",
    "x_nei = Blayers.gather(data['features'], nei) # (n, nei_num, d)\n",
    "print(x_nei.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([251, 1703])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klein_points = model.manifold.klein_proj(model.manifold.poincare_to_klein(x_nei,model.c), model.c)\n",
    "target_klein_point = model.manifold.klein_proj(model.manifold.klein_midpoint(klein_points), model.c)\n",
    "target_poincare_point = model.manifold.proj(model.manifold.klein_to_poincare(target_klein_point, model.c), model.c)\n",
    "target_poincare_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([251, 1])\n"
     ]
    }
   ],
   "source": [
    "norm=torch.norm(target_poincare_point, dim=-1)#\n",
    "# 将 norm 调整为 [251, 1]\n",
    "norm = norm.unsqueeze(1)  # 形状: [251, 1]\n",
    "\n",
    "# 确保 norm 中没有零值，避免除零错误\n",
    "norm = torch.clamp(norm, min=1e-6)\n",
    "print(norm.shape)\n",
    "cond = norm > 0.5\n",
    "projected = target_poincare_point / norm * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([251, 1703]) torch.Size([251, 122, 1703])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1148, 0.1179, 0.1170, 0.1164, 0.1171, 0.1172, 0.1171, 0.1179, 0.1179,\n",
       "        0.1179, 0.1179, 0.1164, 0.1171, 0.1179, 0.1179, 0.1179, 0.1179, 0.1179,\n",
       "        0.1179, 0.1179, 0.1151, 0.1174, 0.1167, 0.1179, 0.1176, 0.1165, 0.1171,\n",
       "        0.1164, 0.1164, 0.1164, 0.1164, 0.1179, 0.1157, 0.1179, 0.1163, 0.1173,\n",
       "        0.1179, 0.1155, 0.1172, 0.1170, 0.1179, 0.1164, 0.1179, 0.1170, 0.1117,\n",
       "        0.1157, 0.1156, 0.1172, 0.1167, 0.1164, 0.1140, 0.1167, 0.1179, 0.1160,\n",
       "        0.1127, 0.1179, 0.1179, 0.1164, 0.1171, 0.1179, 0.1179, 0.1179, 0.1179,\n",
       "        0.1164, 0.1159, 0.1179, 0.1174, 0.1179, 0.1171, 0.1158, 0.1164, 0.1164,\n",
       "        0.1179, 0.1179, 0.1173, 0.1128, 0.1179, 0.1179, 0.1172, 0.1124, 0.1179,\n",
       "        0.1157, 0.1171, 0.1169, 0.1179, 0.1179, 0.1164, 0.1163, 0.1179, 0.1155,\n",
       "        0.1174, 0.1160, 0.1148, 0.1179, 0.1179, 0.1179, 0.1163, 0.1162, 0.0663,\n",
       "        0.1179, 0.1179, 0.1157, 0.1165, 0.1158, 0.1179, 0.1179, 0.1171, 0.1151,\n",
       "        0.1171, 0.1179, 0.1171, 0.1179, 0.1171, 0.1171, 0.1164, 0.1179, 0.1173,\n",
       "        0.1166, 0.1164, 0.1171, 0.1149, 0.1158, 0.1164, 0.1179, 0.1179, 0.1179,\n",
       "        0.1158, 0.1170, 0.1152, 0.1139, 0.1166, 0.1179, 0.1179, 0.1179, 0.1179,\n",
       "        0.1179, 0.1179, 0.1179, 0.1171, 0.1179, 0.1173, 0.1157, 0.1179, 0.1179,\n",
       "        0.1164, 0.1171, 0.1172, 0.1134, 0.1172, 0.1176, 0.1173, 0.1171, 0.1147,\n",
       "        0.1172, 0.1171, 0.1160, 0.1144, 0.1179, 0.1172, 0.1179, 0.1159, 0.1179,\n",
       "        0.1170, 0.1171, 0.1171, 0.1164, 0.1170, 0.1174, 0.1157, 0.1165, 0.1148,\n",
       "        0.1167, 0.1170, 0.1146, 0.1179, 0.1172, 0.1173, 0.1179, 0.1151, 0.1172,\n",
       "        0.1171, 0.1172, 0.1179, 0.1170, 0.1163, 0.1179, 0.1133, 0.1179, 0.1157,\n",
       "        0.1164, 0.1164, 0.1179, 0.1111, 0.1179, 0.1173, 0.1179, 0.1172, 0.1144,\n",
       "        0.1163, 0.1152, 0.1175, 0.1166, 0.1172, 0.1168, 0.1135, 0.1171, 0.1160,\n",
       "        0.1157, 0.1163, 0.1179, 0.1164, 0.1157, 0.1171, 0.1179, 0.1171, 0.1172,\n",
       "        0.1179, 0.1164, 0.1179, 0.1171, 0.1179, 0.1179, 0.1173, 0.1167, 0.1171,\n",
       "        0.1170, 0.1172, 0.1179, 0.1171, 0.1172, 0.1179, 0.1158, 0.1171, 0.1172,\n",
       "        0.1179, 0.1179, 0.1157, 0.1179, 0.1179, 0.1172, 0.1171, 0.1158, 0.1059,\n",
       "        0.1171, 0.1163, 0.1159, 0.1157, 0.1179, 0.1171, 0.1172, 0.1171],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=model.manifold.proper_tangent_space(x_nei, model.c)\n",
    "print(res.shape,x_nei.shape)\n",
    "torch.norm(res, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0113e-04, 3.9234e-05, 1.8320e-05,  ..., 1.4654e-04, 1.1818e-02,\n",
       "        1.3010e-04], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.manifold.proper_tangent_space(data['features'], model.c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HKNet",
   "language": "python",
   "name": "hknet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
